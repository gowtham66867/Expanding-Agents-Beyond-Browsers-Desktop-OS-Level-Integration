File Structure:
==============
utils\__init__.py
utils\fdom\__init__.py
utils\fdom\app_controller.py
utils\fdom\auto_captioner.py
utils\fdom\click_engine.py
utils\fdom\config_manager.py
utils\fdom\element_interactor.py
utils\fdom\fdom_analyzer.py
utils\fdom\fdom_creator.py
utils\fdom\interaction_types.py
utils\fdom\interaction_utils.py
utils\fdom\interactive_cli.py
utils\fdom\navigation_engine.py
utils\fdom\screen_manager.py
utils\fdom\screenshot_manager.py
utils\fdom\seraphine_integrator.py
utils\fdom\state_manager.py
utils\fdom\state_processor.py
utils\fdom\visual_differ.py
utils\gui_controller.py
utils\seraphine.py
utils\seraphine_pipeline\__init__.py
utils\seraphine_pipeline\bbox_merger.py
utils\seraphine_pipeline\beautiful_visualizer.py
utils\seraphine_pipeline\create_crops.py
utils\seraphine_pipeline\crop_test.py
utils\seraphine_pipeline\gemini_analyzer.py
utils\seraphine_pipeline\gemini_integration.py
utils\seraphine_pipeline\helpers.py
utils\seraphine_pipeline\ocr_detector.py
utils\seraphine_pipeline\parallel_processor.py
utils\seraphine_pipeline\pipeline_exporter.py
utils\seraphine_pipeline\seraphine_generator.py
utils\seraphine_pipeline\seraphine_preprocessor.py
utils\seraphine_pipeline\seraphine_processor.py
utils\seraphine_pipeline\splashscreen_handler.py
utils\seraphine_pipeline\yolo_detector.py
utils\windowManager\__init__.py
utils\windowManager\window_functions.py
utils\windowManager\window_manager.py

File Contents:
==============

Path: utils\__init__.py
File: __init__.py
Code:


==================================================

Path: utils\fdom\__init__.py
File: __init__.py
Code:


==================================================

Path: utils\fdom\app_controller.py
File: app_controller.py
Code:
"""
AppController - Application launch and window management for fDOM Framework
Handles app launching, window detection, positioning, and folder structure creation
"""
import os
import sys
import subprocess
import time
from pathlib import Path
from typing import Dict, Optional, Tuple
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import track
from rich import print as rprint
import json

# Add parent directory to path for gui_controller import
sys.path.append(str(Path(__file__).parent.parent))
from gui_controller import SimpleWindowAPI

class AppController:
    """
    Professional application launch and window management for fDOM framework
    Handles executable launching, window detection, positioning, and storage setup
    """
    
    def __init__(self, app_path: str, target_screen: int = 1, config: dict = None, template_file_path: str = None):
        """
        Initialize AppController with configuration and screen management
        
        Args:
            app_path: Path to the executable
            target_screen: Target screen for launch
            config: ConfigManager instance for settings
            template_file_path: Path to the template file
        """
        self.app_path = app_path
        self.app_name = self._generate_app_name(app_path)
        self.target_screen = target_screen
        self.config = config or {}
        self.template_file_path = template_file_path
        self.screen_manager = None
        self.console = Console()
        self.gui_api = SimpleWindowAPI()
        self.current_app_info = None
        self.apps_base_dir = Path(__file__).parent.parent.parent / "apps"  # utils/fdom -> utils -> project_root -> apps
        
    def _generate_app_name(self, executable_path: str) -> str:
        """
        Auto-generate clean app name from executable path
        
        Args:
            executable_path: Path to the executable
            
        Returns:
            Clean app name for folder creation
        """
        exe_path = Path(executable_path)
        
        # Get base name without extension
        base_name = exe_path.stem.lower()
        
        # Clean up common patterns
        base_name = base_name.replace(" ", "_")
        base_name = base_name.replace("-", "_")
        base_name = base_name.replace("++", "_plus_plus")
        
        # Remove common suffixes
        suffixes_to_remove = ["_setup", "_installer", "_x64", "_x86", "_win32", "_win64"]
        for suffix in suffixes_to_remove:
            if base_name.endswith(suffix):
                base_name = base_name[:-len(suffix)]
                break
        
        return base_name
    
    def _create_app_folder_structure(self, app_name: str) -> Dict[str, Path]:
        """
        Create complete folder structure for app exploration
        
        Args:
            app_name: Generated app name
            
        Returns:
            Dictionary with all created folder paths
        """
        self.console.print(f"[yellow]üìÅ Creating folder structure for '{app_name}'...[/yellow]")
        
        # Main app directory
        app_dir = self.apps_base_dir / app_name
        app_dir.mkdir(parents=True, exist_ok=True)
        
        # Get storage config from ConfigManager
        storage_config = self.config.get_app_storage_config()
        
        # Create all subdirectories
        paths = {
            'app_dir': app_dir,
            'screenshots': app_dir / storage_config['screenshots'],
            'crops': app_dir / storage_config['crops'],
            'diffs': app_dir / storage_config['diffs'],
            'templates': app_dir / storage_config['templates']
        }
        
        # Create all directories
        for dir_name, dir_path in paths.items():
            if dir_name != 'app_dir':  # app_dir already created
                dir_path.mkdir(exist_ok=True)
                self.console.print(f"  [green]‚úÖ[/green] Created {dir_name}/")
        
        # Create metadata.json
        metadata = {
            "app_name": app_name,
            "created_timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ"),
            "fdom_creator_version": "1.0.0",
            "exploration_status": "initialized",
            "folder_structure": {
                "screenshots": storage_config['screenshots'],
                "crops": storage_config['crops'], 
                "diffs": storage_config['diffs'],
                "templates": storage_config['templates']
            }
        }
        
        metadata_path = app_dir / "metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        self.console.print(f"  [green]‚úÖ[/green] Created metadata.json")
        
        return paths
    
    def launch_app(self) -> dict:
        """Launch application with optional template file"""
        try:
            print(f"üéØ Strategy 1: Direct launch on Screen {self.target_screen}...")
            
            # ‚úÖ BUILD LAUNCH COMMAND WITH TEMPLATE FILE
            launch_args = [self.app_path]
            
            if self.template_file_path:
                launch_args.append(self.template_file_path)
                print(f"üìÑ Including template file: {os.path.basename(self.template_file_path)}")
            
            print(f"Launching: {' '.join(launch_args)}")
            
            # Launch with template file
            process = subprocess.Popen(
                launch_args,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
            )
            
            # Wait for app to start and find its window
            window_id = None
            app_title_partial = self.app_name.lower()
            
            for attempt in track(range(15), description="Waiting for window..."):
                time.sleep(1)
                
                # Try to find the window using better search patterns for Office apps
                window_id = None
                app_name_lower = self.app_name.lower()
                search_patterns = [
                    app_title_partial,                  # Original search term
                    app_name_lower,                     # "powerpnt"
                    self.app_name,                      # "POWERPNT"
                    "powerpoint",                       # Direct PowerPoint match
                    "excel",                           # Direct Excel match  
                    "word",                            # Direct Word match
                    "outlook",                         # Direct Outlook match
                    "access",                          # Direct Access match
                    "publisher",                       # Direct Publisher match
                    "onenote",                         # Direct OneNote match
                    "project",                         # Direct Project match
                    "visio",                           # Direct Visio match  
                    "teams",                           # Direct Teams match
                    "sharepoint",                      # Direct SharePoint match
                    "skype"                            # Direct Skype match
                ]

                for pattern in search_patterns:
                    window_id = self.gui_api.find_window(pattern)
                    if window_id:
                        break
            
            if not window_id:
                self.console.print(f"[red]‚ùå Could not find window for {self.app_name} after 15s[/red]")
                return {"success": False, "error": "Window not found"}
            
            self.console.print(f"[green]‚úÖ Window found: {window_id}[/green]")
            
            # Get window info and detect actual screen using screen_manager logic
            time.sleep(1)
            window_info = self.gui_api.get_window_info(window_id)
            
            if not window_info:
                self.console.print("[red]‚ùå Could not get window information[/red]")
                return {"success": False, "error": "Window info unavailable"}
            
            pos = window_info['window_data']['position']
            size = window_info['window_data']['size']
            hwnd = window_info['window_data']['hwnd']
            
            # Use screen_manager's detection logic
            actual_screen = self._detect_window_screen_using_screen_manager(pos, size)
            
            self.console.print(f"[yellow]üìç Window opened on Screen {actual_screen} at ({pos['x']}, {pos['y']})[/yellow]")
            
            # Force move to TEST SCREEN if not already there
            if actual_screen != self.target_screen:
                self.console.print(f"[yellow]üîÑ Moving window from Screen {actual_screen} to Screen {self.target_screen} (TEST SCREEN)...[/yellow]")
                
                # Get target screen info from screen_manager
                target_screen_info = None
                for screen in self.screen_manager.screens:
                    if screen['id'] == self.target_screen:
                        target_screen_info = screen
                        break
                
                if target_screen_info:
                    # Move to target screen coordinates
                    new_x = target_screen_info['left'] + 100
                    new_y = target_screen_info['top'] + 100
                    
                    self.console.print(f"[cyan]üéØ Moving to coordinates: ({new_x}, {new_y})[/cyan]")
                    
                    if self.gui_api.move_window(window_id, new_x, new_y):
                        self.console.print(f"[green]‚úÖ Move command sent[/green]")
                        time.sleep(2)  # Wait for move to complete
                        
                        if self.gui_api.maximize_window(window_id):
                            self.console.print(f"[green]‚úÖ Maximize command sent[/green]")
                            time.sleep(2)  # Wait for maximize to complete
                            
                            # CRITICAL FIX: Force refresh and re-find window
                            final_screen, updated_window_id = self._robust_window_retracking(
                                hwnd, self.target_screen, self.app_name.lower(), window_id
                            )
                            
                            # Update the window_id with the potentially new one
                            window_id = updated_window_id
                        else:
                            self.console.print(f"[red]‚ùå Failed to maximize window[/red]")
                            final_screen = actual_screen
                    else:
                        self.console.print(f"[red]‚ùå Failed to move window[/red]")
                        final_screen = actual_screen
                else:
                    self.console.print(f"[red]‚ùå Could not find target screen info[/red]")
                    final_screen = actual_screen
            else:
                self.console.print(f"[green]‚úÖ Window already on Screen {actual_screen} (TEST SCREEN)[/green]")
                final_screen = actual_screen
            
            # Position and prepare window (using the potentially updated window_id)
            positioning_result = self._position_window_for_exploration(window_id, final_screen)
            
            # Store app information with actual final screen (and updated window_id)
            self.current_app_info = {
                "app_name": self.app_name,
                "executable_path": self.app_path,
                "window_id": window_id,  # This is now the updated window_id
                "target_screen": final_screen,
                "folder_paths": self._create_app_folder_structure(self.app_name),
                "process_id": process.pid,
                "hwnd": hwnd  # Store hwnd for direct access if needed
            }
            
            self.console.print(f"[bold green]üéØ Final: App on Screen {final_screen} (TEST SCREEN)[/bold green]")
            
            return {
                "success": True,
                "app_info": self.current_app_info,
                "positioning_result": positioning_result
            }
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Error launching application: {e}[/red]")
            return {"success": False, "error": str(e)}
    
    def _position_window_for_exploration(self, window_id: str, target_screen: int) -> Dict:
        """
        Position and prepare window for optimal fDOM exploration
        Assumes window is already on the correct screen
        """
        self.console.print(f"[yellow]üéØ Preparing window on screen {target_screen}...[/yellow]")
        
        results = {"steps": [], "success": True}
        
        try:
            # Focus window
            focus_delay = self.config.get("interaction.window_focus_delay", 0.5)
            time.sleep(focus_delay)
            
            if self.gui_api.focus_window(window_id):
                results["steps"].append("‚úÖ Window focused")
                self.console.print(f"  [green]‚úÖ[/green] Window focused")
            else:
                results["steps"].append("‚ùå Failed to focus window")
                results["success"] = False
            
            # Maximize for consistent screenshots
            if self.gui_api.maximize_window(window_id):
                results["steps"].append("‚úÖ Window maximized")
                self.console.print(f"  [green]‚úÖ[/green] Window maximized")
            else:
                results["steps"].append("‚ùå Failed to maximize window")
            
            return results
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Error positioning window: {e}[/red]")
            results["success"] = False
            results["error"] = str(e)
            return results
    
    def _robust_window_retracking(self, hwnd: int, expected_screen: int, app_title_partial: str, current_window_id: str) -> Tuple[int, str]:
        """
        Robustly re-track window after move/maximize operations
        Returns tuple of (actual_screen, updated_window_id)
        """
        self.console.print(f"[cyan]üîÑ Re-tracking window after operations...[/cyan]")
        
        updated_window_id = current_window_id  # Start with current ID
        
        # Strategy 1: Force refresh the GUI API and find by hwnd/title
        for attempt in range(5):
            self.console.print(f"[cyan]üîç Attempt {attempt+1}: Force refresh and re-detect...[/cyan]")
            
            # Force complete refresh
            self.gui_api.refresh()
            time.sleep(1)  # Wait for refresh
            
            # Try to find window again by title (this rebuilds the lookup)
            new_window_id = self.gui_api.find_window(app_title_partial)
            
            if new_window_id:
                # Update the window_id we'll return
                updated_window_id = new_window_id
                
                # Get fresh window info
                fresh_info = self.gui_api.get_window_info(new_window_id)
                
                if fresh_info:
                    pos = fresh_info['window_data']['position']
                    size = fresh_info['window_data']['size']
                    
                    self.console.print(f"[green]‚úÖ Re-tracked window: ({pos['x']}, {pos['y']}) size {size['width']}√ó{size['height']}[/green]")
                    
                    # Detect current screen
                    actual_screen = self._detect_window_screen_using_screen_manager(pos, size)
                    
                    if actual_screen == expected_screen:
                        self.console.print(f"[green]üéØ SUCCESS: Window confirmed on Screen {expected_screen} (TEST SCREEN)[/green]")
                        return expected_screen, updated_window_id
                    else:
                        self.console.print(f"[yellow]‚ö†Ô∏è Window detected on Screen {actual_screen}, expected {expected_screen}[/yellow]")
                        # Don't retry immediately - it might be correct visually
                        if attempt >= 2:  # After attempt 3, trust the visual
                            self.console.print(f"[yellow]üéØ Trusting visual confirmation - assuming Screen {expected_screen}[/yellow]")
                            return expected_screen, updated_window_id
                else:
                    self.console.print(f"[yellow]‚ö†Ô∏è Found window ID but couldn't get info on attempt {attempt+1}[/yellow]")
            else:
                self.console.print(f"[yellow]‚ö†Ô∏è Could not re-find window by title on attempt {attempt+1}[/yellow]")
            
            # Strategy 2: Try using the hwnd directly with Windows API
            try:
                import win32gui
                if win32gui.IsWindow(hwnd):
                    rect = win32gui.GetWindowRect(hwnd)
                    pos = {'x': rect[0], 'y': rect[1]}
                    size = {'width': rect[2] - rect[0], 'height': rect[3] - rect[1]}
                    
                    self.console.print(f"[cyan]üîß Direct hwnd query: ({pos['x']}, {pos['y']}) size {size['width']}√ó{size['height']}[/cyan]")
                    
                    actual_screen = self._detect_window_screen_using_screen_manager(pos, size)
                    
                    if actual_screen == expected_screen:
                        self.console.print(f"[green]üéØ SUCCESS: Direct hwnd confirms Screen {expected_screen}[/green]")
                        return expected_screen, updated_window_id
                    else:
                        self.console.print(f"[yellow]üîß Direct hwnd shows Screen {actual_screen}[/yellow]")
                        # If this is consistent, trust it
                        if attempt >= 1:
                            return actual_screen, updated_window_id
            except Exception as e:
                self.console.print(f"[yellow]‚ö†Ô∏è Direct hwnd query failed: {e}[/yellow]")
            
            if attempt < 4:  # Don't wait on last attempt
                time.sleep(1)
        
        # Final fallback: assume the move worked
        self.console.print(f"[yellow]üéØ Fallback: Assuming operations succeeded - Screen {expected_screen}[/yellow]")
        return expected_screen, updated_window_id
    
    def take_initial_screenshot(self) -> Optional[str]:
        """
        Take initial screenshot for fDOM exploration - APP WINDOW ONLY
        ENHANCED: Force refresh window coordinates after maximization
        """
        if not self.current_app_info:
            self.console.print("[red]‚ùå No app launched for screenshot[/red]")
            return None

        self.console.print("[yellow]üì∏ Taking initial screenshot (S001) - APP WINDOW ONLY...[/yellow]")
        
        # ‚úÖ CRITICAL FIX: Wait for maximization to complete and refresh coordinates
        self.console.print("[yellow]‚è≥ Waiting for window animation to complete...[/yellow]")
        time.sleep(2)  # Allow maximization animation to complete
        
        # ‚úÖ FORCE REFRESH: Get fresh window coordinates after maximization
        self.console.print("[yellow]üîÑ Refreshing window coordinates after maximization...[/yellow]")
        
        try:
            window_id = self.current_app_info["window_id"]
            
            # Force complete refresh of window API
            self.gui_api.refresh()
            time.sleep(0.5)
            
            # Get fresh window info (this should have post-maximization coordinates)
            window_info = self.gui_api.get_window_info(window_id)
            
            if not window_info:
                # FALLBACK: Try to re-find window by app name
                self.console.print("[yellow]üîÑ Window lookup failed, attempting recovery...[/yellow]")
                
                app_name = Path(self.current_app_info["executable_path"]).stem.lower()
                new_window_id = self.gui_api.find_window(app_name)
                
                if new_window_id:
                    self.console.print(f"[green]‚úÖ Re-found window with new ID: {new_window_id}[/green]")
                    self.current_app_info["window_id"] = new_window_id
                    window_info = self.gui_api.get_window_info(new_window_id)
            
            if window_info:
                pos = window_info['window_data']['position']
                size = window_info['window_data']['size']
                
                # ‚úÖ DEBUG: Show what we detected
                self.console.print(f"[cyan]üîç CURRENT window state (post-maximization):[/cyan]")
                self.console.print(f"   Window ID: {window_id}")
                self.console.print(f"   Position: ({pos['x']}, {pos['y']})")
                self.console.print(f"   Size: {size['width']}√ó{size['height']}")
                
                # ‚úÖ VALIDATION: Check if size looks like maximized on 1920√ó1080 screen
                expected_width = 1920
                expected_height = 1080
                
                if abs(size['width'] - expected_width) > 100 or abs(size['height'] - expected_height) > 100:
                    self.console.print(f"[yellow]‚ö†Ô∏è Window size {size['width']}√ó{size['height']} doesn't look maximized for 1920√ó1080 screen[/yellow]")
                    self.console.print(f"[yellow]   Expected ~{expected_width}√ó{expected_height}[/yellow]")
                    
                    # Try using direct hwnd method as it might be more reliable
                    return self._take_hwnd_direct_screenshot()
                else:
                    self.console.print(f"[green]‚úÖ Window appears maximized on Monitor 1[/green]")
                
                # ‚úÖ ENHANCED VALIDATION: Check coordinates are reasonable for Monitor 1 (2560-4480)
                monitor_1_left = 2560
                monitor_1_right = 4480
                
                if not (monitor_1_left - 50 <= pos['x'] <= monitor_1_right + 50):
                    self.console.print(f"[yellow]‚ö†Ô∏è Window X position {pos['x']} outside Monitor 1 range ({monitor_1_left}-{monitor_1_right})[/yellow]")
                    return self._take_hwnd_direct_screenshot()
                
                # Create bounding box for window
                window_bbox = {
                    'left': pos['x'],
                    'top': pos['y'], 
                    'width': size['width'],
                    'height': size['height']
                }
                
                # ‚úÖ TESTING: Try a small test capture first
                self.console.print(f"[cyan]üß™ Testing maximized window capture: {window_bbox}[/cyan]")
                
                import mss
                with mss.mss() as sct:
                    # Test capture of small region (top-left corner)
                    test_bbox = {
                        'left': pos['x'],
                        'top': pos['y'],
                        'width': min(200, size['width']),
                        'height': min(200, size['height'])
                    }
                    
                    test_screenshot = sct.grab(test_bbox)
                    
                    # Analyze test image for content
                    from PIL import Image
                    test_img = Image.frombytes('RGB', test_screenshot.size, test_screenshot.bgra, 'raw', 'BGRX')
                    
                    # Convert to grayscale and check for content
                    import numpy as np
                    test_array = np.array(test_img.convert('L'))
                    content_pixels = np.sum(test_array > 240)  # Count non-white pixels
                    total_pixels = test_array.size
                    content_ratio = content_pixels / total_pixels
                    
                    self.console.print(f"[cyan]üìä Content analysis:[/cyan]")
                    self.console.print(f"   Content pixels: {content_ratio:.2%}")
                    
                    # Save test image for debugging
                    test_path = self.current_app_info["folder_paths"]["screenshots"] / "test_capture.png"
                    test_img.save(test_path)
                    self.console.print(f"[cyan]üîç Test image saved: {test_path}[/cyan]")
                    
                    if content_ratio < 0.01:  # Less than 1% content
                        self.console.print(f"[yellow]‚ùå Test capture shows minimal content[/yellow]")
                        return self._take_fallback_screen_capture()
                    
                    # Capture full window
                    self.console.print(f"[green]‚úÖ Test capture looks good, proceeding with full capture[/green]")
                    window_screenshot = sct.grab(window_bbox)
                    
                    # Convert to PIL Image
                    img = Image.frombytes('RGB', window_screenshot.size, window_screenshot.bgra, 'raw', 'BGRX')
                    
                    # Save screenshot as S001.png
                    screenshots_dir = self.current_app_info["folder_paths"]["screenshots"]
                    screenshot_path = screenshots_dir / "S001.png"
                    img.save(screenshot_path)
                    
                    # Calculate file size
                    file_size = screenshot_path.stat().st_size / (1024 * 1024)
                    
                    self.console.print(f"[green]‚úÖ App-only screenshot saved: {screenshot_path.name} ({file_size:.2f} MB)[/green]")
                    self.console.print(f"[cyan]üìç Screenshot path:[/cyan] {screenshot_path}")
                    self.console.print(f"[cyan]üéØ Captured area:[/cyan] {window_bbox['width']}√ó{window_bbox['height']} pixels from app window")
                    
                    return str(screenshot_path)
            else:
                # Fallback to direct hwnd method
                return self._take_hwnd_direct_screenshot()

        except Exception as e:
            self.console.print(f"[red]‚ùå Error taking app screenshot: {e}[/red]")
            return self._take_fallback_screen_capture()

    def _take_hwnd_direct_screenshot(self) -> Optional[str]:
        """
        Direct hwnd-based screenshot when normal lookup fails
        """
        self.console.print("[yellow]üîß Using direct hwnd screenshot method...[/yellow]")
        
        try:
            # We need to get the hwnd from somewhere - let's search for the window
            import win32gui
            import win32con
            
            app_name = Path(self.current_app_info["executable_path"]).stem.lower()
            
            # Find window by title using Windows API directly
            hwnd = None
            def enum_windows_callback(window_hwnd, lParam):
                nonlocal hwnd
                if win32gui.IsWindowVisible(window_hwnd):
                    window_title = win32gui.GetWindowText(window_hwnd).lower()
                    if app_name in window_title:
                        hwnd = window_hwnd
                        return False  # Stop enumeration
                return True
            
            win32gui.EnumWindows(enum_windows_callback, 0)
            
            if hwnd:
                rect = win32gui.GetWindowRect(hwnd)
                self.console.print(f"[green]‚úÖ Direct hwnd found: {hwnd} at {rect}[/green]")
                
                # Create bounding box
                window_bbox = {
                    'left': rect[0],
                    'top': rect[1], 
                    'width': rect[2] - rect[0],
                    'height': rect[3] - rect[1]
                }
                
                # Capture using mss
                import mss
                with mss.mss() as sct:
                    window_screenshot = sct.grab(window_bbox)
                    
                    from PIL import Image
                    img = Image.frombytes('RGB', window_screenshot.size, window_screenshot.bgra, 'raw', 'BGRX')
                    
                    screenshots_dir = self.current_app_info["folder_paths"]["screenshots"]
                    screenshot_path = screenshots_dir / "S001.png"
                    img.save(screenshot_path)
                    
                    file_size = screenshot_path.stat().st_size / (1024 * 1024)
                    
                    self.console.print(f"[green]‚úÖ Direct hwnd screenshot saved: {screenshot_path.name} ({file_size:.1f} MB)[/green]")
                    return str(screenshot_path)
            else:
                self.console.print("[red]‚ùå Could not find window via direct hwnd search[/red]")
                return self._take_fallback_screen_capture()
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Direct hwnd screenshot failed: {e}[/red]")
            return self._take_fallback_screen_capture()

    def _take_fallback_screen_capture(self) -> Optional[str]:
        """
        Fallback: Take full screen capture of target screen
        """
        self.console.print("[yellow]üîÑ Using fallback: Full screen capture[/yellow]")
        
        try:
            target_screen = self.current_app_info["target_screen"]
            screenshot_array = self.screen_manager.capture_screen(target_screen)
            
            if screenshot_array is None:
                self.console.print("[red]‚ùå Fallback screen capture also failed[/red]")
                return None
            
            # Save screenshot as S001.png
            screenshots_dir = self.current_app_info["folder_paths"]["screenshots"]
            screenshot_path = screenshots_dir / "S001.png"
            
            # Convert BGR to RGB for PIL
            from PIL import Image
            screenshot_rgb = screenshot_array  # Already in correct format for PIL
            img = Image.fromarray(screenshot_rgb)
            img.save(screenshot_path)
            
            # Calculate file size
            file_size = screenshot_path.stat().st_size / (1024 * 1024)
            
            self.console.print(f"[green]‚úÖ Fallback screenshot saved: {screenshot_path.name} ({file_size:.1f} MB)[/green]")
            self.console.print(f"[yellow]‚ö†Ô∏è Note: This is a full screen capture, not app-only[/yellow]")
            
            return str(screenshot_path)
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Fallback capture failed: {e}[/red]")
            return None
    
    def get_app_info_summary(self) -> None:
        """Display comprehensive app information summary"""
        if not self.current_app_info:
            self.console.print("[red]‚ùå No app information available[/red]")
            return
        
        app_info = self.current_app_info
        
        # Create summary table
        table = Table(title="üì± Application Information", show_header=True, header_style="bold magenta")
        table.add_column("Property", style="cyan", width=20)
        table.add_column("Value", style="white", width=50)
        
        table.add_row("App Name", app_info["app_name"])
        table.add_row("Executable", app_info["executable_path"])
        table.add_row("Window ID", app_info["window_id"])
        table.add_row("Target Screen", str(app_info["target_screen"]))
        table.add_row("Process ID", str(app_info["process_id"]))
        
        # Add folder paths - FIXED: Handle path display correctly
        for name, path in app_info["folder_paths"].items():
            if name != "app_dir":
                try:
                    # Try to show relative to apps base directory
                    if hasattr(self, 'apps_base_dir'):
                        relative_path = path.relative_to(self.apps_base_dir)
                        display_path = f"apps/{relative_path}"
                    else:
                        # Fallback: show relative to project root by going up from current dir
                        project_root = Path.cwd().parent  # utils -> project root
                        relative_path = path.relative_to(project_root)
                        display_path = str(relative_path)
                except ValueError:
                    # Final fallback: show absolute path
                    display_path = str(path)
                
                table.add_row(f"{name.title()} Dir", display_path)
        
        self.console.print(table)
        
        # Show window state
        window_info = self.gui_api.get_window_info(app_info["window_id"])
        if window_info:
            state = self.gui_api.get_window_state(app_info["window_id"])
            pos = window_info['window_data']['position']
            size = window_info['window_data']['size']
            
            panel = Panel(
                f"State: {state.upper()}\nPosition: ({pos['x']}, {pos['y']})\nSize: {size['width']}√ó{size['height']} pixels",
                title="[bold green]ü™ü Window Status[/bold green]",
                border_style="green"
            )
            self.console.print(panel)

    def _detect_window_screen_using_screen_manager(self, window_pos: Dict, window_size: Dict) -> int:
        """
        Detect which screen a window is on using screen_manager's screen data
        """
        window_center_x = window_pos['x'] + window_size['width'] // 2
        window_center_y = window_pos['y'] + window_size['height'] // 2
        
        self.console.print(f"[cyan]üîç Window center: ({window_center_x}, {window_center_y})[/cyan]")
        
        # Check which screen contains the window center using screen_manager data
        for screen in self.screen_manager.screens:
            screen_bounds = f"({screen['left']}, {screen['top']}) to ({screen['right']}, {screen['bottom']})"
            self.console.print(f"[cyan]üì∫ Screen {screen['id']}: {screen_bounds}[/cyan]")
            
            if (screen['left'] <= window_center_x < screen['right'] and 
                screen['top'] <= window_center_y < screen['bottom']):
                self.console.print(f"[green]‚úÖ Window center is on Screen {screen['id']}[/green]")
                return screen['id']
        
        # Fallback: return Screen 1 (TEST SCREEN)
        self.console.print(f"[yellow]‚ö†Ô∏è Window center not found in any screen, defaulting to Screen 1[/yellow]")
        return 1


def test_app_controller():
    """Test function for AppController - DELTA 3 testing"""
    console = Console()
    
    console.print("\n[bold green]üöÄ DELTA 3: AppController Test[/bold green]")
    console.print("=" * 50)
    
    try:
        # Import previous deltas
        from config_manager import ConfigManager
        from screen_manager import ScreenManager
        
        # Test 1: Initialize components
        console.print("[yellow]üîß Initializing components...[/yellow]")
        config_manager = ConfigManager()
        screen_manager = ScreenManager(config_manager)
        app_controller = AppController(config_manager, screen_manager)
        console.print("[green]‚úÖ All components initialized[/green]")
        
        # Test 2: Get test executable
        console.print("\n[yellow]üîç Finding test executable...[/yellow]")
        test_exe = "notepad.exe"  # Windows built-in
        
        # Try to find notepad in system
        import shutil
        notepad_path = shutil.which(test_exe)
        
        if not notepad_path:
            console.print(f"[red]‚ùå {test_exe} not found in PATH[/red]")
            console.print("[yellow]üí° Please run: python app_controller.py --test-launch C:\\path\\to\\your\\app.exe[/yellow]")
            return False
        
        console.print(f"[green]‚úÖ Found executable:[/green] {notepad_path}")
        
        # Test 3: Screen selection for app
        if screen_manager.screens:
            selected_screen = screen_manager.screens[0]['id']  # Use second screen for test
            console.print(f"[cyan]üñ•Ô∏è Using screen {selected_screen} for test[/cyan]")
        else:
            console.print("[red]‚ùå No screens available[/red]")
            return False
        
        # Test 4: Launch application
        console.print(f"\n[yellow]üöÄ Testing app launch...[/yellow]")
        launch_result = app_controller.launch_app()
        
        if not launch_result["success"]:
            console.print(f"[red]‚ùå App launch failed: {launch_result.get('error', 'Unknown error')}[/red]")
            return False
        
        console.print("[green]‚úÖ App launched successfully[/green]")
        
        # Test 5: Take initial screenshot
        console.print("\n[yellow]üì∏ Testing initial screenshot...[/yellow]")
        screenshot_path = app_controller.take_initial_screenshot()
        
        if not screenshot_path:
            console.print("[red]‚ùå Screenshot failed[/red]")
            return False
        
        console.print(f"[green]‚úÖ Screenshot saved:[/green] {screenshot_path}")
        
        # Test 6: Display app information
        console.print("\n[yellow]üìã App Information Summary[/yellow]")
        app_controller.get_app_info_summary()
        
        # Test 7: Clean up - close the app
        console.print("\n[yellow]üßπ Cleaning up (closing app)...[/yellow]")
        if app_controller.current_app_info:
            window_id = app_controller.current_app_info["window_id"]
            if app_controller.gui_api.close_window(window_id):
                console.print("[green]‚úÖ App closed successfully[/green]")
            else:
                console.print("[yellow]‚ö†Ô∏è App may still be running[/yellow]")
        
        console.print("\n[bold green]üéâ DELTA 3 PASSED: AppController is ready![/bold green]")
        return True
        
    except Exception as e:
        console.print(f"\n[bold red]üí• DELTA 3 FAILED: {e}[/bold red]")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="fDOM AppController - Delta 3 Testing")
    parser.add_argument("--test-launch", type=str, help="Test launch with specific executable")
    parser.add_argument("--auto-test", action="store_true", help="Auto test with notepad.exe")
    
    args = parser.parse_args()
    
    if args.test_launch:
        # Test with custom executable
        from config_manager import ConfigManager
        from screen_manager import ScreenManager
        
        config = ConfigManager()
        screen_manager = ScreenManager(config)
        app_controller = AppController(args.test_launch, config=config)
        
        # Select screen interactively
        selected = screen_manager.prompt_user_selection()
        if selected:
            result = app_controller.launch_app()
            if result["success"]:
                screenshot = app_controller.take_initial_screenshot()
                app_controller.get_app_info_summary()
                
    elif args.auto_test:
        success = test_app_controller()
        exit(0 if success else 1)
    else:
        print("Usage: python app_controller.py --auto-test")
        print("       python app_controller.py --test-launch C:\\path\\to\\app.exe")


==================================================

Path: utils\fdom\auto_captioner.py
File: auto_captioner.py
Code:
"""
Auto Captioner - Automatically discover tooltips/captions by hovering over elements
Uses SendInput to bypass Windows 10 SetCursorPos bug for proper hover events
Extended with Seraphine Pipeline integration for Gemini analysis
"""
import time
import ctypes
import os
import asyncio
from pathlib import Path
from ctypes import wintypes
from typing import Dict, List, Optional, Tuple
from rich.console import Console
from rich.progress import Progress
from datetime import datetime
from PIL import Image, ImageDraw, ImageFont
import io
import json

from .screenshot_manager import ScreenshotManager
from .visual_differ import VisualDiffer


class AutoCaptioner:
    """Automatically discover element captions by hovering and visual comparison"""
    
    def __init__(self, element_interactor):
        self.element_interactor = element_interactor
        self.app_controller = element_interactor.app_controller
        self.visual_differ = element_interactor.visual_differ
        self.console = Console()
        self.screenshot_manager = ScreenshotManager(self.app_controller, self.visual_differ, debug_mode=False)
        
        # DISABLE CONSOLE OUTPUT FOR SCREENSHOT MANAGER AND VISUAL DIFFER
        # Create a UTF-8 compatible null stream
        null_stream = io.StringIO()
        null_console = Console(file=null_stream, force_terminal=False)
        
        self.screenshot_manager.console = null_console
        self.visual_differ.console = null_console
        
        # Setup paths
        self.app_info = self.app_controller.current_app_info
        self.captions_dir = self.app_info["folder_paths"]["app_dir"] / "captions"
        self.captions_dir.mkdir(exist_ok=True)
        
        # Settings
        self.hover_wait_time = 3
        
        # Track our temporary files for cleanup
        self.temp_files = []
        
        # FDOM path
        self.fdom_path = self.app_info["folder_paths"]["app_dir"] / "fdom.json"
        
        # NEW: Track processing batch and results  
        self.ordered_node_ids = []  # Preserve order from discovered_captions
        self.processed_nodes = []   # All nodes in this batch (for marking as done)
        self.gemini_results = {}    # Store gemini results for fdom update
        
    def discover_all_captions(self, pending_list: List[str]) -> Dict[str, str]:
        """Main function: Discover captions for all pending elements and analyze with Gemini"""
        
        # Debug: Show what we're starting with
        self.console.print(f"[yellow]üîç DEBUG: Input pending_list: {pending_list[:5]}...[/yellow]")
        
        # ‚úÖ ENHANCED FILTERING: Filter out HL nodes AND already processed nodes
        filtered_list = []
        skipped_hl_nodes = []
        skipped_done_nodes = []
        
        for node_id in pending_list:
            # Handle both simple node IDs and state::node_id format
            actual_node_id = node_id.split("::")[-1] if "::" in node_id else node_id
            
            # Skip HL nodes
            if actual_node_id.startswith('HL'):
                skipped_hl_nodes.append(node_id)
                continue
            
            # ‚úÖ NEW: Skip nodes that already have autocaptioning done
            if self._is_node_already_processed(node_id):
                skipped_done_nodes.append(node_id)
                continue
            
            filtered_list.append(node_id)
        
        # Report filtering results
        if skipped_hl_nodes:
            self.console.print(f"[yellow]‚ö†Ô∏è Skipped {len(skipped_hl_nodes)} HL nodes[/yellow]")
        if skipped_done_nodes:
            self.console.print(f"[yellow]‚ö†Ô∏è Skipped {len(skipped_done_nodes)} already processed nodes[/yellow]")
        
        # ‚úÖ BACK TO WORKING VERSION: Sort by distance from trigger, prioritizing current state
        sorted_list = self._sort_nodes_by_distance_from_trigger(filtered_list)
        
        self.console.print(f"\n[bold green]üîç AUTO CAPTIONER - Starting Discovery[/bold green]")
        self.console.print(f"[cyan]üìä Elements to process: {len(sorted_list)} (filtered from {len(pending_list)})[/cyan]")
        
        # Use sorted list instead of original pending_list
        if not sorted_list:
            self.console.print("[yellow]‚ö†Ô∏è No elements to process after filtering[/yellow]")
            return {}
        
        # Take global "before" screenshot
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        before_screenshot = self.screenshot_manager.take_screenshot(f"auto_caption_before_{timestamp}")
        self.temp_files.append(before_screenshot)
        
        if not before_screenshot:
            return {}
        
        # ‚úÖ DYNAMIC EXPLORATION: Process elements with dynamic distance calculation
        discovered_captions = {}
        self.processed_nodes = pending_list.copy()
        
        # Track current position for dynamic distance calculation
        current_state_id = self.element_interactor.current_state_id
        fdom_data = self.element_interactor.state_manager.fdom_data
        current_state_data = fdom_data.get("states", {}).get(current_state_id, {})
        trigger_node = current_state_data.get("trigger_node")
        
        # ‚úÖ ENHANCED: Initialize with trigger node corners
        if trigger_node:
            trigger_bbox = self._get_node_bbox(trigger_node)
            if trigger_bbox:
                self.current_corners = self._get_element_corners(trigger_bbox)
                center_coords = self._get_node_center_coordinates(trigger_node)
                self.current_hover_position = center_coords
            else:
                self.current_hover_position = None
                self.current_corners = []
        else:
            self.current_hover_position = None
            self.current_corners = []
        
        with Progress() as progress:
            task = progress.add_task("[cyan]Discovering captions...", total=len(sorted_list))
            
            # ‚úÖ DYNAMIC: Update remaining list after each hover
            remaining_nodes = sorted_list.copy()
            
            for i in range(len(sorted_list)):
                if not remaining_nodes:
                    break
                
                # ‚úÖ FIND NEXT: Always find closest to current position from remaining nodes
                next_node = self._find_closest_current_state_node(remaining_nodes)
                
                if not next_node:
                    # No more current state nodes, pick first remaining
                    next_node = remaining_nodes[0]
                
                remaining_nodes.remove(next_node)
                
                caption_result = self._discover_single_caption(next_node, before_screenshot, i+1, len(sorted_list))
                
                if caption_result:
                    discovered_captions[next_node] = caption_result
                
                # ‚úÖ UPDATE: Current position after hover
                self._update_current_hover_position(next_node)
                
                progress.update(task, advance=1)
        
        # Store the order for mapping (use sorted order)
        self.ordered_node_ids = list(discovered_captions.keys())
        
        # ü§ñ Seraphine Pipeline Analysis
        if discovered_captions:
            self.console.print(f"\n[bold cyan]ü§ñ Sending to Seraphine - Analyzing {len(discovered_captions)} captions with Gemini[/bold cyan]")
            asyncio.run(self._analyze_captions_with_seraphine(discovered_captions))
            
            # NOW add caption files to cleanup list AFTER Gemini analysis is complete
            for caption_path in discovered_captions.values():
                self.temp_files.append(caption_path)
        
        # üîÑ NEW: UPDATE FDOM with results
        self._update_fdom_with_results()
        
        # üßπ CLEANUP: Delete all temporary files
        self._cleanup_temp_files()
        self._cleanup_seraphine_files()
        
        # Summary
        self.console.print(f"\n[bold green]‚úÖ AUTO CAPTIONER COMPLETE[/bold green]")
        
        return discovered_captions
    
    async def _analyze_captions_with_seraphine(self, discovered_captions: Dict[str, str]) -> None:
        """Analyze discovered caption images using PROPER seraphine pipeline infrastructure"""
        try:
            # üî• CREATE FAKE DETECTION DATA FOR SERAPHINE
            fake_detections = self._create_fake_detections_for_captions(discovered_captions)
            
            # üî• USE SERAPHINE PROCESSOR TO CREATE PROPER IMAGES
            from utils.seraphine_pipeline.seraphine_processor import FinalSeraphineProcessor
            
            # Create processor with proper parameters
            processor = FinalSeraphineProcessor(enable_timing=False, enable_debug=False)
            
            # Process the fake detections (creates groups, final_groups, etc.)
            seraphine_analysis = processor.process_detections(fake_detections)
            
            # Create a dummy image (we'll replace the crops with our caption images)
            dummy_image_path = self._create_dummy_background_image()
            
            # üî• REPLACE BBOX PROCESSOR CROPS WITH OUR CAPTION IMAGES
            bbox_processor = seraphine_analysis['bbox_processor']
            self._inject_caption_images_into_processor(bbox_processor, discovered_captions)
            
            # üî• USE SERAPHINE'S IMAGE GENERATOR (1280x1280, proper layout, lightgray borders, labels)
            from utils.seraphine_pipeline.seraphine_generator import FinalGroupImageGenerator
            
            generator = FinalGroupImageGenerator(
                output_dir=str(self.captions_dir),
                save_mapping=False,
                enable_debug=False
            )
            
            # Generate properly formatted seraphine images
            result = generator.create_grouped_images(
                image_path=dummy_image_path,
                seraphine_analysis=seraphine_analysis,
                filename_base="caption_analysis",
                return_direct_images=True
            )
            
            # üîß FIX: Check if any images have "combined" in the name
            combined_images = [(img, filename) for img, filename in result['direct_images'] if "combined" in filename]
            
            if not combined_images:
                return
            
            # üî• USE SERAPHINE'S GEMINI ANALYZER
            from utils.seraphine_pipeline.gemini_analyzer import GeminiIconAnalyzer
            
            analyzer = GeminiIconAnalyzer(
                prompt_path=None,  # Use default prompt
                output_dir=str(self.captions_dir),
                max_concurrent_requests=1,
                save_results=False
            )
            
            # Use only the combined images
            gemini_results = await analyzer.analyze_grouped_images(
                grouped_image_paths=None,
                filename_base="caption_analysis",
                direct_images=combined_images  # Only send combined images
            )
            
            # üîß NEW: Process Gemini results and map back to original fdom IDs
            self._process_gemini_results(gemini_results, discovered_captions)
            
            # Display results
            self._display_gemini_caption_results(gemini_results, discovered_captions)
            
            # üßπ IMMEDIATE CLEANUP: Add dummy file to cleanup list right after Gemini is done
            self.temp_files.append(dummy_image_path)
            
        except Exception as e:
            pass
    
    def _create_fake_detections_for_captions(self, discovered_captions: Dict[str, str]) -> Dict:
        """Create fake detection data that seraphine can process"""
        fake_detections = []
        
        for i, (node_id, caption_path) in enumerate(discovered_captions.items()):
            if os.path.exists(caption_path):
                # Get image dimensions
                from PIL import Image
                with Image.open(caption_path) as img:
                    width, height = img.size
                
                # Create fake detection with proper structure for VERTICAL grouping
                # Spread them out vertically so they get grouped into V0, V1, V2...
                fake_y_position = i * 100  # Space them out vertically
                
                fake_detection = {
                    'bbox': [10, fake_y_position, 10 + width, fake_y_position + height],
                    'id': i + 1,
                    'merged_id': i + 1,
                    'type': 'text',  # Caption is text
                    'source': 'caption',
                    'confidence': 1.0,
                    'explore': True,  # NEW: Force explore=True for auto-captioner
                }
                fake_detections.append(fake_detection)
        
        # Create fake detection results structure (matching expected format)
        return fake_detections  # Just return the list, not the dict!
    
    def _create_dummy_background_image(self) -> str:
        """Create a dummy white background image for seraphine"""
        from PIL import Image
        
        # Create white background
        dummy_image = Image.new('RGB', (1280, 1280), 'white')
        
        # Save it
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        dummy_path = str(self.captions_dir / f"dummy_background_{timestamp}.png")
        dummy_image.save(dummy_path)
        
        # EXPLICITLY close the image to release file handle
        dummy_image.close()
        
        return dummy_path
    
    def _inject_caption_images_into_processor(self, bbox_processor, discovered_captions: Dict[str, str]) -> None:
        """Replace bbox processor's crop method to return our caption images"""
        
        # Create mapping from merged_id to caption path
        caption_mapping = {}
        for i, (node_id, caption_path) in enumerate(discovered_captions.items()):
            caption_mapping[i + 1] = caption_path  # merged_id starts from 1
        
        # Store original method
        original_crop_method = bbox_processor.crop_bbox_from_image
        
        # Create our replacement method
        def custom_crop_bbox_from_image(bbox):
            """Custom crop method that returns our caption images"""
            merged_id = bbox.merged_id
            if merged_id in caption_mapping:
                caption_path = caption_mapping[merged_id]
                if os.path.exists(caption_path):
                    from PIL import Image
                    return Image.open(caption_path)
            
            # Fallback to original method
            return original_crop_method(bbox)
        
        # Replace the method
        bbox_processor.crop_bbox_from_image = custom_crop_bbox_from_image
    
    def _display_gemini_caption_results(self, results: Dict, discovered_captions: Dict[str, str]) -> None:
        """Display Gemini analysis results for captions"""
        if not results or not results.get('images'):
            return
        
        self.console.print(f"\n[bold green]ü§ñ FOUND CAPTIONS[/bold green]")
        
        total_analyzed = 0
        for image_result in results['images']:
            if image_result['analysis_success'] and image_result.get('icons'):
                for icon in image_result['icons']:
                    # Show only top 4 results
                    if total_analyzed >= 4:
                        break
                        
                    icon_id = icon.get('id', 'unknown')
                    icon_name = icon.get('name', 'unknown')
                    usage = icon.get('usage', 'No description')
                    
                    # self.console.print(f"[cyan]üìù {icon_id}:[/cyan] [bold]{icon_name}[/bold]")
                    # self.console.print(f"    üí¨ {usage}")
                    # self.console.print()
                    total_analyzed += 1
                    
                if total_analyzed >= 4:
                    break
            
            if total_analyzed >= 4:
                break
    
    def _cleanup_temp_files(self) -> None:
        """Clean up all temporary files created during the session"""
        if not self.temp_files:
            return
        
        self.console.print(f"\n[yellow]üßπ Deleting {len(self.temp_files)} temporary files...[/yellow]")
        
        # Force garbage collection to release any file handles
        import gc
        gc.collect()
        
        # Add delay to ensure file handles are released
        time.sleep(0.3)
        
        cleaned_count = 0
        for temp_file in self.temp_files:
            try:
                if temp_file and os.path.exists(temp_file):
                    # Try multiple times with delays if file is locked
                    for attempt in range(3):
                        try:
                            os.remove(temp_file)
                            cleaned_count += 1
                            break
                        except PermissionError:
                            if attempt < 2:  # Not the last attempt
                                time.sleep(0.2)
                                gc.collect()
                            else:
                                # If still locked after 3 attempts, skip it
                                pass
            except Exception:
                pass
        
        self.temp_files.clear()
    
    def _cleanup_seraphine_files(self) -> None:
        """Clean up seraphine-generated files in captions directory"""
        try:
            # Force garbage collection to release any file handles
            import gc
            gc.collect()
            
            # Add delay to ensure file handles are released
            time.sleep(0.5)
            
            seraphine_patterns = [
                "combined_groups_*.png",
                "caption_analysis_*.png", 
                "dummy_background_*.png"
            ]
            
            import glob
            files_deleted = 0
            
            for pattern in seraphine_patterns:
                pattern_path = str(self.captions_dir / pattern)
                for file_path in glob.glob(pattern_path):
                    try:
                        if os.path.exists(file_path):
                            # Try multiple times with delays if file is locked
                            for attempt in range(5):  # More attempts for stubborn files
                                try:
                                    os.remove(file_path)
                                    files_deleted += 1
                                    break
                                except PermissionError:
                                    if attempt < 4:  # Not the last attempt
                                        time.sleep(0.3)
                                        gc.collect()
                                    else:
                                        # If still locked after 5 attempts, skip it
                                        pass
                    except Exception:
                        pass
            
            if files_deleted > 0:
                self.console.print(f"[yellow]üßπ Cleaned up {files_deleted} seraphine files[/yellow]")
                
        except Exception:
            pass
    
    def _send_input_hover(self, abs_x: int, abs_y: int, element_name: str) -> bool:
        """Send actual WM_MOUSEMOVE messages using SendInput to trigger hover events"""
        try:
            # Get current position
            current_pos = self.app_controller.gui_api.get_cursor_position()
            start_x, start_y = current_pos if current_pos else (abs_x - 50, abs_y - 20)
            
            # Define Windows structures
            class MOUSEINPUT(ctypes.Structure):
                _fields_ = [
                    ("dx", ctypes.c_long),
                    ("dy", ctypes.c_long),
                    ("mouseData", wintypes.DWORD),
                    ("dwFlags", wintypes.DWORD),
                    ("time", wintypes.DWORD),
                    ("dwExtraInfo", ctypes.POINTER(wintypes.ULONG))
                ]
            
            class INPUT(ctypes.Structure):
                class _INPUT(ctypes.Union):
                    _fields_ = [("mi", MOUSEINPUT)]
                _anonymous_ = ("_input",)
                _fields_ = [
                    ("type", wintypes.DWORD),
                    ("_input", _INPUT)
                ]
            
            user32 = ctypes.windll.user32
            
            # Get screen dimensions
            screen_width = user32.GetSystemMetrics(0)
            screen_height = user32.GetSystemMetrics(1)
            
            # Send smooth movement using SendInput
            steps = 15
            for i in range(steps + 1):
                progress = i / steps
                eased_progress = 1 - (1 - progress) ** 2  # Ease-out
                
                current_x = int(start_x + (abs_x - start_x) * eased_progress)
                current_y = int(start_y + (abs_y - start_y) * eased_progress)
                
                # Convert to SendInput coordinates (0-65535 range)
                input_x = int((current_x * 65535) / screen_width)
                input_y = int((current_y * 65535) / screen_height)
                
                # Create input structure
                inp = INPUT()
                inp.type = 0  # INPUT_MOUSE
                inp.mi.dx = input_x
                inp.mi.dy = input_y
                inp.mi.mouseData = 0
                inp.mi.dwFlags = 0x8001  # MOUSEEVENTF_MOVE + MOUSEEVENTF_ABSOLUTE
                inp.mi.time = 0
                inp.mi.dwExtraInfo = None
                
                # Send the input
                result = user32.SendInput(1, ctypes.byref(inp), ctypes.sizeof(INPUT))
                if result != 1:
                    return False
                
                time.sleep(0.02)
            
            # Hold position for hover duration
            time.sleep(self.hover_wait_time)
            
            return True
            
        except Exception:
            return False
    
    def _discover_single_caption(self, unique_node_id: str, before_screenshot: str, index: int, total: int) -> Optional[str]:
        """Discover caption for a single element"""
        try:
            # Parse node ID
            if "::" in unique_node_id:
                state_name, node_id = unique_node_id.split("::", 1)
            else:
                node_id = unique_node_id
            
            # Find node data
            node_data = self.element_interactor._find_node_in_fdom(unique_node_id)
            if not node_data:
                return None
            
            element_name = node_data.get('g_icon_name', 'unknown')
            bbox = node_data.get('bbox', [])
            
            if not bbox or len(bbox) != 4:
                return None
            
            # ‚úÖ FIX: Calculate hover position 20px from left edge instead of center
            hover_x = bbox[0] + 20  # Left edge + 20px
            hover_y = (bbox[1] + bbox[3]) // 2  # Vertical center
            
            # Get window position
            window_pos = self._get_window_position()
            if not window_pos:
                return None
            
            # Convert to absolute coordinates
            abs_x = window_pos['x'] + hover_x
            abs_y = window_pos['y'] + hover_y
            
            # ‚úÖ DEBUG: Show hover position for first few elements
            if index <= 3:
                self.console.print(f"[cyan]üéØ Hovering on {element_name} at left+20px: ({hover_x}, {hover_y}) ‚Üí abs ({abs_x}, {abs_y})[/cyan]")
            
            # Perform SendInput hover
            hover_success = self._send_input_hover(abs_x, abs_y, element_name)
            if not hover_success:
                return None
            
            # Take after screenshot
            after_screenshot = self.screenshot_manager.take_screenshot(f"auto_caption_after_{node_id}")
            if not after_screenshot:
                return None
            
            self.temp_files.append(after_screenshot)
            
            # Create diff output path
            safe_element_name = element_name.encode('ascii', 'ignore').decode('ascii').replace(' ', '_').replace('¬∞', 'deg')
            crop_filename = f"caption_{node_id}_{safe_element_name}.png"
            diff_output_path = str(self.captions_dir / crop_filename)
            
            # Compare screenshots - use hover position for click_coords
            diff_result = self.visual_differ.extract_change_regions(
                before_screenshot,
                after_screenshot,
                diff_output_path,
                click_coords=(abs_x, abs_y)
            )
            
            # Check results
            if diff_result.get("success", False) and diff_result.get("regions", []):
                return diff_output_path
            else:
                return None
            
        except Exception:
            return None
    
    def _get_window_position(self) -> Optional[Dict]:
        """Get current window position"""
        try:
            window_id = self.app_controller.current_app_info["window_id"]
            window_info = self.app_controller.gui_api.get_window_info(window_id)
            
            if window_info and 'window_data' in window_info and 'position' in window_info['window_data']:
                position = window_info['window_data']['position']
                if 'x' in position and 'y' in position:
                    return position
            
            return None
            
        except Exception:
            return None

    def _create_string_sort_mapping(self, num_items: int) -> Dict[str, int]:
        """Create mapping from string-sorted Gemini IDs back to original order indices"""
        
        # Generate the group IDs seraphine will create: H0, H1, H2, ..., H(num_items-1)
        seraphine_groups = [f"H{i}" for i in range(num_items)]
        
        # Sort them the same way Python/Gemini does (string sort)
        string_sorted_groups = sorted(seraphine_groups)
        
        # Create mapping: string-sorted Gemini ID -> original index
        mapping = {}
        for gemini_index, group_id in enumerate(string_sorted_groups):
            # Extract original index from group ID
            original_index = int(group_id[1:])  # H10 -> 10
            gemini_id = f"{group_id}_1"  # H10_1
            mapping[gemini_id] = original_index
            
            # self.console.print(f"[cyan]üó∫Ô∏è String-sort mapping: {gemini_id} -> original index {original_index}[/cyan]")
        
        return mapping

    def _process_gemini_results(self, gemini_results: Dict, discovered_captions: Dict[str, str]) -> None:
        """Process Gemini results using string-sort-aware mapping"""
        try:
            if not gemini_results or not gemini_results.get('images'):
                self.console.print("[yellow]‚ö†Ô∏è No gemini_results or images found[/yellow]")
                return
            
            # Create string-sort mapping
            num_items = len(self.ordered_node_ids)
            string_sort_mapping = self._create_string_sort_mapping(num_items)
            
            self.console.print(f"[cyan]üîç Processing Gemini results with string-sort compensation[/cyan]")
            self.console.print(f"[cyan]üìä Processing {len(gemini_results['images'])} image results[/cyan]")
            
            total_processed = 0
            for image_result in gemini_results['images']:
                if image_result['analysis_success'] and image_result.get('icons'):
                    self.console.print(f"[green]‚úÖ Image success: {len(image_result['icons'])} icons found[/green]")
                    for icon in image_result['icons']:
                        # Extract Gemini icon ID (H0_1, H1_1, H10_1, etc.)
                        gemini_id = icon.get('id', 'unknown')
                        
                        # Look up original index using string-sort mapping
                        if gemini_id in string_sort_mapping:
                            original_index = string_sort_mapping[gemini_id]
                            
                            # Get original fdom ID using the index
                            if 0 <= original_index < len(self.ordered_node_ids):
                                original_fdom_id = self.ordered_node_ids[original_index]
                                
                                # Store processed result
                                self.gemini_results[original_fdom_id] = {
                                    'icon_name': icon.get('name', ''),
                                    'usage': icon.get('usage', '')
                                }
                                total_processed += 1
                                
                                if total_processed <= 5:  # Show first 5 for debugging
                                    self.console.print(f"[green]‚úÖ String-sort mapped {gemini_id} -> index {original_index} -> {original_fdom_id}: {icon.get('name', 'Unknown')}[/green]")
                            else:
                                self.console.print(f"[yellow]‚ö†Ô∏è Index out of range: {original_index}[/yellow]")
                        else:
                            self.console.print(f"[yellow]‚ö†Ô∏è No string-sort mapping found for Gemini ID: {gemini_id}[/yellow]")
                else:
                    self.console.print(f"[yellow]‚ö†Ô∏è Image failed or no icons: {image_result.get('analysis_success', False)}[/yellow]")
            
            self.console.print(f"[green]‚úÖ Auto-captioner processed {total_processed} Gemini results into self.gemini_results[/green]")
                            
        except Exception as e:
            self.console.print(f"[red]‚ùå Error processing Gemini results: {str(e)}[/red]")
            import traceback
            self.console.print(f"[red]üìã Traceback: {traceback.format_exc()}[/red]")

    def _update_fdom_with_results(self) -> None:
        """Update fdom.json with gemini results and mark all nodes as processed"""
        try:
            # Load current fdom
            if not self.fdom_path.exists():
                self.console.print("[red]‚ùå fdom.json not found![/red]")
                return
            
            with open(self.fdom_path, 'r', encoding='utf-8') as f:
                fdom_data = json.load(f)
            
            updates_made = 0
            gemini_updates_made = 0
            
            self.console.print(f"[cyan]üîÑ Updating fDOM with {len(self.gemini_results)} Gemini results[/cyan]")
            
            # Process all nodes in batch
            for node_id in self.processed_nodes:
                # Parse state and node ID
                if "::" in node_id:
                    state_name, actual_node_id = node_id.split("::", 1)
                else:
                    state_name = "root"
                    actual_node_id = node_id
                
                # Navigate to the node
                if (state_name in fdom_data.get("states", {}) and 
                    actual_node_id in fdom_data["states"][state_name].get("nodes", {})):
                    
                    node_data = fdom_data["states"][state_name]["nodes"][actual_node_id]
                    
                    # Mark as processed (for all nodes, including HL)
                    node_data["autocaptioning"] = "done"
                    updates_made += 1
                    
                    # Update with Gemini results (only for non-HL nodes with results)
                    if node_id in self.gemini_results and not actual_node_id.startswith('HL'):
                        gemini_result = self.gemini_results[node_id]
                        
                        # Update icon name: new + ", " + original
                        original_icon_name = node_data.get("g_icon_name", "")
                        new_icon_name = gemini_result.get("icon_name", "")
                        if new_icon_name:
                            node_data["g_icon_name"] = f"{new_icon_name}, {original_icon_name}"
                            gemini_updates_made += 1
                            
                            if gemini_updates_made <= 3:  # Show first 3 updates
                                self.console.print(f"[green]‚úÖ Updated {actual_node_id}: '{new_icon_name}' + '{original_icon_name}'[/green]")
                        
                        # Update brief: OVERWRITE with new usage
                        new_usage = gemini_result.get("usage", "")
                        if new_usage:
                            node_data["g_brief"] = new_usage  # Direct overwrite, no comma
            
            # Save updated fdom
            if updates_made > 0:
                with open(self.fdom_path, 'w', encoding='utf-8') as f:
                    json.dump(fdom_data, f, indent=2, ensure_ascii=False)
                
                self.element_interactor.state_manager.fdom_data = fdom_data
                self.element_interactor.state_manager._rebuild_tracking_sets()
                self.console.print(f"[green]‚úÖ Updated fdom.json - {updates_made} nodes marked as processed, {gemini_updates_made} got Gemini updates[/green]")
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Failed to update fdom.json: {str(e)}[/red]")
            import traceback
            self.console.print(f"[red]üìã Traceback: {traceback.format_exc()}[/red]")

    def _is_node_already_processed(self, node_id: str) -> bool:
        """Check if node already has autocaptioning done"""
        try:
            # Load current fdom
            if not self.fdom_path.exists():
                return False
            
            with open(self.fdom_path, 'r', encoding='utf-8') as f:
                fdom_data = json.load(f)
            
            # Parse node ID
            if "::" in node_id:
                state_name, actual_node_id = node_id.split("::", 1)
            else:
                state_name = "root"
                actual_node_id = node_id
            
            # Check if node exists and has autocaptioning done
            if (state_name in fdom_data.get("states", {}) and 
                actual_node_id in fdom_data["states"][state_name].get("nodes", {})):
                
                node_data = fdom_data["states"][state_name]["nodes"][actual_node_id]
                return node_data.get("autocaptioning") == "done"
            
            return False
            
        except Exception:
            return False

    def _sort_nodes_by_distance_from_trigger(self, node_list: List[str]) -> List[str]:
        """Sort nodes by distance from trigger, prioritizing current state"""
        try:
            if not node_list:
                return node_list
            
            # Get trigger node as starting point
            current_state_id = self.element_interactor.current_state_id
            fdom_data = self.element_interactor.state_manager.fdom_data
            current_state_data = fdom_data.get("states", {}).get(current_state_id, {})
            trigger_node = current_state_data.get("trigger_node")
            
            if not trigger_node:
                self.console.print(f"[yellow]‚ö†Ô∏è No trigger node - using original order[/yellow]")
                return node_list
            
            # Get starting coordinates (trigger node)
            current_pos = self._get_node_center_coordinates(trigger_node)
            if not current_pos:
                self.console.print(f"[yellow]‚ö†Ô∏è No trigger coordinates - using original order[/yellow]")
                return node_list
            
            current_x, current_y = current_pos
            self.console.print(f"[cyan]üìç Starting enhanced nearest neighbor from trigger {trigger_node} at ({current_x}, {current_y})[/cyan]")
            
            # ‚úÖ PRIORITIZE: Current state elements first, then others
            current_state_nodes = [n for n in node_list if n.startswith(f"{current_state_id}::")]
            other_state_nodes = [n for n in node_list if not n.startswith(f"{current_state_id}::")]
            
            # ‚úÖ ENHANCED: Use 4-corner distance algorithm for current state elements
            current_ordered = self._enhanced_nearest_neighbor_order(current_state_nodes, current_x, current_y)
            
            # ‚úÖ STATIC DISTANCE: Other elements sorted by distance from trigger
            other_ordered = []
            if other_state_nodes:
                other_distances = []
                for node_id in other_state_nodes:
                    node_coords = self._get_node_center_coordinates(node_id)
                    if node_coords:
                        node_x, node_y = node_coords
                        distance = ((node_x - current_x) ** 2 + (node_y - current_y) ** 2) ** 0.5
                        other_distances.append((node_id, distance))
                    else:
                        other_distances.append((node_id, 9999))
                
                other_distances.sort(key=lambda x: x[1])
                other_ordered = [node_id for node_id, _ in other_distances]
            
            # Combine: Current state (enhanced nearest neighbor) + Other states (distance sorted)
            final_order = current_ordered + other_ordered
            
            # Show the exploration path
            self.console.print(f"[green]üéØ Enhanced nearest neighbor exploration path:[/green]")
            if current_ordered:
                self.console.print(f"[green]üìã Current state path ({len(current_ordered)} elements):[/green]")
                for i, node_id in enumerate(current_ordered[:5]):
                    actual_node_id = node_id.split("::")[-1] if "::" in node_id else node_id
                    self.console.print(f"[green]  {i+1}. {actual_node_id}[/green]")
                
                if len(current_ordered) > 5:
                    self.console.print(f"[green]  ... and {len(current_ordered) - 5} more[/green]")
            
            return final_order
            
        except Exception as e:
            self.console.print(f"[yellow]‚ö†Ô∏è Error in enhanced nearest neighbor exploration: {e}[/yellow]")
            return node_list

    def _enhanced_nearest_neighbor_order(self, node_list: List[str], start_x: int, start_y: int) -> List[str]:
        """Enhanced nearest neighbor: considers all 4 corners of each element for optimal pathfinding"""
        if not node_list:
            return []
        
        unvisited = node_list.copy()
        ordered = []
        current_corners = [(start_x, start_y)]  # Start with trigger point
        
        self.console.print(f"[cyan]üîç Starting enhanced pathfinding with {len(node_list)} elements[/cyan]")
        
        while unvisited:
            best_node = None
            best_distance = float('inf')
            best_connection = None  # Store which corners connect
            
            # üéØ FIND MINIMUM: Test all current corners ‚Üí all target corners
            for node_id in unvisited:
                node_bbox = self._get_node_bbox(node_id)
                if not node_bbox:
                    continue
                    
                # Get all 4 corners of candidate element
                target_corners = self._get_element_corners(node_bbox)
                
                # Test all combinations of current corners ‚Üí target corners
                for current_corner in current_corners:
                    for i, target_corner in enumerate(target_corners):
                        distance = self._calculate_distance(current_corner, target_corner)
                        
                        if distance < best_distance:
                            best_distance = distance
                            best_node = node_id
                            corner_names = ["top-left", "top-right", "bottom-left", "bottom-right"]
                            best_connection = (current_corner, target_corner, corner_names[i])
            
            if best_node:
                ordered.append(best_node)
                unvisited.remove(best_node)
                
                # üöÄ UPDATE: Current position is now ALL corners of the selected element
                best_bbox = self._get_node_bbox(best_node)
                if best_bbox:
                    current_corners = self._get_element_corners(best_bbox)
                    
                    # Debug: Show the optimal connection for first few elements
                    if len(ordered) <= 3:
                        actual_node_id = best_node.split("::")[-1] if "::" in best_node else best_node
                        self.console.print(f"[green]üîó {actual_node_id}: {best_connection[0]} ‚Üí {best_connection[1]} ({best_connection[2]}, {best_distance:.1f}px)[/green]")
                else:
                    # Fallback to single point if bbox fails
                    current_corners = [best_connection[1]] if best_connection else [(start_x, start_y)]
        
        return ordered

    def _get_element_corners(self, bbox: List[int]) -> List[Tuple[int, int]]:
        """Get all 4 corners of an element"""
        if len(bbox) != 4:
            return []
        
        x1, y1, x2, y2 = bbox
        
        # Return all 4 corners: top-left, top-right, bottom-left, bottom-right
        corners = [
            (x1, y1),      # Top-left
            (x2, y1),      # Top-right  
            (x1, y2),      # Bottom-left
            (x2, y2)       # Bottom-right
        ]
        
        return corners

    def _get_node_bbox(self, node_id: str) -> Optional[List[int]]:
        """Get the bounding box of a node"""
        try:
            # Handle state::node_id format
            if "::" in node_id:
                state_name, actual_node_id = node_id.split("::", 1)
            else:
                state_name = self.element_interactor.current_state_id
                actual_node_id = node_id
            
            # Get node data from FDOM
            fdom_data = self.element_interactor.state_manager.fdom_data
            state_data = fdom_data.get("states", {}).get(state_name, {})
            nodes = state_data.get("nodes", {})
            
            if actual_node_id not in nodes:
                return None
            
            node_data = nodes[actual_node_id]
            bbox = node_data.get('bbox', [])
            
            # Validate bbox format
            if len(bbox) != 4:
                return None
            
            return bbox
            
        except Exception:
            return None

    def _calculate_distance(self, point1: Tuple[int, int], point2: Tuple[int, int]) -> float:
        """Calculate Euclidean distance between two points"""
        x1, y1 = point1
        x2, y2 = point2
        return ((x2 - x1) ** 2 + (y2 - y1) ** 2) ** 0.5

    def _find_closest_current_state_node(self, remaining_nodes: List[str]) -> Optional[str]:
        """Enhanced: Find closest current state node using 4-corner analysis"""
        if not remaining_nodes or not self.current_hover_position:
            return remaining_nodes[0] if remaining_nodes else None
        
        current_state_id = self.element_interactor.current_state_id
        
        # Filter to current state nodes only
        current_state_nodes = [n for n in remaining_nodes if n.startswith(f"{current_state_id}::")]
        
        if not current_state_nodes:
            # No more current state nodes, return first remaining (other state)
            return remaining_nodes[0]
        
        # ‚úÖ ENHANCED: Use corner-to-corner distance instead of center-to-center
        current_corners = [self.current_hover_position]  # Current position
        
        best_node = None
        best_distance = float('inf')
        
        for node_id in current_state_nodes:
            node_bbox = self._get_node_bbox(node_id)
            if node_bbox:
                target_corners = self._get_element_corners(node_bbox)
                
                # Find minimum distance from current position to any corner of target
                for current_corner in current_corners:
                    for target_corner in target_corners:
                        distance = self._calculate_distance(current_corner, target_corner)
                        
                        if distance < best_distance:
                            best_distance = distance
                            best_node = node_id
        
        return best_node or current_state_nodes[0]

    def _update_current_hover_position(self, node_id: str):
        """Enhanced: Update current hover position to ALL corners of the element"""
        node_bbox = self._get_node_bbox(node_id)
        if node_bbox:
            # Store all corners of current element for next distance calculation
            corners = self._get_element_corners(node_bbox)
            if corners:
                # For simplicity, use center of element as current position
                # But store corners in self.current_corners for enhanced algorithm
                x1, y1, x2, y2 = node_bbox
                center_x = (x1 + x2) // 2
                center_y = (y1 + y2) // 2
                self.current_hover_position = (center_x, center_y)
                
                # Also store corners for enhanced algorithm
                self.current_corners = corners
                
                # Debug for first few elements
                if hasattr(self, '_debug_counter'):
                    self._debug_counter += 1
                else:
                    self._debug_counter = 1
                    
                if self._debug_counter <= 3:
                    actual_node_id = node_id.split("::")[-1] if "::" in node_id else node_id
                    self.console.print(f"[dim]üìç Updated position: {actual_node_id} center={self.current_hover_position}, corners={len(corners)}[/dim]")

    def _get_node_center_coordinates(self, node_id: str) -> Optional[Tuple[int, int]]:
        """Get center coordinates of a node"""
        bbox = self._get_node_bbox(node_id)
        if bbox:
            x1, y1, x2, y2 = bbox
            center_x = (x1 + x2) // 2
            center_y = (y1 + y2) // 2
            return (center_x, center_y)
        return None


==================================================

Path: utils\fdom\click_engine.py
File: click_engine.py
Code:
"""Click execution engine with centroid strategies and verification"""
import time
from typing import Dict, List, Optional, Tuple
from pathlib import Path
from rich.console import Console

from .interaction_types import ClickResult
from .screenshot_manager import ScreenshotManager


class ClickEngine:
    """Handles actual clicking operations with advanced strategies"""
    
    def __init__(self, app_controller, visual_differ, config):
        self.app_controller = app_controller
        self.visual_differ = visual_differ
        self.config = config
        self.console = Console()
        self.screenshot_manager = ScreenshotManager(app_controller, visual_differ)
        
    def execute_click_with_centroids(self, node_data: Dict, window_pos: Dict, 
                                   source_element_name: str) -> ClickResult:
        """Execute 3-centroid clicking strategy with verification"""
        
        # ‚úÖ CRITICAL: Ensure window has focus before clicking
        if not self._ensure_window_has_focus():
            return ClickResult(
                success=False, 
                state_changed=False, 
                error_message="Failed to ensure window focus"
            )
        
        # Calculate adaptive centroids based on element shape
        bbox = node_data['bbox']
        width = bbox[2] - bbox[0]
        height = bbox[3] - bbox[1]
        cx = (bbox[0] + bbox[2]) // 2
        cy = (bbox[1] + bbox[3]) // 2
        
        if width > height:  # Horizontal element
            centroids = [
                (cx, cy),                    # C1: Center
                (cx - width // 4, cy),       # C2: Left-center
                (cx + width // 4, cy)        # C3: Right-center
            ]
            self.console.print(f"[cyan]üìê Horizontal element ({width}x{height}) - using horizontal spread[/cyan]")
        else:  # Vertical element
            centroids = [
                (cx, cy),                    # C1: Center
                (cx, cy - height // 4),      # C2: Upper-center
                (cx, cy + height // 4)       # C3: Lower-center
            ]
            self.console.print(f"[cyan]üìê Vertical element ({width}x{height}) - using vertical spread[/cyan]")
        
        # Convert to absolute coordinates
        abs_centroids = []
        for rel_x, rel_y in centroids:
            abs_x = window_pos['left'] + rel_x
            abs_y = window_pos['top'] + rel_y
            abs_centroids.append((abs_x, abs_y))
        
        self.console.print(f"[cyan]üéØ Centroids: C1{abs_centroids[0]} C2{abs_centroids[1]} C3{abs_centroids[2]}[/cyan]")
        
        # Take before screenshot
        before_screenshot = self.screenshot_manager.take_screenshot("before_click")
        if not before_screenshot:
            return ClickResult(success=False, state_changed=False, error_message="Could not take before screenshot")
        
        before_hash = self.visual_differ.calculate_image_hash(before_screenshot)
        
        # Try each centroid
        wait_times = [2, 2, 2]
        
        for attempt, (centroid, wait_time) in enumerate(zip(abs_centroids, wait_times), 1):
            abs_x, abs_y = centroid
            
            self.console.print(f"\n[yellow]üéØ ATTEMPT {attempt}/3: Centroid C{attempt} at ({abs_x}, {abs_y})[/yellow]")
            
            success = self._attempt_single_click(abs_x, abs_y, wait_time, before_hash, before_screenshot, f"C{attempt}")
            if success:
                return ClickResult(
                    success=True,
                    state_changed=True,
                    wait_time_used=wait_time,
                    hash_before=before_hash,
                    hash_after=self._temp_after_hash,
                    after_screenshot=self._temp_after_screenshot,
                    diff_result=self._temp_diff_result
                )
            
            # Try nudging if not last attempt
            if attempt < 3:
                self.console.print(f"[yellow]üîÑ C{attempt} failed, trying nudge strategy...[/yellow]")
                if self._try_nudge_strategy(abs_x, abs_y, wait_time, before_hash, before_screenshot, f"C{attempt}"):
                    return ClickResult(
                        success=True,
                        state_changed=True,
                        wait_time_used=wait_time,
                        hash_before=before_hash,
                        hash_after=self._temp_after_hash,
                        after_screenshot=self._temp_after_screenshot,
                        diff_result=self._temp_diff_result
                    )
        
        # Mark as non-interactive if all attempts failed
        return ClickResult(
            success=True,
            state_changed=False,
            interaction_type="non_interactive",
            error_message="No UI response to clicks"
        )
    
    def _ensure_window_has_focus(self) -> bool:
        """Ensure the target app window has focus before clicking"""
        try:
            if not self.app_controller.current_app_info:
                self.console.print("[red]‚ùå No app info available for focus[/red]")
                return False
            
            window_id = self.app_controller.current_app_info['window_id']
            
            # ‚úÖ GET HWND: We need the hwnd for smart_foreground
            window_info = self.app_controller.gui_api.get_window_info(window_id)
            if not window_info:
                self.console.print("[red]‚ùå Could not get window info for focus[/red]")
                return False
            
            hwnd = window_info['window_data']['hwnd']
            
            # ‚úÖ USE SMART FOREGROUND: The minimize/maximize hack instead of simple focus
            focus_success, focus_message = self.app_controller.gui_api.controller.wm.smart_foreground(hwnd)
            
            if focus_success:
                self.console.print(f"[green]üéØ Window focused successfully: {focus_message}[/green]")
                
                # ‚úÖ WAIT FOR ANIMATION: Allow extra time for minimize/maximize animations
                self.console.print("[yellow]‚è≥ Waiting for focus animation to complete...[/yellow]")
                time.sleep(2)  # Allow minimize/maximize animation to complete
                
                # ‚úÖ FORCE REFRESH: Get fresh window coordinates after smart focus
                self.console.print("[yellow]üîÑ Refreshing window coordinates after focus...[/yellow]")
                
                # Force complete refresh of window API
                self.app_controller.gui_api.refresh()
                time.sleep(0.5)
                
                # Get fresh window info (this should have post-focus coordinates)
                fresh_window_info = self.app_controller.gui_api.get_window_info(window_id)
                
                if fresh_window_info:
                    pos = fresh_window_info['window_data']['position']
                    size = fresh_window_info['window_data']['size']
                    
                    # ‚úÖ DEBUG: Show what we detected after smart focus
                    self.console.print(f"[cyan]üîç WINDOW STATE (post-smart-focus):[/cyan]")
                    self.console.print(f"   Window ID: {window_id}")
                    self.console.print(f"   Position: ({pos['x']}, {pos['y']})")
                    self.console.print(f"   Size: {size['width']}√ó{size['height']}")
                    
                    return True
                else:
                    self.console.print("[red]‚ùå Could not get fresh window info after smart focus[/red]")
                    return False
                
            else:
                self.console.print(f"[red]‚ùå Smart foreground failed: {focus_message}[/red]")
                return False
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Smart focus operation failed: {e}[/red]")
            return False
    
    def _attempt_single_click(self, abs_x: int, abs_y: int, wait_time: int, 
                             before_hash: str, before_screenshot: str, label: str) -> bool:
        """Attempt a single click with timing and change detection"""
        try:
            # Move to position and click immediately (no hover wait)
            self.app_controller.gui_api.set_cursor_position(abs_x, abs_y)
            time.sleep(0.1)  # ‚úÖ REDUCED: Minimal delay instead of 1 second hover
            
            # Click
            self.app_controller.gui_api.click(abs_x, abs_y)
            self.console.print(f"[green]‚úÖ {label} click sent to ({abs_x}, {abs_y})[/green]")
            
            # Wait for UI response
            self.console.print(f"[yellow]‚è±Ô∏è Waiting {wait_time}s for UI response...[/yellow]")
            time.sleep(wait_time)
            
            # Check for change
            after_screenshot = self.screenshot_manager.take_screenshot(f"after_{label}_wait_{wait_time}s")
            if not after_screenshot:
                return False
            
            after_hash = self.visual_differ.calculate_image_hash(after_screenshot)
            
            if before_hash != after_hash:
                self.console.print(f"[green]üéØ Hash change detected with {label} - validating visual changes...[/green]")
                
                # Validate meaningful changes
                temp_diff_path = f"temp_validation_{label}.png"
                diff_result = self.visual_differ.extract_change_regions(
                    before_screenshot, after_screenshot, temp_diff_path, (abs_x, abs_y)
                )
                
                if diff_result["success"] and diff_result.get("regions"):
                    self.console.print(f"[bold green]üéâ MEANINGFUL STATE CHANGE with {label}![/bold green]")
                    self._temp_after_screenshot = after_screenshot
                    self._temp_after_hash = after_hash
                    self._temp_diff_result = diff_result
                    return True
                else:
                    self.console.print(f"[yellow]‚ö†Ô∏è Hash changed but no meaningful visual regions with {label}[/yellow]")
                    self.screenshot_manager.cleanup_screenshot(after_screenshot)
                    return False
            else:
                self.console.print(f"[yellow]‚ö†Ô∏è No change detected with {label}[/yellow]")
                self.screenshot_manager.cleanup_screenshot(after_screenshot)
                return False
            
        except Exception as e:
            self.console.print(f"[red]‚ùå {label} click failed: {e}[/red]")
            return False
    
    def _try_nudge_strategy(self, abs_x: int, abs_y: int, wait_time: int, 
                           before_hash: str, before_screenshot: str, label: str) -> bool:
        """Try nudging in different directions"""
        nudge_directions = [(25, 0), (-25, 0), (0, 25), (0, -25)]
        
        for nudge_x, nudge_y in nudge_directions:
            nudge_abs_x = abs_x + nudge_x
            nudge_abs_y = abs_y + nudge_y
            
            self.console.print(f"[dim]üîÑ Nudge +({nudge_x}, {nudge_y}) to ({nudge_abs_x}, {nudge_abs_y})[/dim]")
            
            try:
                # Move to nudge position
                self.app_controller.gui_api.set_cursor_position(nudge_abs_x, nudge_abs_y)
                time.sleep(0.2)
                
                # Return to centroid and click
                success = self._attempt_single_click(abs_x, abs_y, wait_time, before_hash, before_screenshot, f"{label}_nudge")
                if success:
                    return True
            except Exception as e:
                self.console.print(f"[dim]‚ùå Nudge failed: {e}[/dim]")
                continue
            
            break  # Only try first nudge direction
        
        return False


==================================================

Path: utils\fdom\config_manager.py
File: config_manager.py
Code:
"""
ConfigManager - Foundation for fDOM Framework
Handles all configuration loading, validation, and testing
"""
import json
import os
from pathlib import Path
from typing import Dict, Any, Optional
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich import print as rprint

class ConfigManager:
    """
    Professional configuration management for fDOM framework
    Handles loading, validation, and testing of all configuration settings
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """
        Initialize ConfigManager with automatic config loading
        
        Args:
            config_path: Optional path to config file. Uses default if None.
        """
        self.console = Console()
        self.config_path = config_path or self._get_default_config_path()
        self.config = self._load_and_validate_config()
        
    def _get_default_config_path(self) -> str:
        """Get default config file path relative to this module"""
        current_dir = Path(__file__).parent
        return str(current_dir / "fdom_config.json")
    
    def _load_and_validate_config(self) -> Dict[str, Any]:
        """
        Load configuration file with comprehensive validation
        
        Returns:
            Loaded and validated configuration dictionary
            
        Raises:
            FileNotFoundError: If config file doesn't exist
            ValueError: If config file is invalid JSON or missing required keys
        """
        if not os.path.exists(self.config_path):
            raise FileNotFoundError(f"Configuration file not found: {self.config_path}")
        
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
        except json.JSONDecodeError as e:
            raise ValueError(f"Invalid JSON in config file: {e}")
        
        # Validate required sections
        required_sections = [
            "exploration", "graph_traversal", "node_status_tracking",
            "capture", "storage", "seraphine", "interaction", "debug"
        ]
        
        missing_sections = [section for section in required_sections if section not in config]
        if missing_sections:
            raise ValueError(f"Missing required config sections: {missing_sections}")
        
        return config
    
    def get(self, key_path: str, default: Any = None) -> Any:
        """
        Get configuration value using dot notation
        
        Args:
            key_path: Dot-separated path to config value (e.g., "exploration.max_states_per_session")
            default: Default value if key not found
            
        Returns:
            Configuration value or default
        """
        keys = key_path.split('.')
        value = self.config
        
        try:
            for key in keys:
                value = value[key]
            return value
        except (KeyError, TypeError):
            return default
    
    def update(self, key_path: str, value: Any) -> None:
        """
        Update configuration value using dot notation
        
        Args:
            key_path: Dot-separated path to config value
            value: New value to set
        """
        keys = key_path.split('.')
        config = self.config
        
        # Navigate to parent of target key
        for key in keys[:-1]:
            if key not in config:
                config[key] = {}
            config = config[key]
        
        # Set the final value
        config[keys[-1]] = value
    
    def test_config(self) -> bool:
        """
        Comprehensive configuration testing with rich console output
        
        Returns:
            True if all tests pass, False otherwise
        """
        self.console.print("\n[bold blue]üîß FDOM CONFIGURATION TEST[/bold blue]")
        self.console.print("=" * 60)
        
        try:
            # Test 1: Config file exists and loads
            self.console.print(f"[yellow]üìÅ Config file:[/yellow] {self.config_path}")
            self.console.print(f"[green]‚úÖ Config loaded successfully[/green]")
            
            # Test 2: Show all configuration sections
            self._display_config_sections()
            
            # Test 3: Validate critical values
            validation_results = self._validate_config_values()
            
            # Test 4: Check file paths and permissions
            path_results = self._test_storage_paths()
            
            # Summary
            all_passed = validation_results and path_results
            status = "[green]‚úÖ PASSED[/green]" if all_passed else "[red]‚ùå FAILED[/red]"
            self.console.print(f"\n[bold]üéØ Configuration Test Result: {status}[/bold]")
            
            return all_passed
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Configuration test failed: {e}[/red]")
            return False
    
    def _display_config_sections(self) -> None:
        """Display all configuration sections in a beautiful table"""
        table = Table(title="üìã Configuration Sections", show_header=True, header_style="bold magenta")
        table.add_column("Section", style="cyan", width=20)
        table.add_column("Key Settings", style="white", width=40)
        table.add_column("Status", justify="center", width=10)
        
        for section_name, section_data in self.config.items():
            if isinstance(section_data, dict):
                key_count = len(section_data)
                sample_keys = list(section_data.keys())[:3]
                if len(section_data) > 3:
                    sample_keys.append("...")
                
                table.add_row(
                    section_name,
                    f"{key_count} settings: {', '.join(sample_keys)}",
                    "[green]‚úì[/green]"
                )
        
        self.console.print(table)
    
    def _validate_config_values(self) -> bool:
        """Validate configuration values for correctness"""
        self.console.print("\n[yellow]üîç Validating Configuration Values[/yellow]")
        
        validation_tests = [
            ("exploration.max_states_per_session", lambda x: isinstance(x, int) and x > 0, "Must be positive integer"),
            ("exploration.click_timeout_seconds", lambda x: isinstance(x, (int, float)) and x > 0, "Must be positive number"),
            ("capture.screenshot_format", lambda x: x in ["png", "jpg", "jpeg"], "Must be png, jpg, or jpeg"),
            ("capture.screenshot_quality", lambda x: isinstance(x, int) and 1 <= x <= 100, "Must be integer 1-100"),
            ("seraphine.confidence_threshold", lambda x: isinstance(x, (int, float)) and 0 <= x <= 1, "Must be float 0-1"),
            ("storage.screenshots_subdir", lambda x: isinstance(x, str) and len(x) > 0, "Must be non-empty string"),
            ("interaction.window_focus_delay", lambda x: isinstance(x, (int, float)) and x > 0, "Must be positive number"),
            ("debug.verbose_logging", lambda x: isinstance(x, bool), "Must be boolean"),
        ]
        
        all_valid = True
        for key_path, validator, error_msg in validation_tests:
            value = self.get(key_path)
            
            # Check if key exists
            if value is None:
                self.console.print(f"  [red]‚ùå[/red] {key_path}: [red]MISSING[/red]")
                self.console.print(f"    [red]Error: Key not found in configuration[/red]")
                all_valid = False
                continue
            
            # Validate value
            is_valid = validator(value)
            status = "[green]‚úÖ[/green]" if is_valid else "[red]‚ùå[/red]"
            self.console.print(f"  {status} {key_path}: {value}")
            
            if not is_valid:
                self.console.print(f"    [red]Error: {error_msg}[/red]")
                all_valid = False
        
        return all_valid
    
    def _test_storage_paths(self) -> bool:
        """Test storage path configuration"""
        self.console.print("\n[yellow]üìÅ Testing Storage Path Configuration[/yellow]")
        
        storage_dirs = [
            self.get("storage.screenshots_subdir"),
            self.get("storage.crops_subdir"),
            self.get("storage.diffs_subdir"),
            self.get("storage.templates_subdir")
        ]
        
        all_valid = True
        for dir_name in storage_dirs:
            if not dir_name or not isinstance(dir_name, str):
                self.console.print(f"  [red]‚ùå Invalid directory name: {dir_name}[/red]")
                all_valid = False
            else:
                self.console.print(f"  [green]‚úÖ[/green] {dir_name}: Valid directory name")
        
        return all_valid
    
    def get_app_storage_config(self) -> Dict[str, str]:
        """
        Get storage configuration for app directory creation
        
        Returns:
            Dictionary with storage subdirectory names
        """
        return {
            'screenshots': self.get("storage.screenshots_subdir"),
            'crops': self.get("storage.crops_subdir"),
            'diffs': self.get("storage.diffs_subdir"),
            'templates': self.get("storage.templates_subdir")
        }
    
    def get_seraphine_config(self) -> Dict[str, Any]:
        """
        Get seraphine integration configuration
        
        Returns:
            Dictionary with seraphine settings
        """
        return self.config.get("seraphine", {})
    
    def is_debug_mode(self) -> bool:
        """Check if debug mode is enabled"""
        return self.get("debug.verbose_logging", False)
    
    def should_use_rich_output(self) -> bool:
        """Check if rich console output should be used"""
        return self.get("debug.rich_console_output", True)


def test_config_manager():
    """Test function for ConfigManager - DELTA 1 testing"""
    console = Console()
    
    console.print("\n[bold green]üöÄ DELTA 1: ConfigManager Test[/bold green]")
    console.print("=" * 50)
    
    try:
        # Test 1: Initialize ConfigManager
        console.print("[yellow]üîß Initializing ConfigManager...[/yellow]")
        config_manager = ConfigManager()
        console.print("[green]‚úÖ ConfigManager initialized successfully[/green]")
        
        # Test 2: Run comprehensive config test
        test_result = config_manager.test_config()
        
        # Test 3: Test specific value retrieval
        console.print("\n[yellow]üîç Testing Value Retrieval[/yellow]")
        test_keys = [
            "exploration.max_states_per_session",
            "capture.screenshot_format", 
            "seraphine.mode",
            "seraphine.confidence_threshold",
            "storage.screenshots_subdir"
        ]
        
        for key in test_keys:
            value = config_manager.get(key)
            console.print(f"  {key}: [cyan]{value}[/cyan]")
        
        # Test 4: Test configuration helpers
        console.print("\n[yellow]üõ†Ô∏è Testing Helper Methods[/yellow]")
        storage_config = config_manager.get_app_storage_config()
        console.print(f"  Storage config: [cyan]{storage_config}[/cyan]")
        
        seraphine_config = config_manager.get_seraphine_config()
        console.print(f"  Seraphine config: [cyan]{seraphine_config}[/cyan]")
        
        debug_mode = config_manager.is_debug_mode()
        console.print(f"  Debug mode: [cyan]{debug_mode}[/cyan]")
        
        rich_output = config_manager.should_use_rich_output()
        console.print(f"  Rich output: [cyan]{rich_output}[/cyan]")
        
        # Final result
        if test_result:
            console.print("\n[bold green]üéâ DELTA 1 PASSED: ConfigManager is ready![/bold green]")
        else:
            console.print("\n[bold red]‚ùå DELTA 1 FAILED: Configuration issues detected[/bold red]")
            
        return test_result
        
    except Exception as e:
        console.print(f"\n[bold red]üí• DELTA 1 FAILED: {e}[/bold red]")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="fDOM ConfigManager - Delta 1 Testing")
    parser.add_argument("--test-config", action="store_true", help="Run comprehensive config test")
    parser.add_argument("--config-path", type=str, help="Path to custom config file")
    
    args = parser.parse_args()
    
    if args.test_config:
        success = test_config_manager()
        exit(0 if success else 1)
    else:
        print("Usage: python config_manager.py --test-config")
        print("       python config_manager.py --test-config --config-path /path/to/config.json")


==================================================

Path: utils\fdom\element_interactor.py
File: element_interactor.py
Code:
"""ElementInteractor - Core exploration engine for fDOM Framework
Implements sophisticated click ‚Üí detect ‚Üí navigate strategy
"""
import json
import os
import sys
import time
import hashlib
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime

# ‚úÖ ADD PATH RESOLUTION FOR DIRECT SCRIPT EXECUTION
if __name__ == "__main__":
    # Add the project root to Python path when running directly
    project_root = Path(__file__).parent.parent.parent
    sys.path.insert(0, str(project_root))

from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.prompt import Prompt, IntPrompt
from rich import print as rprint
from PIL import Image
import numpy as np
import argparse
import psutil

# Import our framework modules
from config_manager import ConfigManager
from screen_manager import ScreenManager
from app_controller import AppController
from state_manager import StateManager
from seraphine_integrator import SeraphineIntegrator
from visual_differ import VisualDiffer

# Import modular components
from utils.fdom.interaction_types import ClickResult, BacktrackStrategy
from utils.fdom.interaction_utils import (
    sanitize_app_name, 
    sanitize_node_id_for_files
)
from utils.fdom.interactive_cli import InteractiveCLI
from utils.fdom.screenshot_manager import ScreenshotManager
from utils.fdom.state_processor import StateProcessor
from utils.fdom.navigation_engine import NavigationEngine
from utils.fdom.click_engine import ClickEngine


class ElementInteractor:
    """
    Core exploration engine implementing depth-first interaction strategy
    CLEANED: Pure orchestration - delegates to modular components
    """
    
    def __init__(self, app_executable_path: str, state_manager: Optional[StateManager] = None, app_controller: Optional[AppController] = None):
        """Initialize ElementInteractor for specific app exploration"""
        self.console = Console()
        self.app_executable_path = app_executable_path
        
        # Initialize framework components
        self.config = ConfigManager()
        self.screen_manager = ScreenManager(self.config)
        
        # ‚úÖ LOAD TEMPLATE FILE CONFIG
        template_config = load_template_file_config()
        template_file_path = None
        
        if template_config.get('auto_load_on_launch', True):
            template_file_path = get_template_file_for_app(app_executable_path, template_config)
            
            if template_file_path:
                self.console.print(f"[yellow]üéØ Will launch with template: {os.path.basename(template_file_path)}[/yellow]")
        
        # ‚úÖ Use AppController properly with correct constructor
        if app_controller:
            self.app_controller = app_controller
            self.console.print(f"[green]üîó Using provided AppController instance[/green]")
        else:
            # ‚úÖ FIXED: Use correct target screen (default to Screen 1 = TEST SCREEN)
            target_screen = self.config.get("capture.default_screen", 1)  # Screen 1 = Monitor 1 = 1920√ó1080
            
            self.app_controller = AppController(
                app_path=app_executable_path,
                target_screen=target_screen, 
                config=self.config,
                template_file_path=template_file_path  # ‚Üê PASS TEMPLATE FILE
            )
            
            # Set screen_manager on AppController after creation
            self.app_controller.screen_manager = self.screen_manager
            
            # ‚úÖ PROPER APP LAUNCH using AppController
            self.console.print(f"[yellow]üöÄ Launching app: {app_executable_path}[/yellow]")
            launch_result = self.app_controller.launch_app()  # ‚Üê Use launch_app() method
            
            if not launch_result["success"]:
                raise Exception(f"Failed to launch app: {launch_result.get('error', 'Unknown error')}")
            
            self.console.print(f"[green]‚úÖ App launched successfully![/green]")
        
        # Extract app name from AppController's info
        if hasattr(self.app_controller, 'current_app_info') and self.app_controller.current_app_info:
            self.app_name = self.app_controller.current_app_info["app_name"]
        else:
            self.app_name = sanitize_app_name(Path(app_executable_path).stem)
        
        # ‚úÖ Use StateManager with proper app name
        if state_manager:
            self.state_manager = state_manager
        else:
            self.state_manager = StateManager(self.app_name)
            self._load_existing_fdom()
        
        self.seraphine_integrator = SeraphineIntegrator(self.app_name)
        self.visual_differ = VisualDiffer(self.config)
        
        # Initialize modular components
        self.interactive_cli = InteractiveCLI(self)
        self.screenshot_manager = ScreenshotManager(self.app_controller, self.visual_differ, debug_mode=True)
        self.state_processor = StateProcessor(self.state_manager, self.seraphine_integrator, self.visual_differ)
        self.navigation_engine = NavigationEngine(self.app_controller, self.visual_differ, self.state_manager, self)
        self.click_engine = ClickEngine(self.app_controller, self.visual_differ, self.config)
        
        # Interaction settings
        self.click_offset = self.config.get("interaction.click_center_offset", 2)
        self.wait_times = [3, 5, 10]
        self.max_human_retries = 3
        self.current_state_id = "root"
        self.state_breadcrumb = ["root"]
        self.screenshot_stack = []
        self.debug_mode = True
        
        self.console.print(Panel(
            f"[bold]üéØ ElementInteractor Ready[/bold]\n\n"
            f"üéÆ Strategy: Depth-first exploration\n"
            f"üì± App: {self.app_name}\n"
            f"‚è±Ô∏è Wait times: {' ‚Üí '.join(map(str, self.wait_times))}s\n"
            f"üéØ Click: Center + {self.click_offset}px offset\n"
            f"üîÑ Backtrack: Multi-strategy with human fallback",
            title="üß† Interaction Strategy",
            border_style="green"
        ))
        
        # ‚úÖ FIXED: Build initial DOM only if no existing fDOM data was loaded
        if not self.state_manager.fdom_data.get("states"):
            self._build_initial_dom()
            
            # üéØ NEW: Auto-run captioner after successful initial DOM build
            self._auto_run_captioner_on_first_launch()

    def _load_existing_fdom(self) -> None:
        """Load existing fDOM file if it exists"""
        app_dir = Path(__file__).parent.parent.parent / "apps" / self.app_name
        fdom_path = app_dir / "fdom.json"
        
        if fdom_path.exists():
            try:
                with open(fdom_path, 'r', encoding='utf-8') as f:
                    existing_fdom = json.load(f)
                
                self.state_manager.fdom_data = existing_fdom
                
                # CRITICAL: Always rebuild tracking sets after loading
                self.state_manager._rebuild_tracking_sets()
                
                # Set current state to latest state
                states = existing_fdom.get("states", {})
                if states:
                    state_ids = sorted(states.keys())
                    self.current_state_id = state_ids[-1]
                
                self.console.print(f"[green]üìÇ Loaded existing fDOM: {len(states)} states[/green]")
                
                # DEBUG: Show what was loaded
                self.console.print(f"[cyan]üîç DEBUG: Loaded {len(self.state_manager.pending_nodes)} pending nodes[/cyan]")
                
            except Exception as e:
                self.console.print(f"[yellow]‚ö†Ô∏è Could not load existing fDOM: {e}[/yellow]")
    
    def click_element(self, node_id: str) -> Dict:
        """Execute click with comprehensive interaction workflow"""
        
        # ‚úÖ CRITICAL: Check if app is still running BEFORE every interaction
        if not self._ensure_app_is_running():
            return {
                "success": False,
                "error_message": "App not running and restart failed",
                "state_changed": False
            }
        
        # ‚úÖ CAPTURE BEFORE SCREENSHOT FIRST - BEFORE NAVIGATION
        before_screenshot = self.screenshot_manager.take_screenshot("before_click")
        if not before_screenshot:
            return ClickResult(success=False, state_changed=False, error_message="Could not take before screenshot")
        
        # PHASE 1: Navigation
        target_state = self._find_node_state(node_id)
        original_state = self.current_state_id
        
        if target_state and target_state != self.current_state_id:
            self.console.print(f"[cyan]üß≠ Need to navigate: {self.current_state_id} ‚Üí {target_state}[/cyan]")
            navigation_success = self.navigation_engine.navigate_to_state(target_state, self.current_state_id)
            if not navigation_success:
                # ‚úÖ DON'T GIVE UP! Try backtracking first
                self.console.print(f"[yellow]‚ö†Ô∏è Navigation failed, attempting smart backtracking...[/yellow]")
                
                # Take current screenshot as reference for backtracking
                current_screenshot = self.screenshot_manager.take_screenshot("pre_backtrack")
                backtrack_success = self._smart_backtrack_to_state(target_state, current_screenshot)
                
                if backtrack_success:
                    self.console.print(f"[green]‚úÖ Backtracking successful! Now in {target_state}[/green]")
                    self.current_state_id = target_state
                else:
                    self.console.print(f"[red]‚ùå Both navigation and backtracking failed[/red]")
                    return ClickResult(success=False, state_changed=False, error_message=f"Failed to navigate to state {target_state} - both direct navigation and backtracking failed")
            else:
                self.current_state_id = target_state
        elif target_state:
            self.console.print(f"[cyan]‚úÖ Already in target state: {target_state}[/cyan]")
        else:
            self.console.print(f"[yellow]‚ö†Ô∏è Node {node_id} not found in any state, assuming current state[/yellow]")
        
        # ‚úÖ PHASE 2: Continue with rest of logic using ORIGINAL before_screenshot
        node_data = self._find_node_in_fdom(node_id)
        if not node_data:
            return ClickResult(success=False, state_changed=False, error_message=f"Node {node_id} not found")
        
        # ‚úÖ NEW: Check if element is enabled
        if not node_data.get('g_enabled', True):
            self.console.print(f"[yellow]‚ö†Ô∏è Element '{node_data.get('g_icon_name', 'unknown')}' is disabled - marking as non-interactive[/yellow]")
            self.state_manager.mark_node_explored(node_id, click_result=None, interaction_type="disabled")
            self.state_manager.save_fdom_to_file()
            return ClickResult(success=True, state_changed=False, interaction_type="disabled")
        
        window_pos = self._get_current_window_position()
        if not window_pos:
            return ClickResult(success=False, state_changed=False, error_message="Could not get window position")
        
        source_element_name = node_data.get('g_icon_name', 'unknown')
        self.console.print(f"\n[bold yellow]üéØ CLICKING ELEMENT: {node_id}[/bold yellow]")
        self.console.print(f"[cyan]üìç Target: {source_element_name}[/cyan]")
        
        # ‚úÖ DELEGATE TO CLICK ENGINE
        click_result = self.click_engine.execute_click_with_centroids(
            node_data, window_pos, source_element_name
        )
        
        # PHASE 3: Process Results (delegate to StateProcessor)
        if click_result.success and click_result.state_changed:
            
            # üéØ INJECTION 1: Check app closure BEFORE Seraphine processing
            if not self._verify_app_still_running():
                return self._handle_app_closure_simple(node_id, source_element_name, click_result)
            
            # üéØ INJECTION 2: Check state reversion BEFORE Seraphine processing
            reverted_state = self._check_state_reversion(click_result.after_screenshot)
            if reverted_state:
                return self._handle_state_reversion(node_id, source_element_name, click_result, reverted_state)
            
            # Continue with existing logic - Create diff path
            diffs_dir = self.app_controller.current_app_info["folder_paths"]["diffs"]
            diffs_dir.mkdir(exist_ok=True)
            safe_node_id = sanitize_node_id_for_files(node_id)
            diff_filename = f"{self.current_state_id}_to_processing_via_{safe_node_id}.png"
            diff_path = str(diffs_dir / diff_filename)
            
            # ‚úÖ DELEGATE TO STATE PROCESSOR - PASS PERFECT DIFF_RESULT
            new_state_name = self.state_processor.process_successful_click(
                node_id,                        # node_id: str
                source_element_name,           # source_element_name: str  
                self.current_state_id,         # current_state: str
                before_screenshot,             # before_screenshot: str
                click_result.after_screenshot, # after_screenshot: str
                diff_path,                     # diff_path: str
                click_result.diff_result       # ‚úÖ NEW: Pass perfect diff_result from ClickEngine
            )
            
            if new_state_name:
                # State processing succeeded
                self.current_state_id = new_state_name
                click_result.new_state_id = new_state_name
                click_result.screenshot_path = diff_path
                
                self.console.print(f"[green]üéØ New state created: {new_state_name}[/green]")
                
                # ‚úÖ PHASE 4: AUTO-CAPTIONER on updated DOM
                self.console.print(f"[bold cyan]ü§ñ PHASE 4: AUTO-CAPTIONER on updated DOM[/bold cyan]")
                pending_list = self.interactive_cli.show_pending_nodes_list(showTable=False)
                if pending_list:
                    self.interactive_cli._run_auto_captioner(pending_list)
                    self.console.print("[green]‚úÖ Auto-captioner completed on new state![/green]")
                else:
                    self.console.print("[yellow]‚ö†Ô∏è No pending nodes found for auto-captioning[/yellow]")
                
                # ‚úÖ PHASE 5: AUTOMATED EXPLORATION - Always auto-backtrack for systematic exploration
                if original_state != self.current_state_id:
                    self.console.print(f"[bold blue]üîÑ AUTO-BACKTRACK: Systematic exploration, returning to {original_state}[/bold blue]")
                    
                    # ‚úÖ FIXED: Use BEFORE screenshot as reference, not AFTER
                    self.console.print(f"[dim]üîç DEBUG: Using reference screenshot: {before_screenshot}[/dim]")
                    backtrack_success = self._smart_backtrack_to_state(original_state, before_screenshot)
                    
                    if backtrack_success:
                        self.current_state_id = original_state
                        self.console.print(f"[green]‚úÖ Smart backtrack successful[/green]")
                    else:
                        self.console.print(f"[red]‚ùå Smart backtrack failed - manual intervention may be needed[/red]")
                
                return click_result
            else:
                # State processing failed
                click_result.success = False
                click_result.state_changed = False
                click_result.error_message = "State processing failed"
                self.console.print(f"[red]‚ùå State processing failed[/red]")
            
            # Cleanup
            if not self.debug_mode:
                self.screenshot_manager.cleanup_screenshot(before_screenshot)
                self.screenshot_manager.cleanup_screenshot(click_result.after_screenshot)
            
            return click_result
        elif click_result.success and not click_result.state_changed:
            # Non-interactive element
            self.state_manager.mark_node_explored(node_id, click_result=None, interaction_type="non_interactive")
            self.state_manager.save_fdom_to_file()
            return click_result
        else:
            # Click execution failed
            return click_result

    def navigate_back_to_state(self, target_state_id: str, failure_reference_screenshot: str = None) -> bool:
        """CLEANED: Delegate to NavigationEngine"""
        return self.navigation_engine.navigate_back_to_state(target_state_id, failure_reference_screenshot)

    # =====================================================================
    # CORE UTILITY METHODS (Keep - these are essential orchestration)
    # =====================================================================

    def _find_node_in_fdom(self, node_id: str) -> Optional[Dict]:
        """Find node data in fDOM - handles both state::node_id and old format"""
        # NEW FORMAT: state::node_id
        if "::" in node_id:
            state_name, actual_node_id = node_id.split("::", 1)
            state_data = self.state_manager.fdom_data.get("states", {}).get(state_name, {})
            return state_data.get("nodes", {}).get(actual_node_id)
        
        # OLD FORMAT: search all states (fallback)
        for state_data in self.state_manager.fdom_data.get("states", {}).values():
            nodes = state_data.get("nodes", {})
            if node_id in nodes:
                return nodes[node_id]
        return None

    def _get_current_window_position(self) -> Optional[Dict]:
        """Get current app window position on screen"""
        try:
            if not self.app_controller.current_app_info:
                self.console.print("[red]‚ùå No app currently tracked[/red]")
                return None
            
            window_id = self.app_controller.current_app_info['window_id']
            window_info = self.app_controller.gui_api.get_window_info(window_id)
            
            if window_info:
                pos = window_info['window_data']['position']
                return {
                    'left': pos['x'],
                    'top': pos['y'],
                    'width': window_info['window_data']['size']['width'],
                    'height': window_info['window_data']['size']['height']
                }
            else:
                self.console.print("[red]‚ùå Could not get window position info[/red]")
                return None
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Window position detection failed: {e}[/red]")
            return None

    def _find_node_state(self, unique_node_id: str) -> Optional[str]:
        """Find which state contains the node - handle state::node_id format"""
        # NEW FORMAT: state::node_id
        if "::" in unique_node_id:
            state_name, node_id = unique_node_id.split("::", 1)
            # Verify the node exists in that state
            state_data = self.state_manager.fdom_data.get("states", {}).get(state_name, {})
            if node_id in state_data.get("nodes", {}):
                return state_name
            return None
        
        # OLD FORMAT: search all states (fallback)
        for state_id, state_data in self.state_manager.fdom_data.get("states", {}).items():
            if unique_node_id in state_data.get("nodes", {}):
                return state_id
        return None

    # =====================================================================
    # INTERACTIVE MODE (Delegate to InteractiveCLI)
    # =====================================================================

    def interactive_exploration_mode(self) -> None:
        """CLEANED: Delegate to InteractiveCLI"""
        self.interactive_cli.run_interactive_mode()

    def _build_initial_dom(self):
        """Build initial DOM using AppController's screenshot and Seraphine"""
        self.console.print(f"[yellow]üèóÔ∏è Building initial DOM for {self.app_name}...[/yellow]")
        time.sleep(2)
        
        # ‚úÖ Use AppController's screenshot method
        initial_screenshot = self.app_controller.take_initial_screenshot()
        
        if not initial_screenshot:
            self.console.print("[red]‚ùå Failed to take initial screenshot[/red]")
            return
        
        self.console.print(f"[green]‚úÖ Initial screenshot: {initial_screenshot}[/green]")
        
        # ‚úÖ FIXED: Use correct method name with only screenshot_path parameter
        initial_state = self.state_manager.create_initial_fdom_state(initial_screenshot)
        
        if initial_state and initial_state.get("nodes"):
            self.console.print(f"[green]‚úÖ Initial DOM created with {len(self.state_manager.pending_nodes)} nodes[/green]")
        else:
            self.console.print(f"[red]‚ùå Initial state creation failed or returned no nodes[/red]")

    def _smart_backtrack_to_state(self, target_state: str, reference_screenshot: str) -> bool:
        """Smart 4-step backtracking for automated exploration"""
        return self.navigation_engine.smart_backtrack_to_state(target_state, reference_screenshot)

    def _ensure_app_is_running(self) -> bool:
        """Ensure app is running, restart if needed"""
        try:
            if not self.app_controller.current_app_info:
                self.console.print(f"[yellow]‚ö†Ô∏è No app info - attempting restart...[/yellow]")
                return self._restart_app_for_exploration()
            
            window_id = self.app_controller.current_app_info['window_id']
            window_info = self.app_controller.gui_api.get_window_info(window_id)
            
            if window_info is None:
                self.console.print(f"[yellow]‚ö†Ô∏è App window not found - restarting app...[/yellow]")
                return self._restart_app_for_exploration()
            
            return True
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Error checking app status: {e}[/red]")
            return self._restart_app_for_exploration()

    def _restart_app_for_exploration(self) -> bool:
        """Restart app without running Seraphine (fDOM exists)"""
        try:
            launch_result = self.app_controller.launch_app()
            
            if launch_result["success"]:
                self.console.print(f"[green]‚úÖ App restarted successfully[/green]")
                
                # ‚úÖ CRITICAL FIX: Refresh coordinates after restart
                self.console.print(f"[yellow]üîÑ Refreshing window coordinates after restart...[/yellow]")
                
                # Force complete refresh of window API
                self.app_controller.gui_api.refresh()
                time.sleep(0.5)
                
                # Get fresh window info...
                window_id = self.app_controller.current_app_info['window_id']
                window_info = self.app_controller.gui_api.get_window_info(window_id)
                
                if window_info:
                    pos = window_info['window_data']['position']
                    size = window_info['window_data']['size']
                    self.console.print(f"[green]üîç Fresh coordinates after restart: ({pos['x']}, {pos['y']}) size {size['width']}√ó{size['height']}[/green]")
                
                time.sleep(2)  # Wait for app to be ready
                return True
            else:
                self.console.print(f"[red]‚ùå App restart failed: {launch_result.get('error')}[/red]")
                return False
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Exception during app restart: {e}[/red]")
            return False

    def _handle_app_closure_simple(self, node_id: str, element_name: str, click_result: Dict) -> Dict:
        """Simple app closure handler - no Seraphine, no auto-backtrack"""
        self.console.print(f"[yellow]üö™ App closed by: {element_name}[/yellow]")
        
        # Mark as explored with closes_app type
        self.state_manager.mark_node_explored(
            node_id, 
            click_result="app_closed", 
            interaction_type="closes_app"
        )
        self.state_manager.save_fdom_to_file()
        
        # Restart app
        self.console.print(f"[cyan]üîÑ Restarting app for continued exploration...[/cyan]")
        restart_success = self._restart_app_for_exploration()
        
        # Update click result
        click_result.success = restart_success
        click_result.state_changed = False
        click_result.app_closed = True
        click_result.message = f"App closed by {element_name}, restarted successfully" if restart_success else f"App closed by {element_name} but restart failed"
        
        if restart_success:
            self.console.print(f"[green]‚úÖ App restarted - ready to continue exploration[/green]")
        else:
            self.console.print(f"[red]‚ùå App restart failed[/red]")
        
        return click_result

    def _verify_app_still_running(self) -> bool:
        """SIMPLE: Check if app process is still running"""
        try:
            # Get app name from executable path
            app_name = Path(self.app_executable_path).stem.lower()
            
            # Check if process exists
            for proc in psutil.process_iter(['pid', 'name']):
                if proc.info['name'] and app_name in proc.info['name'].lower():
                    self.console.print(f"[dim]üîç App running check: YES (process found)[/dim]")
                    return True
            
            self.console.print(f"[dim]üîç App closure detected: No {app_name} process[/dim]")
            return False
            
        except Exception as e:
            self.console.print(f"[yellow]‚ö†Ô∏è Process check failed: {e}[/yellow]")
            # Fallback to window check
            try:
                window_pos = self._get_current_window_position()
                return window_pos is not None
            except:
                return False

    def _check_state_reversion(self, current_screenshot: str) -> Optional[str]:
        """Check if current UI matches any known previous state"""
        
        # Get all known states to check against
        known_states = self.state_manager.fdom_data.get("states", {})
        
        # Priority order: Check navigation chain states first, then all others
        check_order = []
        
        # 1. Add navigation chain states (most likely to match)
        for nav_step in reversed(self.navigation_engine.navigation_chain):
            from_state = nav_step.get('from_state')
            if from_state and from_state not in check_order:
                check_order.append(from_state)
        
        # 2. Add root state (very common for cancel actions)
        if "root" not in check_order:
            check_order.append("root")
        
        # 3. Add any other states
        for state_id in known_states:
            if state_id not in check_order:
                check_order.append(state_id)
        
        self.console.print(f"[cyan]üîç Checking state reversion against: {check_order[:5]}{'...' if len(check_order) > 5 else ''}[/cyan]")
        
        # Check similarity against each state
        for state_id in check_order:
            state_data = known_states.get(state_id, {})
            state_image = state_data.get("image")
            
            if state_image and Path(state_image).exists():
                similarity = self.visual_differ.calculate_similarity_percentage(
                    current_screenshot, state_image
                )
                
                self.console.print(f"[dim]üìä {state_id}: {similarity}%[/dim]")
                
                # ‚úÖ STRICT: 99.99% threshold for state reversion
                if similarity >= 99.99:
                    self.console.print(f"[green]üîÑ State reversion detected: ‚Üí {state_id} ({similarity}%)[/green]")
                    return state_id
        
        self.console.print(f"[dim]‚ùå No state reversion detected[/dim]")
        return None

    def _handle_state_reversion(self, node_id: str, element_name: str, click_result: Dict, reverted_state: str) -> Dict:
        """Handle UI reversion to known state - no Seraphine needed"""
        self.console.print(f"[yellow]üîÑ State reversion: {element_name} ‚Üí {reverted_state}[/yellow]")
        
        # Mark as explored with reversion type
        self.state_manager.mark_node_explored(
            node_id, 
            click_result=f"reverted_to_{reverted_state}", 
            interaction_type="state_reversion"
        )
        self.state_manager.save_fdom_to_file()
        
        # Update current state
        original_state = self.current_state_id
        self.current_state_id = reverted_state
        
        # Update navigation chain (remove states after the reverted state)
        self._update_navigation_chain_for_reversion(reverted_state)
        
        # Update click result
        click_result.success = True
        click_result.state_changed = True
        click_result.state_reversion = True
        click_result.reverted_to = reverted_state
        click_result.message = f"{element_name} reverted UI to {reverted_state}"
        
        self.console.print(f"[green]‚úÖ State reversion handled: {original_state} ‚Üí {reverted_state}[/green]")
        self.console.print(f"[green]‚úÖ Skipped Seraphine analysis (state already known)[/green]")
        
        return click_result

    def _update_navigation_chain_for_reversion(self, reverted_state: str):
        """Update navigation chain when UI reverts to a previous state"""
        # Find the position of reverted_state in navigation chain
        chain = self.navigation_engine.navigation_chain
        
        # Remove navigation steps that are no longer valid
        for i in range(len(chain) - 1, -1, -1):
            if chain[i]['to_state'] == reverted_state:
                # Keep up to this point
                self.navigation_engine.navigation_chain = chain[:i+1]
                self.console.print(f"[dim]üîó Navigation chain updated: {len(self.navigation_engine.navigation_chain)} steps[/dim]")
                return
        
        # If reverted to root or a state not in chain, clear the chain
        if reverted_state == "root":
            self.navigation_engine.navigation_chain.clear()
            self.console.print(f"[dim]üîó Navigation chain cleared (reverted to root)[/dim]")

    def _auto_run_captioner_on_first_launch(self) -> None:
        """Automatically run auto-captioner after first-time DOM build"""
        try:
            # Check if initial DOM build was successful
            if not self.state_manager.fdom_data.get("states") or not self.state_manager.pending_nodes:
                self.console.print("[yellow]‚ö†Ô∏è Skipping auto-captioner: No DOM data or pending nodes[/yellow]")
                return
            
            self.console.print(Panel(
                "[bold green]ü§ñ AUTO-CAPTIONER STARTING[/bold green]\n\n"
                "First-time launch detected - automatically discovering element captions.\n"
                "This will help improve element identification accuracy.",
                title="üéØ Automatic Caption Discovery",
                border_style="green"
            ))
            
            # ‚úÖ CLEANEST: Use the same pattern as interactive CLI
            pending_list = self.interactive_cli.show_pending_nodes_list(showTable=False)
            
            if pending_list:
                self.interactive_cli._run_auto_captioner(pending_list)
                self.console.print("[green]‚úÖ Auto-captioner completed! Element captions discovered.[/green]")
            else:
                self.console.print("[yellow]‚ö†Ô∏è No pending nodes found for auto-captioning[/yellow]")
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Auto-captioner failed: {e}[/red]")
            self.console.print("[yellow]üí° You can manually run it later using option '0' in interactive mode[/yellow]")
            
    def raw_click_node(self, node_id, state_id=None):
        """
        Directly click a node using GUI API, NO focus/minimize/maximize, NO screenshot, NO analysis.
        """
        if state_id is None:
            state_id = self.current_state_id
        state = self.state_manager.fdom_data.get("states", {}).get(state_id, {})
        node_data = state.get("nodes", {}).get(node_id)
        if not node_data:
            self.console.print(f"[red]Node {node_id} not found in state {state_id}![/red]")
            return
        window_pos = self._get_current_window_position()
        if not window_pos:
            self.console.print("[red]Could not get window position![/red]")
            return
        bbox = node_data.get('bbox', [0, 0, 0, 0])
        # Support both [x1, y1, x2, y2] and [x, y, w, h]
        if len(bbox) == 4 and bbox[2] > bbox[0] and bbox[3] > bbox[1]:
            # [x1, y1, x2, y2]
            x = window_pos['left'] + (bbox[0] + bbox[2]) // 2
            y = window_pos['top'] + (bbox[1] + bbox[3]) // 2
        else:
            # fallback: [x, y, w, h]
            x = window_pos['left'] + bbox[0] + bbox[2] // 2
            y = window_pos['top'] + bbox[1] + bbox[3] // 2
        self.console.print(f"[bold yellow]RAW CLICK (no focus): {node_id} ({node_data.get('g_icon_name', '')}) at ({x}, {y}) in state {state_id}[/bold yellow]")
        self.app_controller.gui_api.click(x, y)
        time.sleep(0.5)

    def manual_persistent_click_mode(self):
        """
        Smart manual persistent click mode: show all nodes from all states, let user pick index, auto-navigate if needed, click, repeat.
        All clicks are direct, no focus/minimize/maximize, no screenshot, no fDOM update.
        """
        all_states = self.state_manager.fdom_data.get("states", {})
        all_edges = self.state_manager.fdom_data.get("edges", [])
        all_nodes = []
        node_to_state = {}

        def collect_nodes(state_id, node_id, data, level=0):
            icon_name = data.get("g_icon_name", "")
            if icon_name != "unanalyzed":
                all_nodes.append((state_id, node_id, data, level))
                node_to_state[node_id] = state_id
            for child_id, child_data in data.get("children", {}).items():
                collect_nodes(state_id, child_id, child_data, level + 1)

        for state_id, state in all_states.items():
            nodes = state.get("nodes", {})
            for node_id, data in nodes.items():
                collect_nodes(state_id, node_id, data)

        node_list = [(i, state_id, node_id, data, level) for i, (state_id, node_id, data, level) in enumerate(all_nodes)]

        if not node_list:
            self.console.print("[red]No valid nodes found in any state![/red]")
            return

        def find_path_via_edges(from_state, to_state):
            from collections import deque, defaultdict
            graph = defaultdict(list)
            for edge in all_edges:
                graph[edge['from']].append(edge)
            queue = deque([(from_state, [])])
            visited = set()
            while queue:
                state, path = queue.popleft()
                if state == to_state:
                    return path
                if state in visited:
                    continue
                visited.add(state)
                for edge in graph.get(state, []):
                    queue.append((edge['to'], path + [edge]))
            return None

        while True:
            table = Table(title="Manual Clickable Nodes (All States, Smart Navigation, NO FOCUS)")
            table.add_column("Index", style="cyan")
            table.add_column("State", style="magenta")
            table.add_column("Node ID", style="magenta")
            table.add_column("Icon Name", style="green")
            table.add_column("Brief", style="blue")
            table.add_column("Type", style="yellow")
            for idx, state_id, node_id, data, level in node_list:
                indent = "  " * level
                icon_name = data.get("g_icon_name", "")
                brief = data.get("g_brief", "")
                node_type = data.get("g_type", "")
                table.add_row(str(idx), state_id, f"{indent}{node_id}", icon_name, brief, node_type)
            self.console.print(table)

            try:
                idx = IntPrompt.ask("Enter index to click (or blank to exit)", default=None)
            except Exception:
                break
            if idx is None or not str(idx).isdigit():
                break
            idx = int(idx)
            if idx < 0 or idx >= len(node_list):
                self.console.print("[yellow]Invalid index![/yellow]")
                continue

            target_state_id, node_id, node_data, level = node_list[idx][1:]
            base_state = "root"  # or whatever your true base state is

            # Always start navigation from base_state
            nav_state = base_state
            if nav_state != target_state_id:
                path = find_path_via_edges(nav_state, target_state_id)
                if not path:
                    self.console.print(f"[red]No navigation path from {nav_state} to {target_state_id}![/red]")
                    continue
                self.console.print(f"[cyan]Navigating from {nav_state} to {target_state_id}...[/cyan]")
                for edge in path:
                    trigger_node = edge.get('trigger_node')
                    if not trigger_node:
                        action = edge.get('action', '')
                        if action.startswith('click:'):
                            trigger_node = action.split('click:')[1]
                    if not trigger_node:
                        self.console.print(f"[red]Edge missing trigger_node and action: {edge}![/red]")
                        break
                    self.console.print(f"[blue]RAW clicking navigation node: {trigger_node} to reach {edge['to']}[/blue]")
                    self.raw_click_node(trigger_node, state_id=edge['from'])
                    time.sleep(1)
                    nav_state = edge['to']

            # Now in the correct state, click the node (NO FOCUS LOGIC)
            self.raw_click_node(node_id, state_id=target_state_id)

def load_template_file_config(config_path: str = "utils/fdom/fdom_config.json") -> dict:
    """Load template file configuration from fdom_config.json"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        return config.get('template_files', {})
    except Exception as e:
        print(f"‚ö†Ô∏è Could not load template file config: {e}")
        return {}

def get_template_file_for_app(app_path: str, template_config: dict) -> str:
    """Get the appropriate template file for the given app"""
    if not template_config.get('enabled', False):
        return None
    
    # Extract executable name from full path
    app_exe = os.path.basename(app_path).upper()
    
    # Look up in app mappings (case-insensitive)
    app_mappings = template_config.get('app_mappings', {})
    
    # ‚úÖ MAKE CASE-INSENSITIVE LOOKUP
    matching_key = None
    for key in app_mappings.keys():
        if key.upper() == app_exe:
            matching_key = key
            break
    
    if matching_key:
        template_info = app_mappings[matching_key]
        template_filename = template_info['template_file']
        
        # Build full path to template file
        base_dir = template_config.get('base_directory', 'utils/fdom/template_files')
        template_path = os.path.join(base_dir, template_filename)
        
        # Verify file exists
        if os.path.exists(template_path):
            print(f"üìÑ Found template file for {app_exe}: {template_filename}")
            print(f"   Type: {template_info.get('file_type', 'Unknown')}")
            return os.path.abspath(template_path)
        else:
            print(f"‚ö†Ô∏è Template file not found: {template_path}")
    else:
        print(f"‚ÑπÔ∏è No template mapping found for: {app_exe}")
    
    # Handle fallback behavior
    fallback = template_config.get('fallback_behavior', {})
    if fallback.get('show_warning', True):
        print(f"‚ö†Ô∏è No template file configured for {app_exe}")
    
    return None

def main():
    """Enhanced CLI with interactive node selection"""
    parser = argparse.ArgumentParser(description="Enhanced fDOM Element Interaction")
    parser.add_argument("--app-name", default="notepad", help="App to test")
    parser.add_argument("--click-node", help="Specific node to click")
    parser.add_argument("--interactive", action="store_true", help="Interactive node selection mode")
    parser.add_argument("--list-pending", action="store_true", help="Just list pending nodes")
    parser.add_argument("--manual-click", action="store_true", help="Manual persistent click mode (no fdom update, no screenshots)")

    args = parser.parse_args()

    interactor = ElementInteractor(args.app_name)

    if args.list_pending:
        interactor.interactive_cli.show_pending_nodes_list()
        return

    if args.manual_click:
        interactor.manual_persistent_click_mode()
        return

    if args.interactive:
        print("üöÄ STARTING INTERACTIVE EXPLORATION")
        print("=" * 60)
        print("‚úÖ App already launched and DOM built during initialization")
        print("‚úÖ Auto-captioner completed")
        print("üéØ Starting interactive exploration mode...")
        interactor.interactive_exploration_mode()
        return

    if args.click_node:
        result = interactor.click_element(args.click_node)
        print(f"Result: {result}")
        return

    print("Use --interactive for manual node selection")
    print("Use --list-pending to see available nodes")
    print("Use --click-node <node_id> to test specific node")
    print("Use --manual-click for persistent manual click mode")


if __name__ == "__main__":
    main() 

==================================================

Path: utils\fdom\fdom_analyzer.py
File: fdom_analyzer.py
Code:
#!/usr/bin/env python3
import argparse
import json
from collections import Counter, defaultdict
from pathlib import Path

def load_fdom(path):
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def node_signature(node):
    # Use a tuple of key fields to identify duplicates (customize as needed)
    return (
        node.get("type"),
        tuple(node.get("crop", [])),
        node.get("text"),
        node.get("icon"),
        node.get("action"),
    )

def analyze_fdom(fdom):
    stats = {}
    states = fdom.get("states", {})
    edges = fdom.get("edges", [])
    stats["total_states"] = len(states)
    stats["total_edges"] = len(edges)
    node_type_counter = Counter()
    node_sig_counter = Counter()
    state_node_counts = {}
    crop_counter = Counter()
    all_nodes = []

    for state_id, state in states.items():
        nodes = state.get("nodes", [])
        state_node_counts[state_id] = len(nodes)
        for node in nodes:
            node_type = node.get("type", "unknown")
            node_type_counter[node_type] += 1
            sig = node_signature(node)
            node_sig_counter[sig] += 1
            crop = tuple(node.get("crop", []))
            crop_counter[crop] += 1
            all_nodes.append(node)

    stats["total_nodes"] = sum(state_node_counts.values())
    stats["node_types"] = node_type_counter.most_common()
    stats["states_with_most_nodes"] = sorted(state_node_counts.items(), key=lambda x: -x[1])[:10]
    stats["duplicate_nodes"] = [(sig, count) for sig, count in node_sig_counter.items() if count > 1]
    stats["duplicate_crops"] = [(crop, count) for crop, count in crop_counter.items() if count > 1]
    stats["avg_nodes_per_state"] = stats["total_nodes"] / stats["total_states"] if stats["total_states"] else 0

    return stats

def print_stats(stats):
    print("=== FDOM Analysis ===")
    print(f"Total states: {stats['total_states']}")
    print(f"Total nodes: {stats['total_nodes']}")
    print(f"Total edges: {stats['total_edges']}")
    print(f"Average nodes per state: {stats['avg_nodes_per_state']:.2f}")
    print("\nTop 10 node types:")
    for t, c in stats["node_types"][:10]:
        print(f"  {t}: {c}")
    print("\nStates with most nodes:")
    for state_id, count in stats["states_with_most_nodes"]:
        print(f"  {state_id}: {count} nodes")
    print(f"\nDuplicate nodes (by signature): {len(stats['duplicate_nodes'])}")
    for sig, count in stats["duplicate_nodes"][:10]:
        print(f"  {sig}: {count} times")
    print(f"\nDuplicate crops (bounding boxes): {len(stats['duplicate_crops'])}")
    for crop, count in stats["duplicate_crops"][:10]:
        print(f"  {crop}: {count} times")

def main():
    parser = argparse.ArgumentParser(description="Analyze FDOM JSON structure for statistics and repetition.")
    parser.add_argument("--fdom", required=True, help="Path to FDOM JSON file")
    args = parser.parse_args()

    fdom = load_fdom(args.fdom)
    stats = analyze_fdom(fdom)
    print_stats(stats)

if __name__ == "__main__":
    main()


==================================================

Path: utils\fdom\fdom_creator.py
File: fdom_creator.py
Code:
"""
FDOMCreator - Main orchestrator for the fDOM Framework
Integrates all modules into a single cohesive exploration service
"""
import json
import argparse
from pathlib import Path
from typing import Dict, Optional
from rich.console import Console
from rich.panel import Panel
from rich.prompt import Confirm, Prompt

# Import all our modules
from config_manager import ConfigManager
from screen_manager import ScreenManager  
from app_controller import AppController
from state_manager import StateManager
from element_interactor import ElementInteractor

class FDOMCreator:
    """
    Main orchestrator for fDOM exploration
    Coordinates all modules with centralized state management
    """
    
    def __init__(self):
        self.console = Console()
        
        # SINGLE config load point
        self.config_manager = ConfigManager()  # Loads fdom_config.json
        self.config = self.config_manager.config  # Direct access to all settings
        
        # Pass config to ALL modules
        self.screen_manager = ScreenManager(self.config_manager)
        self.app_controller = AppController(self.config_manager, self.screen_manager)
        
        # App-specific modules (initialized when app is set)
        self.state_manager = None
        self.element_interactor = None
        
        # Centralized state
        self.current_app_name = None
        self.exploration_active = False
        
        # CENTRALIZED path management
        self.project_root = Path(__file__).parent.parent.parent
        self.apps_base_dir = self.project_root / "apps"  # ROOT LEVEL
        
        # All modules use THESE paths, not their own
        self.app_controller.apps_base_dir = self.apps_base_dir  # Override
        
    def create_fdom_for_app(self, executable_path: str) -> Dict:
        """Complete fDOM creation workflow with smart detection"""
        
        try:
            # STEP 1: Screen Selection
            screen_id = self._handle_screen_selection()
            if not screen_id:
                return {"success": False, "error": "Screen selection failed"}
            
            # STEP 2: Launch Application  
            app_result = self._launch_application(executable_path, screen_id)
            if not app_result["success"]:
                return app_result
            
            # STEP 3: Initialize App-Specific Modules (loads existing fDOM if present)
            if not self._initialize_app_modules():
                return {"success": False, "error": "Module initialization failed"}
            
            # STEP 4: CONDITIONAL - Create Initial fDOM only if needed
            initial_state = None
            if len(self.state_manager.fdom_data.get("states", {})) == 0:
                # Fresh run - create initial fDOM
                self.console.print(f"[yellow]üÜï Fresh session detected - creating initial fDOM[/yellow]")
                initial_state = self._create_initial_fdom()
                if not initial_state["success"]:
                    return initial_state
            else:
                # Existing data - skip Step 4
                self.console.print(f"[green]‚ôªÔ∏è Existing session detected - skipping fDOM creation[/green]")
                initial_state = {"success": True, "mode": "resumed"}
            
            # STEP 5: Start Exploration Loop
            exploration_result = self._start_exploration_loop()
            
            return {
                "success": True,
                "app_name": self.current_app_name,
                "initial_state": initial_state,
                "exploration_result": exploration_result
            }
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Error in fDOM creation: {e}[/red]")
            return {"success": False, "error": str(e)}
    
    def _handle_screen_selection(self) -> Optional[int]:
        """Centralized screen selection - used by ALL modules"""
        
        # Check config for auto-selection
        auto_select = not self.config.get("capture.screen_selection_prompt", True)
        default_screen = self.config.get("capture.default_screen", 1)
        
        if auto_select:
            self.selected_screen_id = default_screen
            self.console.print(f"[green]üì∫ Auto-selected Screen {default_screen} from config[/green]")
        else:
            self.selected_screen_id = self.screen_manager.prompt_user_selection()
        
        # STORE for all modules to use
        self.screen_id = self.selected_screen_id
        return self.selected_screen_id
    
    def _launch_application(self, executable_path: str, screen_id: int) -> Dict:
        """Launch application and take initial screenshot"""
        self.console.print(f"\n[bold yellow]üöÄ STEP 2: LAUNCHING APPLICATION[/bold yellow]")
        
        # Launch with app_controller
        launch_result = self.app_controller.launch_app_for_exploration(executable_path, screen_id)
        
        if launch_result["success"]:
            self.current_app_name = launch_result["app_info"]["app_name"]
            
            # Take initial screenshot using app_controller's method (app-only)
            screenshot_path = self.app_controller.take_initial_screenshot()
            
            if screenshot_path:
                self.console.print(f"[green]‚úÖ Initial screenshot: {screenshot_path}[/green]")
                return {"success": True, "screenshot_path": screenshot_path}
            else:
                return {"success": False, "error": "Failed to take initial screenshot"}
        
        return launch_result
    
    def _initialize_app_modules(self) -> bool:
        """Initialize ALL modules with centralized state"""
        
        # Initialize StateManager first
        self.state_manager = StateManager(app_name=self.current_app_name)
        
        # Check for existing fDOM data
        fdom_file = self.apps_base_dir / self.current_app_name / "fdom.json"
        if fdom_file.exists():
            try:
                with open(fdom_file, 'r', encoding='utf-8') as f:
                    existing_fdom = json.load(f)
                
                self.state_manager.fdom_data = existing_fdom
                self.state_manager._rebuild_tracking_sets()
                
                states_count = len(existing_fdom.get('states', {}))
                pending_count = len(self.state_manager.pending_nodes)
                
                self.console.print(f"[green]üìÇ Loaded existing fDOM: {states_count} states[/green]")
                self.console.print(f"[green]üîÑ Restored: {pending_count} pending nodes[/green]")
                
            except Exception as e:
                self.console.print(f"[yellow]‚ö†Ô∏è Could not load existing fDOM: {e}[/yellow]")
        else:
            self.console.print("[cyan]üÜï Fresh session - no existing fDOM found[/cyan]")
        
        # Initialize ElementInteractor with loaded StateManager
        self.element_interactor = ElementInteractor(
            app_name=self.current_app_name,
            state_manager=self.state_manager,
            app_controller=self.app_controller
        )
        
        return True
    
    def _create_initial_fdom(self) -> Dict:
        """Create initial fDOM from screenshot"""
        self.console.print(f"\n[bold yellow]üìä STEP 4: CREATE INITIAL FDOM[/bold yellow]")
        
        # Get the screenshot path using centralized apps_base_dir
        initial_screenshot = self.apps_base_dir / self.current_app_name / "screenshots" / "S001.png"
        
        if not initial_screenshot.exists():
            return {"success": False, "error": "Initial screenshot not found"}
        
        # Use state_manager to create fDOM (this calls seraphine internally)
        state_data = self.state_manager.create_initial_fdom_state(str(initial_screenshot))
        
        if state_data:
            # CRITICAL FIX: Save fDOM to JSON file
            fdom_file_path = self.state_manager.save_fdom_to_file()
            self.console.print(f"[green]üíæ fDOM saved to: {fdom_file_path}[/green]")
            
            return {"success": True, "state_data": state_data, "fdom_file": fdom_file_path}
        else:
            return {"success": False, "error": "fDOM creation failed"}
    
    def _start_exploration_loop(self) -> Dict:
        """Start the interactive exploration loop WITH USER CHOICE"""
        self.console.print(f"\n[bold yellow]üéØ STEP 5: START EXPLORATION[/bold yellow]")
        
        # Display current exploration status
        self.state_manager.display_exploration_status()
        
        exploration_results = []
        self.exploration_active = True
        
        while self.exploration_active:
            # üéØ NEW: Let user select which node to test
            next_node = self._interactive_node_selection()
            
            if not next_node:
                self.console.print("[yellow]üõë Exploration stopped by user[/yellow]")
                break
            
            # Test the selected node
            self.console.print(f"\n[bold yellow]üéØ Testing: {next_node}[/bold yellow]")
            click_result = self.element_interactor.click_element(next_node)
            exploration_results.append({
                "node": next_node,
                "result": click_result
            })
            
            # Display result
            if click_result.success and click_result.state_changed:
                self.console.print(f"[green]‚úÖ {next_node}: State changed ‚Üí {click_result.new_state_id}[/green]")
            elif click_result.success:
                self.console.print(f"[yellow]‚ö™ {next_node}: No state change (non-interactive)[/yellow]")
            else:
                self.console.print(f"[red]‚ùå {next_node}: Failed - {click_result.error_message}[/red]")
        
        return {"nodes_explored": len(exploration_results), "results": exploration_results}

    def _interactive_node_selection(self) -> Optional[str]:
        """Let user choose which pending node to test"""
        
        # ‚úÖ FIX: ALWAYS reload from JSON before showing selection
        self._force_reload_fdom_from_file()
        
        if not self.state_manager.pending_nodes:
            self.console.print("[green]‚úÖ No pending nodes - all explored![/green]")
            return None
        
        # Collect all pending nodes with details
        pending_list = []
        for node_id in sorted(self.state_manager.pending_nodes):
            node_data = self._find_node_in_fdom(node_id)
            if node_data:
                state_id = self._find_node_state(node_id)
                pending_list.append({
                    'id': node_id,
                    'name': node_data.get('g_icon_name', 'Unknown'),
                    'type': node_data.get('type', 'unknown'),
                    'state': state_id or 'unknown'
                })
        
        # Display options
        self.console.print(f"\n[bold blue]üìã PENDING NODES ({len(pending_list)} total)[/bold blue]")
        for i, node in enumerate(pending_list, 1):
            state_display = node['state'].replace('_', '>') if node['state'] != 'unknown' else 'unknown'
            self.console.print(f"[white]{i:2d}. {node['id']} - {node['name']} ({node['type']}) - State: {state_display}[/white]")
        
        # Simple comma-separated list
        node_ids = [node['id'] for node in pending_list]
        self.console.print(f"\n[dim]Simple list: {', '.join(node_ids)}[/dim]")
        
        # Enhanced prompt
        self.console.print(Panel(
            f"[bold]Choose a node to test:[/bold]\n\n"
            f"‚Ä¢ Enter number (1-{len(pending_list)})\n"
            f"‚Ä¢ Enter node ID directly (e.g., H1_2)\n"
            f"‚Ä¢ Enter 'skip' to manually describe\n"
            f"‚Ä¢ Enter 'exit' to stop exploration",
            title="üéØ Node Selection",
            border_style="cyan"
        ))
        
        user_input = Prompt.ask("Your choice").strip()
        
        if user_input.lower() == 'exit':
            return None
        
        if user_input.lower() == 'skip':
            # Let user select which node to skip
            skip_choice = Prompt.ask(f"Which node to skip? (1-{len(pending_list)} or node_id)")
            selected_node = self._parse_node_choice(skip_choice, pending_list, node_ids)
            if selected_node:
                self._handle_manual_skip(selected_node)
            return self._interactive_node_selection()  # Recurse to show menu again
        
        # Parse the selection
        return self._parse_node_choice(user_input, pending_list, node_ids)

    def _parse_node_choice(self, user_input: str, pending_list: list, node_ids: list) -> Optional[str]:
        """Parse user input and return selected node_id"""
        try:
            choice_num = int(user_input)
            if 1 <= choice_num <= len(pending_list):
                selected_node = pending_list[choice_num - 1]['id']
                self.console.print(f"[green]‚úÖ Selected: {selected_node}[/green]")
                return selected_node
            else:
                self.console.print(f"[red]‚ùå Invalid number. Please choose 1-{len(pending_list)}[/red]")
                return None
        except ValueError:
            # Try as direct node ID
            if user_input in node_ids:
                self.console.print(f"[green]‚úÖ Selected: {user_input}[/green]")
                return user_input
            else:
                self.console.print(f"[red]‚ùå Invalid choice. Available: {', '.join(node_ids)}[/red]")
                return None

    def _handle_manual_skip(self, node_id: str):
        """Handle manual skip with description"""
        custom_description = Prompt.ask(
            f"[blue]Describe {node_id}[/blue] (e.g., 'closes app', 'opens file menu')"
        )
        
        self.state_manager.mark_node_explored(
            node_id, 
            click_result=None,
            interaction_type="manual_skip"
        )
        
        self._add_manual_description(node_id, custom_description)
        self.state_manager.save_fdom_to_file()
        
        self.console.print(f"[blue]üìù {node_id}: Skipped - '{custom_description}'[/blue]")

    def _find_node_in_fdom(self, unique_node_id: str) -> Optional[Dict]:
        """Find node data using state::node_id format"""
        if "::" in unique_node_id:
            state_name, node_id = unique_node_id.split("::", 1)
            state_data = self.state_manager.fdom_data.get("states", {}).get(state_name, {})
            return state_data.get("nodes", {}).get(node_id)
        
        # Fallback for old format
        return self._find_node_in_fdom_old(unique_node_id)

    def _find_node_state(self, unique_node_id: str) -> Optional[str]:
        """Find which state contains the node - handle state::node_id format"""
        if "::" in unique_node_id:
            state_name, node_id = unique_node_id.split("::", 1)
            # Verify the node exists in that state
            state_data = self.state_manager.fdom_data.get("states", {}).get(state_name, {})
            if node_id in state_data.get("nodes", {}):
                return state_name
            return None
        
        # Fallback for old format
        for state_id, state_data in self.state_manager.fdom_data.get("states", {}).items():
            if unique_node_id in state_data.get("nodes", {}):
                return state_id
        return None


    def _add_manual_description(self, node_id: str, description: str) -> None:
        """Add manual description to a node"""
        for state_id, state_data in self.state_manager.fdom_data["states"].items():
            if node_id in state_data.get("nodes", {}):
                node = state_data["nodes"][node_id]
                node["status"] = "manual_skip"
                if "interactivity" not in node:
                    node["interactivity"] = {}
                node["interactivity"]["manual_description"] = description
                node["interactivity"]["type"] = "manual_skip"
                break

    def _force_reload_fdom_from_file(self) -> None:
        """Force reload fDOM data from JSON file to ensure latest state"""
        try:
            fdom_file = self.apps_base_dir / self.current_app_name / "fdom.json"
            if fdom_file.exists():
                with open(fdom_file, 'r', encoding='utf-8') as f:
                    latest_fdom = json.load(f)
                
                # Replace in-memory data with latest from file
                self.state_manager.fdom_data = latest_fdom
                
                # Rebuild tracking sets with fresh data
                self.state_manager._rebuild_tracking_sets()
                
                self.console.print(f"[cyan]üìÇ Reloaded fresh fDOM: {len(self.state_manager.pending_nodes)} pending nodes[/cyan]")
            else:
                self.console.print("[yellow]‚ö†Ô∏è No fDOM file found to reload[/yellow]")
                
        except Exception as e:
            self.console.print(f"[red]‚ùå Failed to reload fDOM: {e}[/red]")

def main():
    parser = argparse.ArgumentParser(description="fDOM Creator - Complete Application Exploration")
    parser.add_argument("executable_path", help="Path to executable to explore")
    parser.add_argument("--continue-session", action="store_true", help="Continue existing session")
    
    args = parser.parse_args()
    
    # Create and run fDOM creator
    creator = FDOMCreator()
    result = creator.create_fdom_for_app(args.executable_path)
    
    if result["success"]:
        print(f"\nüéâ fDOM creation completed for {result['app_name']}")
    else:
        print(f"\n‚ùå fDOM creation failed: {result['error']}")

if __name__ == "__main__":
    main()


==================================================

Path: utils\fdom\interaction_types.py
File: interaction_types.py
Code:
"""Data classes and type definitions for element interaction"""
from dataclasses import dataclass
from typing import Optional, List, Tuple, Dict


@dataclass
class ClickResult:
    """Result of clicking an element"""
    success: bool
    state_changed: bool
    new_state_id: Optional[str] = None
    error_message: Optional[str] = None
    screenshot_path: Optional[str] = None
    interaction_type: Optional[str] = None
    wait_time_used: Optional[float] = None
    hash_before: Optional[str] = None
    hash_after: Optional[str] = None
    after_screenshot: Optional[str] = None
    diff_result: Optional[Dict] = None


@dataclass
class BacktrackStrategy:
    """Strategy for returning to previous state"""
    method: str  # "close_icon", "same_location", "esc_key", "human_input"
    coordinates: Optional[Tuple[int, int]] = None
    special_keys: Optional[List[str]] = None
    success: bool = False
    attempts: int = 0


==================================================

Path: utils\fdom\interaction_utils.py
File: interaction_utils.py
Code:
"""Utility functions for element interaction"""
import os
from pathlib import Path
from typing import Dict, Optional, Tuple, List


def sanitize_app_name(app_name: str) -> str:
    """Convert app path to clean app name for folder/file operations"""
    if os.path.sep in app_name or app_name.endswith('.exe'):
        clean_name = Path(app_name).stem
    else:
        clean_name = app_name
    
    clean_name = clean_name.lower().replace(' ', '_').replace('-', '_')
    clean_name = clean_name.replace("++", "_plus_plus")
    
    # Remove common suffixes
    suffixes_to_remove = ["_setup", "_installer", "_x64", "_x86", "_win32", "_win64"]
    for suffix in suffixes_to_remove:
        if clean_name.endswith(suffix):
            clean_name = clean_name[:-len(suffix)]
            break
    
    # Remove problematic characters
    clean_name = ''.join(c for c in clean_name if c.isalnum() or c == '_')
    
    return clean_name


def sanitize_node_id_for_files(node_id: str) -> str:
    """Convert node ID to file-safe format"""
    return node_id.replace("::", "__").replace(":", "_").replace("/", "_").replace("\\", "_")


==================================================

Path: utils\fdom\interactive_cli.py
File: interactive_cli.py
Code:
"""Interactive CLI for element exploration"""
from typing import List, Dict
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.prompt import Prompt
from pathlib import Path
import time


class InteractiveCLI:
    """Handles interactive command-line interface for exploration"""
    
    def __init__(self, element_interactor):
        self.interactor = element_interactor
        self.console = Console()
    
    def run_interactive_mode(self) -> None:
        """Enhanced interactive mode with natural navigation"""
        self.console.print(Panel(
            "[bold]üéÆ Natural Navigation Mode[/bold]\n\n"
            "[green]Commands:[/green]\n"
            "‚Ä¢ Enter number to click element\n"
            "‚Ä¢ 0 - Run auto-captioner on all elements\n"
            "‚Ä¢ -1 - Auto-explore mode (explore 5 nodes sequentially)\n"
            "‚Ä¢ 'back' - Natural backtrack to previous state\n"
            "‚Ä¢ 'root' - Backtrack to root state\n"
            "‚Ä¢ 'chain' - Show current navigation chain\n"
            "‚Ä¢ 'quit' - Exit interactive mode",
            title="üß≠ Interactive Explorer",
            border_style="blue"
        ))
        
        while True:
            try:
                # Show current state
                self.console.print(f"\n[bold]üìç Current State: {self.interactor.current_state_id}[/bold]")
                
                # Show pending nodes
                pending_list = self.show_pending_nodes_list()
                
                if not pending_list:
                    self.console.print("[yellow]No more nodes to explore![/yellow]")
                    break
                
                # Get user input
                user_input = Prompt.ask("Enter number to click, 0 for auto-captioner, -1 for auto-explore, or command")
                
                # Handle commands
                if user_input.lower() == 'quit':
                    break
                elif user_input.strip() == '0':
                    # Auto captioner
                    self._run_auto_captioner(pending_list)
                    continue
                elif user_input.strip() == '-1':
                    # ‚úÖ NEW: Auto-explore mode
                    self._run_auto_explorer(pending_list)
                    continue
                elif user_input.lower() == 'back':
                    self._handle_back_command()
                    continue
                elif user_input.lower() == 'root':
                    self._handle_root_command()
                    continue
                elif user_input.lower() == 'chain':
                    self._show_navigation_chain()
                    continue
                
                # Handle number input
                try:
                    index = int(user_input) - 1
                    if 0 <= index < len(pending_list):
                        self._interactive_click_node_by_index(index, pending_list)
                    else:
                        self.console.print("[red]‚ùå Invalid number. Please try again.[/red]")
                except ValueError:
                    self.console.print("[red]‚ùå Invalid input. Enter a number or command.[/red]")
                
            except KeyboardInterrupt:
                self.console.print("\n[yellow]üëã Exiting interactive mode...[/yellow]")
                break
    
    def show_pending_nodes_list(self, showTable = True) -> List[str]:
        """Show pending nodes in natural discovery order and return the list"""
        if not self.interactor.state_manager.pending_nodes:
            self.console.print("[yellow]‚ö†Ô∏è No pending nodes available.[/yellow]")
            return []
        
        # ‚úÖ FIX: Get nodes in discovery order from fDOM states
        pending_list = []
        
        # Iterate through states in creation order
        states = self.interactor.state_manager.fdom_data.get("states", {})
        state_names = sorted(states.keys())  # This gives us root, root_file, etc. in order
        
        for state_name in state_names:
            state_data = states[state_name]
            nodes = state_data.get("nodes", {})
            
            # Get nodes in the order they appear in the JSON (discovery order)
            for node_id, node_data in nodes.items():
                unique_node_id = f"{state_name}::{node_id}"
                
                # Only include if it's still pending
                if unique_node_id in self.interactor.state_manager.pending_nodes:
                    pending_list.append(unique_node_id)
        
        # ‚úÖ NEW: Filter out "unanalyzed" elements
        filtered_pending_list = []
        for unique_node_id in pending_list:
            node_data = self.interactor._find_node_in_fdom(unique_node_id)
            if node_data:
                element_name = node_data.get('g_icon_name', 'unknown')
                # Skip elements with "unanalyzed" names
                if element_name.lower() != 'unanalyzed':
                    filtered_pending_list.append(unique_node_id)
        
        # Use filtered list for display
        display_list = filtered_pending_list
        unfiltered_count = len(pending_list)
        filtered_count = len(display_list)
        
        # Update table title to show filtered count
        filter_info = f" (Showing {filtered_count}/{unfiltered_count} analyzed elements)" if filtered_count != unfiltered_count else ""
        table = Table(title=f"üü° Pending Nodes - Choose a Number (Discovery Order){filter_info}")
        table.add_column("#", style="cyan", width=3)
        table.add_column("Node ID", style="green", width=8)
        table.add_column("Element Name", style="yellow", width=25)
        table.add_column("Type", style="magenta", width=6)
        table.add_column("G-Type", style="bright_magenta", width=6)
        table.add_column("Group", style="blue", width=6)
        table.add_column("Enabled", style="cyan", width=8)
        table.add_column("Interactive", style="green", width=11)
        
        for i, unique_node_id in enumerate(display_list, 1):
            # Handle state::node_id format
            if "::" in unique_node_id:
                state_name, node_id = unique_node_id.split("::", 1)
            else:
                state_name = "unknown"
                node_id = unique_node_id
            
            # Find node data
            node_data = self.interactor._find_node_in_fdom(unique_node_id)
            
            if node_data:
                element_name = node_data.get('g_icon_name', 'unknown')
                node_type = node_data.get('type', 'unknown')  # Original type
                g_type = node_data.get('g_type', 'icon')      # New Gemini type
                group = node_data.get('group', 'unknown')
                
                # ‚úÖ ENHANCED: Combined enabled + interactive status
                enabled = node_data.get('g_enabled', True)
                interactive = node_data.get('g_interactive', True)
                
                # Create combined status indicator
                if not enabled:
                    status = "üö´ Disabled"
                elif not interactive:
                    status = "‚ÑπÔ∏è Info Only"
                else:
                    status = "‚úÖ Active"
                
            else:
                element_name = "Not found"
                node_type = "unknown"
                g_type = "unknown"
                group = "unknown"
                status = "‚ùì Unknown"
            
            # ‚úÖ Truncate long element names to fit
            if len(element_name) > 25:
                element_name = element_name[:22] + "..."
            
            enabled_status = "‚úÖ Yes" if enabled else "üö´ No"
            interactive_status = "‚ö° Yes" if interactive else "‚ÑπÔ∏è Info"
            
            table.add_row(
                str(i),
                node_id,
                element_name,
                node_type,    # Original yolo/ocr type
                g_type,       # New Gemini type
                group,
                enabled_status,
                interactive_status
            )
        if showTable:
            self.console.print(table)
        
        # ‚úÖ IMPORTANT: Return the filtered list so numbering works correctly
        return display_list
    
    def _interactive_click_node_by_index(self, index: int, pending_list: List[str]) -> None:
        """Click a node by its index in the pending list"""
        
        if index < 0 or index >= len(pending_list):
            self.console.print(f"[red]‚ùå Invalid number. Choose 1-{len(pending_list)}[/red]")
            return
        
        selected_node_id = pending_list[index]
        
        # Find node info for display
        node_data = self.interactor._find_node_in_fdom(selected_node_id)
        element_name = node_data.get('g_icon_name', 'unknown') if node_data else 'unknown'
        
        self.console.print(f"\n[bold yellow]üéØ {index + 1}. {element_name} ({selected_node_id})[/bold yellow]")
        self.console.print(f"[cyan]üöÄ Executing full interaction workflow...[/cyan]")
        
        # Perform the click with full workflow
        result = self.interactor.click_element(selected_node_id)
        
        # Show detailed result
        if result.success:
            if result.state_changed:
                self.console.print(f"[bold green]‚úÖ SUCCESS: State changed to {result.new_state_id}![/bold green]")
                self.console.print(f"[cyan]üì∏ Screenshots: Before/After captured[/cyan]")
                self.console.print(f"[cyan]üîç Visual diff: {result.screenshot_path}[/cyan]")
                self.console.print(f"[cyan]ü§ñ Seraphine: Analyzed new elements[/cyan]")
                self.console.print(f"[cyan]üíæ fDOM: Updated and saved[/cyan]")
            else:
                self.console.print(f"[yellow]‚úÖ SUCCESS: Element marked as {result.interaction_type}[/yellow]")
                if result.interaction_type == "non_interactive":
                    self.console.print(f"[dim]‚ÑπÔ∏è This element doesn't change the UI[/dim]")
        else:
            self.console.print(f"[red]‚ùå FAILED: {result.error_message}[/red]")
        
        # Show updated exploration stats
        explored_count = len(self.interactor.state_manager.explored_nodes)
        pending_count = len(self.interactor.state_manager.pending_nodes)
        non_interactive_count = len(self.interactor.state_manager.non_interactive_nodes)
        
        self.console.print(f"\n[cyan]üìä Progress: {explored_count} explored, {pending_count} pending, {non_interactive_count} non-interactive[/cyan]")
    
    def _handle_back_command(self):
        """Handle 'back' command for natural backtracking"""
        if len(self.interactor.navigation_engine.navigation_chain) == 0:
            self.console.print("[yellow]‚ö†Ô∏è Already at starting point[/yellow]")
            return
        
        # Get previous state
        previous_step = self.interactor.navigation_engine.navigation_chain[-1]
        target_state = previous_step['from_state']
        
        self.console.print(f"[cyan]üîÑ Backing up to: {target_state}[/cyan]")
        
        success = self.interactor.navigation_engine.navigate_back_to_state(target_state)
        
        if success:
            self.console.print(f"[green]‚úÖ Successfully navigated back to {target_state}[/green]")
        else:
            self.console.print(f"[red]‚ùå Failed to navigate back to {target_state}[/red]")
    
    def _handle_root_command(self):
        """Handle 'root' command to return to root state"""
        self.console.print(f"[cyan]üè† Returning to root state...[/cyan]")
        
        success = self.interactor.navigation_engine.navigate_back_to_state("root")
        
        if success:
            self.console.print(f"[green]‚úÖ Successfully returned to root[/green]")
            # Clear navigation chain
            self.interactor.navigation_engine.navigation_chain.clear()
        else:
            self.console.print(f"[red]‚ùå Failed to return to root[/red]")
    
    def _show_navigation_chain(self):
        """Show current navigation chain"""
        chain = self.interactor.navigation_engine.navigation_chain
        
        if not chain:
            self.console.print("[yellow]üìç Navigation chain is empty (at starting point)[/yellow]")
            return
        
        self.console.print("[cyan]üîó Current Navigation Chain:[/cyan]")
        for i, step in enumerate(chain):
            self.console.print(f"[dim]  {i+1}. {step['from_state']} ‚Üí {step['to_state']} (via {step['element_name']})[/dim]")
    
    def _run_auto_captioner(self, pending_list: List[str]) -> None:
        """Run auto captioner on all pending elements"""
        from .auto_captioner import AutoCaptioner
        
        self.console.print(f"\n[bold yellow]ü§ñ AUTO CAPTIONER STARTING...[/bold yellow]")
        self.console.print(f"[cyan]Will hover over {len(pending_list)} elements to discover captions/tooltips[/cyan]")
        
        # Create auto captioner
        auto_captioner = AutoCaptioner(self.interactor)
        
        # Discover captions
        discovered_captions = auto_captioner.discover_all_captions(pending_list)
        
        # ‚úÖ ENSURE CLEANUP: Explicitly call cleanup after completion
        self.console.print(f"[yellow]üßπ Cleaning up temporary interaction screenshots...[/yellow]")
        auto_captioner._cleanup_temp_files()
        
        # Show results
        if discovered_captions:
            # self.console.print(f"\n[bold green]üéâ CAPTIONS DISCOVERED:[/bold green]")
            for node_id, crop_path in discovered_captions.items():
                clean_node_id = node_id.split("::")[-1] if "::" in node_id else node_id
                crop_filename = Path(crop_path).name
                # self.console.print(f"[green]üì∏ {clean_node_id}: {crop_filename}[/green]")
        else:
            self.console.print(f"[yellow]‚ÑπÔ∏è No captions found for any elements[/yellow]")
        
        # input("\nPress Enter to continue...") 
    
    def _run_auto_explorer(self, pending_list: List[str]) -> None:
        """Auto-explore mode: sequentially explore up to 5 nodes"""
        
        if not pending_list:
            self.console.print("[yellow]‚ö†Ô∏è No pending nodes to explore[/yellow]")
            return
        
        self.console.print(f"\n[bold cyan]üöÄ AUTO-EXPLORE MODE STARTING...[/bold cyan]")
        self.console.print(f"[cyan]Will explore up to 5 nodes sequentially[/cyan]")
        self.console.print(f"[dim]Total pending: {len(pending_list)} nodes[/dim]")
        
        # Track exploration results
        exploration_results = []
        explored_count = 0
        max_explorations = 50
        
        # ‚úÖ FIX: Use a copy of the original list and track position
        remaining_nodes = pending_list.copy()
        
        while explored_count < max_explorations and remaining_nodes:
            # Take the first node from remaining list
            selected_node_id = remaining_nodes.pop(0)
            
            # Find node info for display
            node_data = self.interactor._find_node_in_fdom(selected_node_id)
            element_name = node_data.get('g_icon_name', 'unknown') if node_data else 'unknown'
            
            self.console.print(f"\n[bold yellow]üéØ AUTO-EXPLORE {explored_count + 1}/{max_explorations}: {element_name} ({selected_node_id})[/bold yellow]")
            self.console.print(f"[cyan]üöÄ Executing full interaction workflow...[/cyan]")
            
            # Perform the click with full workflow
            try:
                result = self.interactor.click_element(selected_node_id)
                
                # Track result
                exploration_results.append({
                    'node_id': selected_node_id,
                    'element_name': element_name,
                    'success': result.success,
                    'state_changed': result.state_changed if result.success else False,
                    'interaction_type': result.interaction_type if result.success else 'failed',
                    'error_message': result.error_message if not result.success else None
                })
                
                # Show detailed result
                if result.success:
                    if result.state_changed:
                        self.console.print(f"[bold green]‚úÖ SUCCESS: State changed to {result.new_state_id}![/bold green]")
                        self.console.print(f"[cyan]üì∏ Screenshots: Before/After captured[/cyan]")
                        self.console.print(f"[cyan]üîç Visual diff: {result.screenshot_path}[/cyan]")
                        self.console.print(f"[cyan]ü§ñ Seraphine: Analyzed new elements[/cyan]")
                        self.console.print(f"[cyan]üíæ fDOM: Updated and saved[/cyan]")
                    else:
                        self.console.print(f"[yellow]‚úÖ SUCCESS: Element marked as {result.interaction_type}[/yellow]")
                        if result.interaction_type == "non_interactive":
                            self.console.print(f"[dim]‚ÑπÔ∏è This element doesn't change the UI[/dim]")
                else:
                    self.console.print(f"[red]‚ùå FAILED: {result.error_message}[/red]")
                    self.console.print(f"[yellow]‚è≠Ô∏è Skipping to next node...[/yellow]")
                
                # ‚úÖ CRITICAL: Increment counter regardless of success/failure
                explored_count += 1
                
                # Small delay between explorations for stability
                if explored_count < max_explorations and remaining_nodes:  # Don't wait after the last one
                    self.console.print(f"[dim]‚è≥ Waiting 2 seconds before next exploration...[/dim]")
                    time.sleep(2)
                    
            except Exception as e:
                self.console.print(f"[red]‚ùå EXCEPTION during exploration: {e}[/red]")
                exploration_results.append({
                    'node_id': selected_node_id,
                    'element_name': element_name,
                    'success': False,
                    'state_changed': False,
                    'interaction_type': 'exception',
                    'error_message': str(e)
                })
                
                # ‚úÖ CRITICAL: Increment counter even on exception
                explored_count += 1
                
                self.console.print(f"[yellow]‚è≠Ô∏è Skipping to next node...[/yellow]")
        
        # ‚úÖ SAFETY: Show why we stopped
        if explored_count >= max_explorations:
            self.console.print(f"[green]‚úÖ Completed {max_explorations} explorations as planned[/green]")
        elif not remaining_nodes:
            self.console.print(f"[yellow]‚ö†Ô∏è No more nodes to explore (completed {explored_count} explorations)[/yellow]")
        
        # Show final summary
        self._show_auto_explore_summary(exploration_results)
        
        # Show updated exploration stats
        explored_count_total = len(self.interactor.state_manager.explored_nodes)
        pending_count = len(self.interactor.state_manager.pending_nodes)
        non_interactive_count = len(self.interactor.state_manager.non_interactive_nodes)
        
        self.console.print(f"\n[cyan]üìä Progress: {explored_count_total} explored, {pending_count} pending, {non_interactive_count} non-interactive[/cyan]")
        
        # Pause for user review
        self.console.print(f"\n[bold yellow]‚è∏Ô∏è AUTO-EXPLORE SESSION COMPLETE[/bold yellow]")
        input("Press Enter to continue with manual exploration...")

    def _show_auto_explore_summary(self, results: List[Dict]) -> None:
        """Show summary of auto-exploration results"""
        
        if not results:
            return
        
        self.console.print(f"\n[bold blue]üìã AUTO-EXPLORE SUMMARY:[/bold blue]")
        
        # Create summary table
        summary_table = Table(title="Auto-Exploration Results")
        summary_table.add_column("#", style="cyan", width=3)
        summary_table.add_column("Element", style="yellow", width=20)
        summary_table.add_column("Result", style="green", width=15)
        summary_table.add_column("Type", style="magenta", width=12)
        summary_table.add_column("Error", style="red", width=25)
        
        success_count = 0
        state_change_count = 0
        
        for i, result in enumerate(results, 1):
            element_name = result['element_name']
            if len(element_name) > 20:
                element_name = element_name[:17] + "..."
                
            error_msg = result.get('error_message', '')
            if error_msg and len(error_msg) > 25:
                error_msg = error_msg[:22] + "..."
            
            # Format result status
            if result['success']:
                if result['state_changed']:
                    status = "‚úÖ State Change"
                    state_change_count += 1
                else:
                    status = f"‚úÖ {result['interaction_type'].title()}"
                success_count += 1
                error_msg = "-"
            else:
                status = "‚ùå Failed"
            
            summary_table.add_row(
                str(i),
                element_name,
                status,
                result['interaction_type'],
                error_msg or "-"
            )
        
        self.console.print(summary_table)
        
        # Show statistics
        total = len(results)
        if total > 0:
            self.console.print(f"\n[cyan]üìà Statistics:[/cyan]")
            self.console.print(f"[green]‚úÖ Successful: {success_count}/{total} ({success_count/total*100:.1f}%)[/green]")
            self.console.print(f"[blue]üîÑ State Changes: {state_change_count}/{total} ({state_change_count/total*100:.1f}%)[/blue]")
            self.console.print(f"[red]‚ùå Failed: {total-success_count}/{total} ({(total-success_count)/total*100:.1f}%)[/red]") 

==================================================

Path: utils\fdom\navigation_engine.py
File: navigation_engine.py
Code:
"""Navigation and backtracking strategies - Natural approach"""
import time
from typing import Dict, Optional, List, Tuple
from rich.console import Console
from pathlib import Path

from .interaction_types import BacktrackStrategy


class NavigationEngine:
    """Handles state navigation and natural backtracking strategies"""
    
    def __init__(self, app_controller, visual_differ, state_manager, element_interactor):
        self.app_controller = app_controller
        self.visual_differ = visual_differ
        self.state_manager = state_manager
        self.element_interactor = element_interactor
        self.console = Console()
        # ‚úÖ Track navigation chain for backtracking
        self.navigation_chain = []  # [C1, C2, C3] in order of clicking
    
    def navigate_to_state(self, target_state: str, current_state: str) -> bool:
        """Enhanced navigation with MULTI-HOP support"""
        
        self.console.print(f"[cyan]üß≠ NAVIGATION: {current_state} ‚Üí {target_state}[/cyan]")
        
        # ‚úÖ FIND NAVIGATION PATH using breadth-first search
        navigation_path = self._find_navigation_path(current_state, target_state)
        
        if not navigation_path:
            self.console.print(f"[red]‚ùå No navigation path found from {current_state} to {target_state}[/red]")
            return False
        
        self.console.print(f"[cyan]üó∫Ô∏è Navigation path: {' ‚Üí '.join(navigation_path)}[/cyan]")
        
        # ‚úÖ EXECUTE MULTI-HOP NAVIGATION
        current = current_state
        for i in range(1, len(navigation_path)):
            next_state = navigation_path[i]
            
            self.console.print(f"[cyan]üöÄ Step {i}: {current} ‚Üí {next_state}[/cyan]")
            
            if not self._execute_single_hop(current, next_state):
                self.console.print(f"[red]‚ùå Failed at step {i}: {current} ‚Üí {next_state}[/red]")
                return False
            
            current = next_state
            self.element_interactor.current_state_id = current
            
            # Wait for UI transition
            time.sleep(1)
        
        self.console.print(f"[green]‚úÖ Multi-hop navigation successful: {current_state} ‚Üí {target_state}[/green]")
        return True
    
    def _find_navigation_path(self, start_state: str, target_state: str) -> List[str]:
        """Find shortest path between states using BFS"""
        if start_state == target_state:
            return [start_state]
        
        # Build graph from edges
        graph = {}
        edges = self.state_manager.fdom_data.get("edges", [])
        
        for edge in edges:
            from_state = edge.get("from")
            to_state = edge.get("to")
            if from_state and to_state:
                if from_state not in graph:
                    graph[from_state] = []
                graph[from_state].append(to_state)
        
        # BFS to find shortest path
        from collections import deque
        
        queue = deque([(start_state, [start_state])])
        visited = {start_state}
        
        while queue:
            current_state, path = queue.popleft()
            
            if current_state == target_state:
                return path
            
            for neighbor in graph.get(current_state, []):
                if neighbor not in visited:
                    visited.add(neighbor)
                    queue.append((neighbor, path + [neighbor]))
        
        return []  # No path found
    
    def _execute_single_hop(self, from_state: str, to_state: str) -> bool:
        """Execute single navigation hop (original logic)"""
        # Find the edge that leads to to_state
        edges = self.state_manager.fdom_data.get("edges", [])
        target_edge = None
        
        for edge in edges:
            if edge.get("from") == from_state and edge.get("to") == to_state:
                target_edge = edge
                break
        
        if not target_edge:
            self.console.print(f"[red]‚ùå No edge found: {from_state} ‚Üí {to_state}[/red]")
            return False
        
        # Extract and execute trigger node (existing logic)
        action = target_edge.get("action", "")
        if not action.startswith("click:"):
            self.console.print(f"[red]‚ùå Invalid action format: {action}[/red]")
            return False
        
        trigger_node_id = action.split(":", 1)[1]
        if "::" in trigger_node_id:
            clean_trigger_id = trigger_node_id.split("::", 1)[1]
        else:
            clean_trigger_id = trigger_node_id
        
        # Find trigger node in from_state
        from_state_data = self.state_manager.fdom_data["states"].get(from_state, {})
        trigger_node = from_state_data.get("nodes", {}).get(clean_trigger_id)
        
        if not trigger_node:
            self.console.print(f"[red]‚ùå Trigger node {clean_trigger_id} not found in {from_state}[/red]")
            return False
        
        # Execute click
        window_pos = self.element_interactor._get_current_window_position()
        if not window_pos:
            return False
        
        source_element_name = trigger_node.get('g_icon_name', 'unknown')
        
        # Track navigation
        nav_info = {
            'node_id': clean_trigger_id,
            'node_data': trigger_node,
            'element_name': source_element_name,
            'from_state': from_state,
            'to_state': to_state
        }
        self.navigation_chain.append(nav_info)
        
        click_result = self.element_interactor.click_engine.execute_click_with_centroids(
            trigger_node, window_pos, source_element_name
        )
        
        if click_result.success:
            self.console.print(f"[green]‚úÖ Single hop successful: {from_state} ‚Üí {to_state}[/green]")
            return True
        else:
            self.navigation_chain.pop()
            self.console.print(f"[red]‚ùå Single hop failed: {click_result.error_message}[/red]")
            return False
    
    def navigate_back_to_state(self, target_state_id: str, failure_reference_screenshot: str = None) -> bool:
        """NATURAL BACKTRACKING: 4-step strategy based on visual cues"""
        
        self.console.print(f"[bold blue]üîÑ NATURAL BACKTRACKING to {target_state_id}[/bold blue]")
        self.console.print(f"[cyan]üîó Navigation chain: {len(self.navigation_chain)} steps[/cyan]")
        
        # ‚úÖ STRATEGY 1: Look for close buttons in current state
        if self._try_close_button_strategy():
            if self._verify_reached_target(target_state_id):
                return True
        
        # ‚úÖ STRATEGY 2: Try ESC key
        if self._try_esc_key_strategy():
            if self._verify_reached_target(target_state_id):
                return True
        
        # ‚úÖ STRATEGY 3: Try clicking previous navigation elements (C2, C1...)
        if self._try_reverse_navigation_chain():
            if self._verify_reached_target(target_state_id):
                return True
        
        # ‚úÖ STRATEGY 4: Ask human
        return self._try_human_input_strategy(target_state_id)
    
    def _try_close_button_strategy(self) -> bool:
        """STRATEGY 1: Look for close/cancel/x buttons in current state"""
        self.console.print(f"[yellow]üîß Strategy 1: Looking for close buttons...[/yellow]")
        
        current_state_data = self.state_manager.fdom_data["states"].get(self.element_interactor.current_state_id, {})
        current_nodes = current_state_data.get("nodes", {})
        
        # Look for close-related elements
        close_keywords = ["close", "cancel", "x", "‚úï", "√ó", "ok", "done", "finish"]
        
        for node_id, node_data in current_nodes.items():
            element_name = node_data.get('g_icon_name', '').lower()
            
            for keyword in close_keywords:
                if keyword in element_name:
                    self.console.print(f"[green]‚úÖ Found close button: {element_name}[/green]")
                    
                    # Try clicking it
                    window_pos = self.element_interactor._get_current_window_position()
                    if window_pos:
                        click_result = self.element_interactor.click_engine.execute_click_with_centroids(
                            node_data, window_pos, element_name
                        )
                        
                        if click_result.success:
                            self.console.print(f"[green]üéâ Close button clicked successfully![/green]")
                            time.sleep(1)  # Wait for close animation
                            return True
        
        self.console.print(f"[yellow]‚ö†Ô∏è No close buttons found[/yellow]")
        return False
    
    def _try_esc_key_strategy(self) -> bool:
        """STRATEGY 2: Try ESC key"""
        self.console.print(f"[yellow]üîß Strategy 2: Trying ESC key...[/yellow]")
        
        try:
            success = self.app_controller.gui_api.send_esc_enhanced()
            
            if success:
                self.console.print(f"[green]‚úÖ ESC key sent successfully[/green]")
                time.sleep(1)
                return True
            else:
                self.console.print(f"[yellow]‚ö†Ô∏è ESC key failed[/yellow]")
                return False
                
        except Exception as e:
            self.console.print(f"[red]‚ùå ESC strategy failed: {e}[/red]")
            return False
    
    def _try_reverse_navigation_chain(self) -> bool:
        """STRATEGY 3: Try clicking previous navigation elements in reverse order"""
        self.console.print(f"[yellow]üîß Strategy 3: Trying reverse navigation chain...[/yellow]")
        
        if not self.navigation_chain:
            self.console.print(f"[yellow]‚ö†Ô∏è No navigation chain to reverse[/yellow]")
            return False
        
        # Try in reverse order: C3 ‚Üí C2 ‚Üí C1
        for i in range(len(self.navigation_chain) - 1, -1, -1):
            nav_step = self.navigation_chain[i]
            
            self.console.print(f"[cyan]üîÑ Trying to click: {nav_step['element_name']} (step {i+1})[/cyan]")
            
            # Check if this element is still visible in current state
            current_state_data = self.state_manager.fdom_data["states"].get(self.element_interactor.current_state_id, {})
            current_nodes = current_state_data.get("nodes", {})
            
            if nav_step['node_id'] in current_nodes:
                # Element still visible, try clicking it
                window_pos = self.element_interactor._get_current_window_position()
                if window_pos:
                    click_result = self.element_interactor.click_engine.execute_click_with_centroids(
                        nav_step['node_data'], window_pos, nav_step['element_name']
                    )
                    
                    if click_result.success:
                        self.console.print(f"[green]‚úÖ Reverse navigation successful: {nav_step['element_name']}[/green]")
                        time.sleep(1)
                        # Remove this and subsequent steps from chain
                        self.navigation_chain = self.navigation_chain[:i]
                        return True
            else:
                self.console.print(f"[dim]‚ö†Ô∏è Element {nav_step['element_name']} no longer visible[/dim]")
        
        self.console.print(f"[yellow]‚ö†Ô∏è Reverse navigation chain failed[/yellow]")
        return False
    
    def _try_human_input_strategy(self, target_state_id: str) -> bool:
        """STRATEGY 6: Ask human for assistance with timeout and auto-restart fallback"""
        self.console.print(f"[bold red]ü§ù Strategy 6: Human assistance needed[/bold red]")
        
        from rich.prompt import Prompt
        import threading
        import signal
        
        current_state = self.element_interactor.current_state_id
        self.console.print(f"[yellow]Current state: {current_state}[/yellow]")
        self.console.print(f"[yellow]Target state: {target_state_id}[/yellow]")
        
        # Check for learned strategy first
        learned_strategy = self._get_learned_exit_strategy(current_state, target_state_id)
        if learned_strategy:
            self.console.print(f"[cyan]üß† Found learned exit strategy for {current_state} ‚Üí {target_state_id}[/cyan]")
            if self._execute_learned_exit_strategy(learned_strategy):
                return True
            else:
                self.console.print(f"[yellow]‚ö†Ô∏è Learned strategy failed, falling back to human help[/yellow]")
        
        self.console.print(f"[bold yellow]üìç CLICK RECORDING ACTIVE - Your clicks will be learned for future automation[/bold yellow]")
        
        before_screenshot = self.element_interactor.screenshot_manager.take_screenshot("before_human_help")
        
        # ‚úÖ FIX: Add fallback learning when click monitoring fails
        click_monitor = self._start_click_monitoring()
        if not click_monitor:
            self.console.print(f"[yellow]‚ö†Ô∏è Click monitoring failed - will use manual learning fallback[/yellow]")
        
        # ‚úÖ NEW: Add timeout mechanism
        self.console.print(f"[bold yellow]‚è∞ Please help navigate back manually within 10 seconds, then press Enter[/bold yellow]")
        self.console.print(f"[dim]If no response in 10 seconds, will auto-restart with default file[/dim]")
        
        try:
            # ‚úÖ TIMEOUT: 10-second timeout using threading
            user_response = None
            response_received = threading.Event()
            
            def get_user_input():
                nonlocal user_response
                try:
                    user_response = input("Press Enter when you've navigated back (or 'skip' to abort): ")
                    response_received.set()
                except:
                    pass
            
            input_thread = threading.Thread(target=get_user_input, daemon=True)
            input_thread.start()
            
            # Wait for user input or timeout
            if response_received.wait(timeout=10.0):
                # User responded within 10 seconds
                if user_response and user_response.lower() == 'skip':
                    return False
                
                # ‚úÖ EXISTING: Continue with click learning logic
                recorded_clicks = self._stop_click_monitoring(click_monitor) if click_monitor else []
                
                if recorded_clicks:
                    self._learn_exit_strategy_from_clicks(current_state, target_state_id, recorded_clicks, before_screenshot)
                else:
                    self._save_learned_exit_strategy(current_state, target_state_id, {
                        "method": "manual_navigation",
                        "learned_from": "human_assistance_fallback",
                        "success_rate": 1.0,
                        "last_used": time.time(),
                        "note": "Click monitoring failed, but human successfully navigated"
                    })
                    self.console.print(f"[green]‚úÖ Saved manual navigation strategy as fallback[/green]")
                
                self.navigation_chain.clear()
                return True
            
            else:
                # ‚úÖ TIMEOUT: No response within 10 seconds - auto-restart
                self.console.print(f"[red]‚è∞ No human response within 10 seconds - auto-restarting application[/red]")
                
                # Stop click monitoring
                if click_monitor:
                    self._stop_click_monitoring(click_monitor)
                
                # ‚úÖ CALL: The auto-restart function
                restart_success = self._auto_restart_with_default_file()
                
                if restart_success:
                    self.console.print(f"[green]‚úÖ Application restarted successfully - continuing exploration[/green]")
                    return True
                else:
                    self.console.print(f"[red]‚ùå Auto-restart failed - manual intervention required[/red]")
                    return False
                    
        except Exception as e:
            self.console.print(f"[red]‚ùå Error in human input strategy: {e}[/red]")
            return False

    def _get_learned_exit_strategy(self, from_state: str, to_state: str) -> Optional[Dict]:
        """Get previously learned exit strategy for this state transition"""
        try:
            current_state_data = self.state_manager.fdom_data["states"].get(from_state, {})
            exit_strategies = current_state_data.get("exit_strategies", {})
            
            # Look for exact target match first
            if to_state in exit_strategies:
                strategy = exit_strategies[to_state]
                self.console.print(f"[cyan]üéØ Found exact exit strategy: {from_state} ‚Üí {to_state}[/cyan]")
                return strategy
            
            # Look for generic "root" strategy if target is root
            if to_state == "root" and "root" in exit_strategies:
                strategy = exit_strategies["root"]
                self.console.print(f"[cyan]üè† Found root exit strategy: {from_state} ‚Üí root[/cyan]")
                return strategy
            
            return None
            
        except Exception as e:
            self.console.print(f"[yellow]‚ö†Ô∏è Error getting learned strategy: {e}[/yellow]")
            return None

    def _execute_learned_exit_strategy(self, strategy: Dict) -> bool:
        """Execute a previously learned exit strategy"""
        try:
            method = strategy.get("method")
            
            if method == "click_element":
                # Execute click on learned element
                node_id = strategy.get("node_id")
                element_name = strategy.get("element_name", "learned_element")
                
                self.console.print(f"[cyan]ü§ñ Executing learned strategy: clicking {element_name} ({node_id})[/cyan]")
                
                # Find the element in current state
                current_state_data = self.state_manager.fdom_data["states"].get(
                    self.element_interactor.current_state_id, {}
                )
                current_nodes = current_state_data.get("nodes", {})
                
                if node_id in current_nodes:
                    window_pos = self.element_interactor._get_current_window_position()
                    if window_pos:
                        click_result = self.element_interactor.click_engine.execute_click_with_centroids(
                            current_nodes[node_id], window_pos, element_name
                        )
                        
                        if click_result.success:
                            self.console.print(f"[green]‚úÖ Learned strategy executed successfully[/green]")
                            time.sleep(1)
                            return True
                        else:
                            self.console.print(f"[yellow]‚ö†Ô∏è Learned click failed: {click_result.error_message}[/yellow]")
                else:
                    self.console.print(f"[yellow]‚ö†Ô∏è Learned element {node_id} not found in current state[/yellow]")
            
            elif method == "key_sequence":
                # Execute learned key sequence (like ESC)
                keys = strategy.get("keys", [])
                self.console.print(f"[cyan]ü§ñ Executing learned key sequence: {keys}[/cyan]")
                
                for key in keys:
                    if key == "ESC":
                        self.app_controller.gui_api.send_key("ESCAPE")
                        time.sleep(0.5)
                
                return True
            
            return False
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Error executing learned strategy: {e}[/red]")
            return False

    def _start_click_monitoring(self):
        """Start monitoring mouse clicks using Windows API"""
        try:
            import threading
            from ctypes import wintypes
            import ctypes
            
            # Storage for recorded clicks
            self.recorded_clicks = []
            self.monitoring_active = True
            
            # Windows hook setup
            WH_MOUSE_LL = 14
            WM_LBUTTONDOWN = 0x0201
            
            class POINT(ctypes.Structure):
                _fields_ = [("x", ctypes.c_long), ("y", ctypes.c_long)]
            
            class MSLLHOOKSTRUCT(ctypes.Structure):
                _fields_ = [("pt", POINT), ("mouseData", wintypes.DWORD),
                           ("flags", wintypes.DWORD), ("time", wintypes.DWORD),
                           ("dwExtraInfo", ctypes.POINTER(wintypes.ULONG))]
            
            def low_level_mouse_proc(nCode, wParam, lParam):
                if nCode >= 0 and self.monitoring_active:
                    if wParam == WM_LBUTTONDOWN:
                        # Record the click
                        info = ctypes.cast(lParam, ctypes.POINTER(MSLLHOOKSTRUCT)).contents
                        click_x = info.pt.x
                        click_y = info.pt.y
                        
                        self.recorded_clicks.append({
                            'x': click_x,
                            'y': click_y,
                            'timestamp': time.time()
                        })
                        
                        self.console.print(f"[dim]üìç Recorded click at ({click_x}, {click_y})[/dim]")
                
                return ctypes.windll.user32.CallNextHookExW(None, nCode, wParam, lParam)
            
            # Set up the hook
            HOOKPROC = ctypes.WINFUNCTYPE(ctypes.c_int, ctypes.c_int, wintypes.WPARAM, wintypes.LPARAM)
            self.hook_proc = HOOKPROC(low_level_mouse_proc)
            
            self.hook_id = ctypes.windll.user32.SetWindowsHookExW(
                WH_MOUSE_LL, self.hook_proc, 
                ctypes.windll.kernel32.GetModuleHandleW(None), 0
            )
            
            if not self.hook_id:
                self.console.print(f"[yellow]‚ö†Ô∏è Failed to set up click monitoring[/yellow]")
                return None
            
            return self.hook_id
            
        except Exception as e:
            self.console.print(f"[yellow]‚ö†Ô∏è Click monitoring setup failed: {e}[/yellow]")
            return None

    def _stop_click_monitoring(self, hook_id):
        """Stop click monitoring and return recorded clicks"""
        try:
            self.monitoring_active = False
            
            if hook_id:
                import ctypes
                ctypes.windll.user32.UnhookWindowsHookEx(hook_id)
            
            recorded_clicks = getattr(self, 'recorded_clicks', [])
            self.console.print(f"[cyan]üìä Recorded {len(recorded_clicks)} clicks during human assistance[/cyan]")
            
            return recorded_clicks
            
        except Exception as e:
            self.console.print(f"[yellow]‚ö†Ô∏è Error stopping click monitoring: {e}[/yellow]")
            return []

    def _learn_exit_strategy_from_clicks(self, from_state: str, to_state: str, 
                                       recorded_clicks: List[Dict], before_screenshot: str):
        """Analyze recorded clicks and learn exit strategy"""
        try:
            if not recorded_clicks:
                self.console.print(f"[yellow]‚ö†Ô∏è No clicks recorded - cannot learn strategy[/yellow]")
                return
            
            # Take "after" screenshot to verify the transition worked
            after_screenshot = self.element_interactor.screenshot_manager.take_screenshot("after_human_help")
            
            # Get window position for coordinate conversion
            window_pos = self.element_interactor._get_current_window_position()
            if not window_pos:
                self.console.print(f"[yellow]‚ö†Ô∏è Cannot get window position for learning[/yellow]")
                return
            
            self.console.print(f"[cyan]üß† Learning exit strategy from {len(recorded_clicks)} clicks...[/cyan]")
            
            # Process the most significant click (usually the last one that caused the transition)
            significant_click = recorded_clicks[-1]  # Last click is usually the important one
            
            # Convert absolute coordinates to window-relative coordinates
            window_rel_x = significant_click['x'] - window_pos['left']
            window_rel_y = significant_click['y'] - window_pos['top']
            
            # Find matching FDOM element at these coordinates
            matching_element = self._find_element_at_coordinates(from_state, window_rel_x, window_rel_y)
            
            if matching_element:
                # Save as learned click strategy
                self._save_learned_exit_strategy(from_state, to_state, {
                    "method": "click_element",
                    "node_id": matching_element['node_id'],
                    "element_name": matching_element['element_name'],
                    "coordinates": [window_rel_x, window_rel_y],
                    "learned_from": "human_assistance",
                    "success_rate": 1.0,
                    "last_used": time.time()
                })
                
                self.console.print(f"[green]‚úÖ Learned exit strategy: {from_state} ‚Üí {to_state} via '{matching_element['element_name']}'[/green]")
            else:
                # Could be a key press or gesture - save coordinates as fallback
                self._save_learned_exit_strategy(from_state, to_state, {
                    "method": "click_coordinates",
                    "coordinates": [window_rel_x, window_rel_y],
                    "learned_from": "human_assistance",
                    "success_rate": 1.0,
                    "last_used": time.time()
                })
                
                self.console.print(f"[green]‚úÖ Learned coordinate-based exit strategy: {from_state} ‚Üí {to_state} at ({window_rel_x}, {window_rel_y})[/green]")
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Error learning from clicks: {e}[/red]")

    def _find_element_at_coordinates(self, state_id: str, rel_x: int, rel_y: int) -> Optional[Dict]:
        """Find FDOM element that contains the given coordinates"""
        try:
            state_data = self.state_manager.fdom_data["states"].get(state_id, {})
            nodes = state_data.get("nodes", {})
            
            # Search for element containing these coordinates
            for node_id, node_data in nodes.items():
                bbox = node_data.get("bbox", [])
                if len(bbox) == 4:
                    x1, y1, x2, y2 = bbox
                    
                    # Check if coordinates are within this element (with small tolerance)
                    if (x1 - 5 <= rel_x <= x2 + 5 and 
                        y1 - 5 <= rel_y <= y2 + 5):
                        
                        element_name = node_data.get('g_icon_name', 'unknown')
                        return {
                            'node_id': node_id,
                            'element_name': element_name,
                            'bbox': bbox
                        }
            
            return None
            
        except Exception as e:
            self.console.print(f"[yellow]‚ö†Ô∏è Error finding element at coordinates: {e}[/yellow]")
            return None

    def _save_learned_exit_strategy(self, from_state: str, to_state: str, strategy: Dict):
        """Save learned exit strategy to FDOM data"""
        try:
            # Get current FDOM data
            fdom_data = self.state_manager.fdom_data
            
            # Ensure the from_state exists
            if from_state not in fdom_data.get("states", {}):
                self.console.print(f"[yellow]‚ö†Ô∏è State {from_state} not found in FDOM[/yellow]")
                return
            
            # Initialize exit_strategies if not exists
            state_data = fdom_data["states"][from_state]
            if "exit_strategies" not in state_data:
                state_data["exit_strategies"] = {}
            
            # Save the strategy
            state_data["exit_strategies"][to_state] = strategy
            
            # Save to file
            self.state_manager.save_fdom_to_file()
            
            self.console.print(f"[green]‚úÖ Exit strategy saved to FDOM: {from_state} ‚Üí {to_state}[/green]")
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Error saving learned strategy: {e}[/red]")
    
    def _verify_reached_target(self, target_state_id: str) -> bool:
        """Verify if we've reached the target state with PROPER comparison"""
        # Take screenshot and compare with known state
        verification_screenshot = self.element_interactor.screenshot_manager.take_screenshot("verification")
        
        if target_state_id == "root":
            # Compare with root state screenshot
            root_state_data = self.state_manager.fdom_data["states"].get("root", {})
            root_image = root_state_data.get("image")
            
            if root_image and Path(root_image).exists():
                hash1 = self.visual_differ.calculate_image_hash(verification_screenshot)
                hash2 = self.visual_differ.calculate_image_hash(root_image)
                
                if hash1 == hash2:
                    self.console.print(f"[green]‚úÖ Backtrack verification: Successfully reached {target_state_id}[/green]")
                    self.element_interactor.current_state_id = target_state_id
                    return True
                else:
                    self.console.print(f"[yellow]‚ö†Ô∏è Backtrack verification: State mismatch for {target_state_id}[/yellow]")
                    return False
            else:
                # Fallback for missing root image
                self.console.print(f"[yellow]‚ö†Ô∏è Backtrack verification: No reference image for {target_state_id}[/yellow]")
                self.element_interactor.current_state_id = target_state_id
                return True
        
        # For other states, similar comparison
        return True
    
    def smart_backtrack_to_state(self, target_state: str, reference_screenshot: str) -> bool:
        """Smart backtracking with ESSENTIAL first check"""
        
        self.console.print(f"[bold blue]üîÑ SMART BACKTRACKING to {target_state}[/bold blue]")
        self.console.print(f"[dim]üì∏ Reference screenshot: {reference_screenshot}[/dim]")
        
        # ‚úÖ STEP 0: Are we ALREADY in the target state? (MOST IMPORTANT CHECK!)
        target_state_screenshot = self._get_target_state_screenshot(target_state)
        if target_state_screenshot:
            current_screenshot = self.element_interactor.screenshot_manager.take_screenshot("backtrack_current_check")
            current_similarity = self.visual_differ.calculate_similarity_percentage(
                current_screenshot, target_state_screenshot)
        else:
            # Fallback logic
            current_similarity = 0.0
        
        self.console.print(f"[cyan]üéØ STEP 0: Current vs target similarity: {current_similarity}%[/cyan]")
        
        if current_similarity >= 99.9:
            self.console.print(f"[green]‚úÖ ALREADY IN TARGET STATE! No backtracking needed ({current_similarity}%)[/green]")
            return True
        
        self.console.print(f"[yellow]‚ö†Ô∏è Need to backtrack: {current_similarity}% < 99.9%[/yellow]")
        
        # Store reference for other strategies
        self.backtrack_reference = reference_screenshot
        current_state = self.element_interactor.current_state_id
        
        # ‚úÖ STEP 1: Try learned strategy first
        learned_strategy = self._get_learned_exit_strategy(current_state, target_state)
        if learned_strategy:
            self.console.print(f"[cyan]üß† Found learned exit strategy for {current_state} ‚Üí {target_state}[/cyan]")
            if self._execute_learned_exit_strategy(learned_strategy):
                if self._verify_reached_target_with_reference(target_state):
                    return True
        
        # ‚úÖ STRATEGY 1: Click outside diff area (safest)
        if self._try_click_outside_diff_strategy(reference_screenshot):
            if self._verify_reached_target_with_reference(target_state):
                # ‚úÖ SAVE successful safe area strategy
                self._save_successful_backtrack_strategy(current_state, target_state, "safe_area_click")
                return True
        
        # ‚úÖ STRATEGY 2: Click same button that opened this state
        if self._try_click_same_opener_button():
            if self._check_app_and_restart_if_needed():
                if self._verify_reached_target_with_reference(target_state):
                    # ‚úÖ SAVE successful opener button strategy
                    self._save_successful_backtrack_strategy(current_state, target_state, "opener_button")
                    return True
        
        # ‚úÖ STRATEGY 3: Press ESC key
        if self._try_esc_key_strategy():
            if self._check_app_and_restart_if_needed():
                if self._verify_reached_target_with_reference(target_state):
                    # ‚úÖ SAVE successful ESC strategy
                    self._save_successful_backtrack_strategy(current_state, target_state, "esc_key")
                    return True
        
        # ‚úÖ STRATEGY 4: Look for close button (with app restart)
        if self._try_close_button_strategy_fixed():
            if self._check_app_and_restart_if_needed():
                if self._verify_reached_target_with_reference(target_state):
                    # ‚úÖ SAVE successful close button strategy
                    self._save_successful_backtrack_strategy(current_state, target_state, "close_button")
                    return True
        
        # ‚úÖ STRATEGY 5: Reverse navigation chain
        if self._try_reverse_navigation_chain():
            if self._check_app_and_restart_if_needed():
                if self._verify_reached_target_with_reference(target_state):
                    # ‚úÖ SAVE successful reverse navigation strategy
                    self._save_successful_backtrack_strategy(current_state, target_state, "reverse_navigation")
                    return True
        
        # ‚úÖ STRATEGY 6: Ask user (already has learning built-in)
        if self._try_human_input_strategy(target_state):
            return True
        
        self.console.print(f"[red]‚ùå All backtrack strategies failed[/red]")
        return False

    def _save_successful_backtrack_strategy(self, from_state: str, to_state: str, method: str):
        """Save automatically discovered successful backtrack strategy"""
        try:
            # Create strategy object based on method
            if method == "esc_key":
                strategy = {
                    "method": "key_sequence",
                    "keys": ["ESC"],
                    "learned_from": "automatic_discovery",
                    "success_rate": 1.0,
                    "last_used": time.time(),
                    "discovery_method": method
                }
            elif method == "safe_area_click":
                # Save the last successful safe area click coordinates
                if hasattr(self, '_last_successful_safe_click'):
                    strategy = {
                        "method": "click_coordinates",
                        "coordinates": self._last_successful_safe_click,
                        "learned_from": "automatic_discovery",
                        "success_rate": 1.0,
                        "last_used": time.time(),
                        "discovery_method": method
                    }
                else:
                    return  # No coordinates to save
            elif method == "opener_button":
                # Save the opener button information
                if self.navigation_chain:
                    last_step = self.navigation_chain[-1]
                    strategy = {
                        "method": "click_element",
                        "node_id": last_step['node_id'],
                        "element_name": last_step['element_name'],
                        "learned_from": "automatic_discovery",
                        "success_rate": 1.0,
                        "last_used": time.time(),
                        "discovery_method": method
                    }
                else:
                    return  # No navigation chain info
            elif method == "close_button":
                # Save the last successful close button
                if hasattr(self, '_last_successful_close_button'):
                    strategy = {
                        "method": "click_element",
                        "node_id": self._last_successful_close_button['node_id'],
                        "element_name": self._last_successful_close_button['element_name'],
                        "learned_from": "automatic_discovery",
                        "success_rate": 1.0,
                        "last_used": time.time(),
                        "discovery_method": method
                    }
                else:
                    return  # No close button info
            elif method == "reverse_navigation":
                # Save reverse navigation strategy
                strategy = {
                    "method": "reverse_navigation_chain",
                    "learned_from": "automatic_discovery",
                    "success_rate": 1.0,
                    "last_used": time.time(),
                    "discovery_method": method
                }
            else:
                return  # Unknown method
            
            # Save using existing method
            self._save_learned_exit_strategy(from_state, to_state, strategy)
            
            self.console.print(f"[green]üß† Auto-learned exit strategy: {from_state} ‚Üí {to_state} via {method}[/green]")
            
        except Exception as e:
            self.console.print(f"[yellow]‚ö†Ô∏è Error saving successful strategy: {e}[/yellow]")

    def _try_click_outside_diff_strategy(self, reference_screenshot: str) -> bool:
        """STRATEGY 1: Click in SAFE areas that don't overlap with UI elements"""
        self.console.print(f"[yellow]üîß Strategy 1: Finding safe click areas...[/yellow]")
        
        try:
            window_pos = self.element_interactor._get_current_window_position()
            if not window_pos:
                return False
            
            safe_areas = self._find_safe_click_areas(window_pos)
            
            if not safe_areas:
                self.console.print(f"[red]‚ùå No safe areas found[/red]")
                return False
            
            self.console.print(f"[cyan]üéØ Found {len(safe_areas)} safe areas[/cyan]")
            
            for i, (safe_x, safe_y) in enumerate(safe_areas[:3]):
                before_click_screenshot = self.element_interactor.screenshot_manager.take_screenshot("before_safe_click")
                
                self.app_controller.gui_api.click(safe_x, safe_y)
                self.console.print(f"[green]‚úÖ Clicked SAFE area #{i+1} at ({safe_x}, {safe_y})[/green]")
                time.sleep(1)
                
                after_click_screenshot = self.element_interactor.screenshot_manager.take_screenshot("after_safe_click")
                reference_similarity = self.visual_differ.calculate_similarity_percentage(after_click_screenshot, reference_screenshot)
                
                # ‚úÖ FIX: Use same 99.0% threshold here too
                if reference_similarity >= 99.0:
                    self.console.print(f"[green]üéâ Safe area click successful - reached target state! (similarity: {reference_similarity}%)[/green]")
                    
                    # Save successful coordinates for learning
                    window_rel_x = safe_x - window_pos['left']
                    window_rel_y = safe_y - window_pos['top']
                    self._last_successful_safe_click = [window_rel_x, window_rel_y]
                    
                    return True
                else:
                    self.console.print(f"[yellow]‚ö†Ô∏è Safe area #{i+1} didn't reach target (similarity: {reference_similarity}%)[/yellow]")
            
            return False
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Safe area click strategy failed: {e}[/red]")
            return False

    def _try_click_same_opener_button(self) -> bool:
        """STRATEGY 2: Click the same button that opened this state"""
        self.console.print(f"[yellow]üîß Strategy 2: Clicking same opener button...[/yellow]")
        
        if not self.navigation_chain:
            self.console.print(f"[yellow]‚ö†Ô∏è No navigation chain to find opener button[/yellow]")
            return False
        
        # Get the last navigation step (what opened current state)
        last_step = self.navigation_chain[-1]
        opener_element = last_step['element_name']
        opener_node_id = last_step['node_id']
        
        self.console.print(f"[cyan]üîÑ Trying to click opener: {opener_element}[/cyan]")
        
        # Find this element in root state (assuming it's still there)
        root_state_data = self.state_manager.fdom_data["states"].get("root", {})
        root_nodes = root_state_data.get("nodes", {})
        
        if opener_node_id in root_nodes:
            window_pos = self.element_interactor._get_current_window_position()
            if window_pos:
                click_result = self.element_interactor.click_engine.execute_click_with_centroids(
                    root_nodes[opener_node_id], window_pos, opener_element
                )
                
                if click_result.success:
                    self.console.print(f"[green]‚úÖ Opener button clicked successfully[/green]")
                    time.sleep(1)
                    return True
        
        self.console.print(f"[yellow]‚ö†Ô∏è Could not find or click opener button[/yellow]")
        return False
    
    def _try_close_button_strategy_fixed(self) -> bool:
        """STRATEGY 4: Look for close buttons ONLY from recently created dialog elements"""
        self.console.print(f"[yellow]üîß Strategy 4: Looking for DIALOG-SPECIFIC close buttons...[/yellow]")
        
        current_state_data = self.state_manager.fdom_data["states"].get(self.element_interactor.current_state_id, {})
        current_nodes = current_state_data.get("nodes", {})
        
        # ‚úÖ ENHANCED: Find close buttons but filter out global/app-level ones
        import re
        close_keywords = ["close", "cancel", "‚úï", "√ó", "ok", "done", "finish"]
        
        close_buttons = []
        
        for node_id, node_data in current_nodes.items():
            element_name = node_data.get('g_icon_name', '').lower()
            element_bbox = node_data.get('bbox', [])
            
            # ‚úÖ FILTER: Skip elements that are likely global app controls
            if self._is_likely_global_control(element_name, element_bbox):
                self.console.print(f"[dim]üö´ Skipping likely global control: {element_name}[/dim]")
                continue
            
            for keyword in close_keywords:
                # Only exact "x" matches (avoid substring matching issues) 
                if keyword == "x" and element_name.strip() == "x":
                    close_buttons.append({
                        'node_id': node_id,
                        'node_data': node_data,
                        'element_name': element_name,
                        'keyword': keyword
                    })
                    break
                elif keyword != "x" and re.search(r'\b' + re.escape(keyword) + r'\b', element_name):
                    close_buttons.append({
                        'node_id': node_id,
                        'node_data': node_data,
                        'element_name': element_name,
                        'keyword': keyword
                    })
                    break
        
        if not close_buttons:
            self.console.print(f"[yellow]‚ö†Ô∏è No close buttons found[/yellow]")
            return False
        
        self.console.print(f"[cyan]üéØ Found {len(close_buttons)} close button(s): {[btn['element_name'] for btn in close_buttons]}[/cyan]")
        
        # ‚úÖ ENHANCED: Try ALL close buttons until one works
        for i, button in enumerate(close_buttons, 1):
            self.console.print(f"[cyan]üîò Trying close button #{i}: {button['element_name']}[/cyan]")
            
            window_pos = self.element_interactor._get_current_window_position()
            if window_pos:
                click_result = self.element_interactor.click_engine.execute_click_with_centroids(
                    button['node_data'], window_pos, button['element_name']
                )
                
                if click_result.success:
                    self.console.print(f"[green]üéâ Close button #{i} clicked successfully: {button['element_name']}![/green]")
                    
                    # ‚úÖ SAVE successful close button for learning
                    self._last_successful_close_button = {
                        'node_id': button['node_id'],
                        'element_name': button['element_name']
                    }
                    
                    time.sleep(1)  # Wait for close animation
                    return True
                else:
                    self.console.print(f"[yellow]‚ö†Ô∏è Close button #{i} click failed: {click_result.error_message}[/yellow]")
        
        self.console.print(f"[red]‚ùå All {len(close_buttons)} close buttons failed[/red]")
        return False
    
    def _check_app_and_restart_if_needed(self) -> bool:
        """Check if app is still running and restart if needed"""
        if not self._verify_app_still_running():
            self.console.print(f"[yellow]‚ö†Ô∏è App closed during backtrack - restarting...[/yellow]")
            restart_success = self._restart_app_after_closure()
            
            if restart_success:
                self.console.print(f"[green]‚úÖ App restarted successfully[/green]")
                return True
            else:
                self.console.print(f"[red]‚ùå Failed to restart app[/red]")
                return False
        
        return True  # App still running
    
    def _verify_app_still_running(self) -> bool:
        """Check if the app window still exists"""
        try:
            if not self.app_controller.current_app_info:
                return False
            
            window_id = self.app_controller.current_app_info['window_id']
            window_info = self.app_controller.gui_api.get_window_info(window_id)
            
            return window_info is not None
            
        except Exception as e:
            self.console.print(f"[yellow]‚ö†Ô∏è Error checking app status: {e}[/yellow]")
            return False
    
    def _restart_app_after_closure(self) -> bool:
        """Restart the app without running Seraphine (fDOM already exists)"""
        try:
            # Get original app path from element_interactor
            app_path = self.element_interactor.app_executable_path
            
            self.console.print(f"[cyan]üîÑ Restarting app: {app_path}[/cyan]")
            
            # Use AppController to relaunch
            launch_result = self.app_controller.launch_app()
            
            if launch_result["success"]:
                self.console.print(f"[green]‚úÖ App relaunched successfully[/green]")
                
                # Wait for app to be ready
                time.sleep(2)
                
                # Verify window tracking
                return self._verify_app_still_running()
            else:
                self.console.print(f"[red]‚ùå App relaunch failed: {launch_result.get('error')}[/red]")
                return False
                
        except Exception as e:
            self.console.print(f"[red]‚ùå Exception during app restart: {e}[/red]")
            return False
    
    def _verify_reached_target_with_reference(self, target_state_id: str) -> bool:
        """ENHANCED: Multi-state verification for popup behavior"""
        verification_screenshot = self.element_interactor.screenshot_manager.take_screenshot("verification")
        
        if target_state_id == "root":
            # ‚úÖ MULTI-STATE VERIFICATION: Check against ALL possible target states
            candidate_references = []
            
            # 1. Add the backtrack reference (before_click - might be C4, C3, C2, C1)
            if hasattr(self, 'backtrack_reference') and self.backtrack_reference:
                candidate_references.append(("before_click", self.backtrack_reference))
            
            # 2. Add ROOT state image (S001.png)
            root_state_data = self.state_manager.fdom_data["states"].get("root", {})
            root_image = root_state_data.get("image")
            if root_image and Path(root_image).exists():
                candidate_references.append(("root_state", root_image))
            
            for nav_step in self.navigation_chain:
                state_id = nav_step.get('from_state')
                if state_id and state_id in self.state_manager.fdom_data.get("states", {}):
                    state_image = self.state_manager.fdom_data["states"][state_id].get("image")
                    if state_image and Path(state_image).exists():
                        candidate_references.append((f"nav_state_{state_id}", state_image))
            
            self.console.print(f"[cyan]üéØ Multi-state verification: {len(candidate_references)} candidates[/cyan]")
            
            # ‚úÖ FIX: More reasonable threshold (99.0% instead of 99.99%)
            for ref_name, ref_path in candidate_references:
                similarity = self.visual_differ.calculate_similarity_percentage(
                    verification_screenshot, ref_path
                )
                
                self.console.print(f"[dim]üìä {ref_name}: {similarity}%[/dim]")
                
                # ‚úÖ REASONABLE: 99.0% threshold (not 99.99%)
                if similarity >= 99.0:
                    self.console.print(f"[green]‚úÖ Multi-state verification: Matched {ref_name} ({similarity}%)[/green]")
                    self.element_interactor.current_state_id = target_state_id
                    return True
            
            self.console.print(f"[yellow]‚ö†Ô∏è Multi-state verification: No state matched ‚â•99.0%[/yellow]")
            return False
        
        return True
    
    def _find_safe_click_areas(self, window_pos: Dict, margin: int = 20, debug: bool = True) -> List[Tuple[int, int]]:
        """Find safe click areas using improved strategies:
        1. Centroids of non-interactive elements
        2. "Home" tab location (safe navigation)
        3. Validated 50x50 blank areas in header region
        """
        safe_areas = []
        
        # Get current state data
        current_state_data = self.state_manager.fdom_data["states"].get(
            self.element_interactor.current_state_id, {}
        )
        current_nodes = current_state_data.get("nodes", {})
        
        # ‚úÖ STRATEGY 1: Use centroids of non-interactive elements
        for node_id, node_data in current_nodes.items():
            if not node_data.get('g_interactive', True):  # Non-interactive elements
                bbox = node_data.get('bbox', [])
                if len(bbox) == 4:
                    # Calculate centroid in absolute coordinates
                    centroid_x = window_pos['left'] + (bbox[0] + bbox[2]) // 2
                    centroid_y = window_pos['top'] + (bbox[1] + bbox[3]) // 2
                    safe_areas.append((centroid_x, centroid_y))
                    
                    if debug:
                        element_name = node_data.get('g_icon_name', 'unknown')
                        self.console.print(f"[dim]‚úÖ Non-interactive safe area: ({centroid_x}, {centroid_y}) from '{element_name}'[/dim]")
        
        # ‚úÖ STRATEGY 2: Find "Home" tab - safe navigation button (LOOK IN ROOT STATE)
        home_found = False
        
        # ‚úÖ FIX: Look for Home tab in ROOT state, not current state
        root_state_data = self.state_manager.fdom_data["states"].get("root", {})
        root_nodes = root_state_data.get("nodes", {})
        
        for node_id, node_data in root_nodes.items():
            element_name = node_data.get('g_icon_name', '').lower()
            if element_name == 'home':
                bbox = node_data.get('bbox', [])
                if len(bbox) == 4:
                    # Calculate centroid in absolute coordinates
                    home_x = window_pos['left'] + (bbox[0] + bbox[2]) // 2
                    home_y = window_pos['top'] + (bbox[1] + bbox[3]) // 2
                    safe_areas.append((home_x, home_y))
                    home_found = True
                    
                    if debug:
                        self.console.print(f"[green]üè† Home tab safe area: ({home_x}, {home_y}) from ROOT state '{element_name}' ({node_id})[/green]")
                    break
        
        if not home_found and debug:
            self.console.print(f"[yellow]‚ö†Ô∏è No 'Home' tab found in ROOT state[/yellow]")
        
        # ‚úÖ STRATEGY 3: Find validated 50x50 blank areas in header (if we need more safe areas)
        if len(safe_areas) < 3:  # Need at least 3 safe areas for reliability
            header_safe_areas = self._find_validated_header_safe_areas(window_pos)
            safe_areas.extend(header_safe_areas)
        
        if debug:
            self.console.print(f"[dim]üéØ Found {len(safe_areas)} total safe areas[/dim]")
            for i, (x, y) in enumerate(safe_areas):
                self.console.print(f"[dim]   Safe #{i+1}: ({x}, {y})[/dim]")
        
        return safe_areas

    def _find_validated_header_safe_areas(self, window_pos: Dict) -> List[Tuple[int, int]]:
        """Find 4 validated 50x50 blank areas in top header using hover testing"""
        
        # Define header region (top ~100px)
        header_top = window_pos['top'] + 10
        header_bottom = window_pos['top'] + 100
        header_left = window_pos['left'] + 50  
        header_right = window_pos['left'] + window_pos['width'] - 50
        
        # Generate candidate 50x50 areas
        candidates = []
        for y in range(header_top, header_bottom - 50, 25):
            for x in range(header_left, header_right - 50, 100):
                candidates.append((x + 25, y + 25))  # Center of 50x50 area
        
        # ‚úÖ VALIDATE using hover testing (like auto-captioner)
        validated_safe_areas = []
        
        self.console.print(f"[dim]üîç Testing {min(len(candidates), 8)} header candidates for safe areas...[/dim]")
        
        for candidate_x, candidate_y in candidates[:8]:  # Test max 8 candidates
            try:
                # Take before screenshot
                before_screenshot = self.element_interactor.screenshot_manager.take_screenshot("safe_area_test")
                if not before_screenshot:
                    continue
                
                # Hover over candidate area (like auto-captioner)
                self.app_controller.gui_api.set_cursor_position(candidate_x, candidate_y)
                time.sleep(0.5)  # Brief hover to trigger any tooltips
                
                # Take after screenshot  
                after_screenshot = self.element_interactor.screenshot_manager.take_screenshot("safe_area_after")
                if not after_screenshot:
                    continue
                
                # ‚úÖ CORRECTED: Use the actual method name
                hash_before = self.visual_differ.calculate_image_hash(before_screenshot)
                hash_after = self.visual_differ.calculate_image_hash(after_screenshot)
                
                if hash_before == hash_after:
                    # ‚úÖ No changes - this area is safe!
                    validated_safe_areas.append((candidate_x, candidate_y))
                    self.console.print(f"[dim]‚úÖ Validated header safe area: ({candidate_x}, {candidate_y})[/dim]")
                    
                    if len(validated_safe_areas) >= 4:  # Found enough safe areas
                        break
                else:
                    self.console.print(f"[dim]‚ö†Ô∏è Area ({candidate_x}, {candidate_y}) triggered visual changes - skipping[/dim]")
                
                # Cleanup screenshots
                if not self.element_interactor.debug_mode:
                    self.element_interactor.screenshot_manager.cleanup_screenshot(before_screenshot)
                    self.element_interactor.screenshot_manager.cleanup_screenshot(after_screenshot)
                    
            except Exception as e:
                self.console.print(f"[dim]‚ö†Ô∏è Error testing area ({candidate_x}, {candidate_y}): {e}[/dim]")
                continue
        
        self.console.print(f"[dim]üéØ Header validation found {len(validated_safe_areas)} safe areas[/dim]")
        return validated_safe_areas
    
    def _is_likely_global_control(self, element_name: str, element_bbox: List[int]) -> bool:
        """Determine if an element is likely a global app control vs dialog control"""
        
        # Get current window bounds
        window_pos = self.element_interactor._get_current_window_position()
        if not window_pos or len(element_bbox) != 4:
            return False
        
        x1, y1, x2, y2 = element_bbox
        element_width = x2 - x1
        element_height = y2 - y1
        
        # Convert to window-relative coordinates
        rel_x1 = x1 - window_pos['left']
        rel_y1 = y1 - window_pos['top']
        rel_x2 = x2 - window_pos['left'] 
        rel_y2 = y2 - window_pos['top']
        
        # ‚úÖ WINDOW-RELATIVE FILTERING (works on any screen resolution)
        window_width = window_pos['width']
        window_height = window_pos['height']
        
        # Rule 1: Elements in the top-right corner of the window (typical close button area)
        if (rel_x2 > window_width * 0.9 and  # Right 10% of window
            rel_y1 < window_height * 0.1 and  # Top 10% of window  
            element_width < 50 and element_height < 50 and  # Small button
            element_name.strip() == "x"):
            
            self.console.print(f"[yellow]üö´ Element '{element_name}' is in top-right corner - likely global app close button[/yellow]")
            return True
        
        # Rule 2: Elements at the very top edge (title bar area)
        if (rel_y1 < 50 and  # Very top of window
            element_name.strip() == "x"):
            
            self.console.print(f"[yellow]üö´ Element '{element_name}' is in title bar area - likely global control[/yellow]")
            return True
        
        # Rule 3: If we're NOT in root state, and this is a single "x" character,
        # and it's positioned like a standard Windows close button
        if (self.element_interactor.current_state_id != "root" and
            element_name.strip() == "x" and
            rel_x2 > window_width * 0.85):  # Right 15% of window
            
            self.console.print(f"[yellow]üö´ Element '{element_name}' looks like main app close button (we're in dialog state)[/yellow]")
            return True
        
        return False 

    def _auto_restart_with_default_file(self) -> bool:
        """Auto-restart application using existing launch logic"""
        try:
            self.console.print(f"[cyan]üîÑ Step 1: Marking current node as explored...[/cyan]")
            
            # ‚úÖ MARK NODE: Change status from "pending" to "explored" before restart
            self._mark_current_exploration_as_explored()
            
            self.console.print(f"[cyan]üîÑ Step 2: Closing current application...[/cyan]")
            
            # Close current app
            if self.app_controller.current_app_info:
                window_id = self.app_controller.current_app_info["window_id"]
                self.app_controller.gui_api.close_window(window_id)
                time.sleep(2)  # Wait for close
            
            self.console.print(f"[cyan]üîÑ Step 3: Restarting with existing launch logic...[/cyan]")
            
            # ‚úÖ USE EXISTING: Just call the existing launch method (it already knows about default files)
            app_executable_path = self.app_controller.current_app_info.get("executable_path")
            if not app_executable_path:
                self.console.print(f"[red]‚ùå No executable path found for restart[/red]")
                return False
            
            # ‚úÖ EXISTING LOGIC: Use the same launch method that already handles default files
            launch_result = self.app_controller.launch_app()
            
            if launch_result["success"]:
                self.console.print(f"[green]‚úÖ App restarted successfully using existing launch logic[/green]")
                
                # Wait for app to be ready
                time.sleep(3)
                
                # ‚úÖ RESET: Clear navigation state and return to root
                self.navigation_chain.clear()
                self.element_interactor.current_state_id = "root"
                
                return True
            else:
                self.console.print(f"[red]‚ùå App restart failed: {launch_result.get('error')}[/red]")
                return False
                
        except Exception as e:
            self.console.print(f"[red]‚ùå Auto-restart failed: {e}[/red]")
            return False

    def _mark_current_exploration_as_explored(self):
        """Mark the node we were trying to explore as 'explored' so we don't retry it"""
        try:
            # ‚úÖ IDENTIFY: What node were we trying to explore when things went wrong?
            current_state_id = self.element_interactor.current_state_id
            
            # Get the last navigation step (the node that opened current problematic state)
            if self.navigation_chain:
                last_nav = self.navigation_chain[-1]
                problematic_node = last_nav.get('node_id')
                from_state = last_nav.get('from_state')
                
                if problematic_node and from_state:
                    self.console.print(f"[yellow]üìù Marking {problematic_node} as 'explored' (caused navigation issues)[/yellow]")
                    
                    # Update FDOM status
                    fdom_data = self.state_manager.fdom_data
                    if (from_state in fdom_data.get("states", {}) and 
                        problematic_node in fdom_data["states"][from_state].get("nodes", {})):
                        
                        node_data = fdom_data["states"][from_state]["nodes"][problematic_node]
                        node_data["status"] = "explored"
                        node_data["exploration_result"] = "navigation_failed_restart_required"
                        node_data["exploration_timestamp"] = time.time()
                        
                        # Save to file
                        self.state_manager.save_fdom_to_file()
                        
                        # Remove from pending sets
                        if hasattr(self.state_manager, 'pending_nodes'):
                            pending_id = f"{from_state}::{problematic_node}"
                            self.state_manager.pending_nodes.discard(pending_id)
                        
                        self.console.print(f"[green]‚úÖ Marked {problematic_node} as explored in FDOM[/green]")
                    else:
                        self.console.print(f"[yellow]‚ö†Ô∏è Could not find {problematic_node} in FDOM to mark as explored[/yellow]")
                else:
                    self.console.print(f"[yellow]‚ö†Ô∏è No problematic node identified to mark as explored[/yellow]")
            else:
                self.console.print(f"[yellow]‚ö†Ô∏è No navigation chain to identify problematic node[/yellow]")
                
        except Exception as e:
            self.console.print(f"[yellow]‚ö†Ô∏è Error marking node as explored: {e}[/yellow]") 
    def _get_target_state_screenshot(self, target_state: str):
        """Get screenshot of the target state"""
        try:
            # Implement the logic to get a screenshot of the target state
            # This is a placeholder and should be replaced with the actual implementation
            return None
        except Exception as e:
            self.console.print(f"[red]‚ùå Error getting target state screenshot: {e}[/red]")
            return None 


==================================================

Path: utils\fdom\screen_manager.py
File: screen_manager.py
Code:
"""
ScreenManager - Multi-screen detection and selection for fDOM Framework
Handles screen discovery, user selection, and screenshot capture using mss
"""
import mss
import os
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from rich.console import Console
from rich.table import Table
from rich.prompt import IntPrompt
from rich.panel import Panel
from rich import print as rprint
import numpy as np
from PIL import Image

class ScreenManager:
    """
    Professional multi-screen management for fDOM framework
    Handles screen detection, selection, and capture operations
    """
    
    def __init__(self, config_manager):
        """
        Initialize ScreenManager with configuration
        
        Args:
            config_manager: ConfigManager instance for settings
        """
        self.config = config_manager
        self.console = Console()
        self.screens = self._detect_screens()
        self.selected_screen = None
        
    def _detect_screens(self) -> List[Dict]:
        """
        Detect all available monitors using mss
        FIXED: Keep 'id' field for compatibility
        """
        try:
            with mss.mss() as sct:
                screens = []
                
                # Get all monitors (index 0 is combined, 1+ are individual)
                for i, monitor in enumerate(sct.monitors):
                    if i == 0:  # Skip the combined monitor
                        continue
                        
                    screen_info = {
                        'id': i,  # Keep 'id' for compatibility
                        'monitor_id': i,  # Also keep monitor_id for clarity
                        'width': monitor['width'],
                        'height': monitor['height'],
                        'left': monitor['left'],
                        'top': monitor['top'],
                        'right': monitor['left'] + monitor['width'],
                        'bottom': monitor['top'] + monitor['height'],
                        'is_primary': monitor['left'] == 0 and monitor['top'] == 0,
                        'monitor_data': monitor
                    }
                    screens.append(screen_info)
                    
                    # Clear debug output
                    primary_text = " (Primary)" if screen_info['is_primary'] else ""
                    self.console.print(f"[cyan]Monitor {i}: {monitor['width']}x{monitor['height']} at ({monitor['left']}, {monitor['top']}){primary_text}[/cyan]")
                
                return screens
                
        except Exception as e:
            self.console.print(f"[red]‚ùå Error detecting monitors: {e}[/red]")
            return []
    
    def test_screen_detection(self) -> bool:
        """
        Test screen detection with comprehensive output and test screenshots
        
        Returns:
            True if all tests pass, False otherwise
        """
        self.console.print("\n[bold blue]üñ•Ô∏è SCREEN DETECTION TEST[/bold blue]")
        self.console.print("=" * 50)
        
        try:
            # Test 1: Screen detection
            self.console.print(f"[yellow]üîç Detecting screens...[/yellow]")
            
            if not self.screens:
                self.console.print("[red]‚ùå No screens detected![/red]")
                return False
            
            self.console.print(f"[green]‚úÖ Found {len(self.screens)} screen(s)[/green]")
            
            # Test 2: Display screen information
            self._display_screen_table()
            
            # Test 3: Take test screenshots
            screenshot_results = self._take_test_screenshots()
            
            # Test 4: Verify screenshot files
            files_created = self._verify_test_screenshots()
            
            # Summary
            all_passed = len(self.screens) > 0 and screenshot_results and files_created
            status = "[green]‚úÖ PASSED[/green]" if all_passed else "[red]‚ùå FAILED[/red]"
            self.console.print(f"\n[bold]üéØ Screen Detection Test Result: {status}[/bold]")
            
            return all_passed
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Screen detection test failed: {e}[/red]")
            return False
    
    def _display_screen_table(self) -> None:
        """Display detected screens in a beautiful table"""
        table = Table(title="üñ•Ô∏è Detected Screens", show_header=True, header_style="bold magenta")
        table.add_column("Screen ID", style="cyan", width=10)
        table.add_column("Resolution", style="white", width=15)
        table.add_column("Position", style="yellow", width=20)
        table.add_column("Size (MB)", style="green", width=12)
        table.add_column("Status", justify="center", width=10)
        
        for screen in self.screens:
            # Calculate approximate screenshot size
            pixels = screen['width'] * screen['height']
            size_mb = (pixels * 3) / (1024 * 1024)  # RGB, approximate
            
            table.add_row(
                str(screen['id']),
                f"{screen['width']}√ó{screen['height']}",
                f"({screen['left']}, {screen['top']})",
                f"{size_mb:.1f} MB",
                "[green]‚úì[/green]"
            )
        
        self.console.print(table)
    
    def _take_test_screenshots(self) -> bool:
        """Take test screenshots of all detected screens"""
        self.console.print("\n[yellow]üì∏ Taking test screenshots...[/yellow]")
        
        try:
            with mss.mss() as sct:
                for screen in self.screens:
                    screen_id = screen['id']
                    monitor = screen['monitor_data']
                    
                    # Capture screenshot
                    screenshot = sct.grab(monitor)
                    
                    # Convert to PIL Image
                    img = Image.frombytes('RGB', screenshot.size, screenshot.bgra, 'raw', 'BGRX')
                    
                    # Save test screenshot
                    filename = f"test_screen_{screen_id}.png"
                    img.save(filename)
                    
                    self.console.print(f"  [green]‚úÖ[/green] Screen {screen_id}: {filename} ({img.size[0]}√ó{img.size[1]})")
                
                return True
                
        except Exception as e:
            self.console.print(f"[red]‚ùå Error taking screenshots: {e}[/red]")
            return False
    
    def _verify_test_screenshots(self) -> bool:
        """Verify that test screenshot files were created"""
        self.console.print("\n[yellow]üîç Verifying test screenshot files...[/yellow]")
        
        all_files_exist = True
        total_size = 0
        
        for screen in self.screens:
            filename = f"test_screen_{screen['id']}.png"
            
            if os.path.exists(filename):
                file_size = os.path.getsize(filename)
                size_mb = file_size / (1024 * 1024)
                total_size += size_mb
                
                self.console.print(f"  [green]‚úÖ[/green] {filename}: {size_mb:.1f} MB")
            else:
                self.console.print(f"  [red]‚ùå[/red] {filename}: File not found")
                all_files_exist = False
        
        if all_files_exist:
            self.console.print(f"[green]üìä Total screenshot data: {total_size:.1f} MB[/green]")
        
        return all_files_exist
    
    def prompt_user_selection(self) -> Optional[int]:
        """
        Interactive screen selection - DEFAULT TO SCREEN 1 (TEST SCREEN)
        """
        if not self.screens:
            self.console.print("[red]‚ùå No screens available for selection[/red]")
            return None
        
        # Check config for auto-selection - DEFAULT TO SCREEN 1 (TEST SCREEN)
        if not self.config.get("capture.screen_selection_prompt", True):
            default_screen = 1  # SCREEN 1 = MONITOR 1 = TEST SCREEN (1920√ó1080)
            if any(screen['id'] == default_screen for screen in self.screens):
                self.console.print(f"[yellow]üéØ Auto-selecting Screen {default_screen} (Monitor 1 - TEST SCREEN)[/yellow]")
                self.selected_screen = default_screen
                return default_screen
        
        # Interactive selection
        self.console.print("\n[bold cyan]üñ•Ô∏è SCREEN SELECTION[/bold cyan]")
        self.console.print("Please select a screen for fDOM exploration:")
        
        # Display options
        self._display_screen_table()
        
        # Get user input
        valid_ids = [screen['id'] for screen in self.screens]
        
        try:
            selected = IntPrompt.ask(
                "\n[bold]Enter screen ID[/bold]",
                choices=[str(id) for id in valid_ids],
                default="1"  # Default to Screen 1 (TEST SCREEN)
            )
            
            self.selected_screen = selected
            
            # Show selection confirmation
            selected_screen = next(s for s in self.screens if s['id'] == selected)
            panel = Panel(
                f"Screen {selected}\n{selected_screen['width']}√ó{selected_screen['height']} pixels\nPosition: ({selected_screen['left']}, {selected_screen['top']})",
                title="[bold green]‚úÖ Selected Screen[/bold green]",
                border_style="green"
            )
            self.console.print(panel)
            
            return selected
            
        except KeyboardInterrupt:
            self.console.print("\n[yellow]‚ö†Ô∏è Screen selection cancelled[/yellow]")
            return None
        except Exception as e:
            self.console.print(f"\n[red]‚ùå Error during screen selection: {e}[/red]")
            return None
    
    def capture_screen(self, screen_id: Optional[int] = None) -> Optional[np.ndarray]:
        """
        Capture screenshot of specified screen
        FIXED: Default to Screen 1 (TEST SCREEN)
        """
        target_screen_id = screen_id or self.selected_screen
        
        if target_screen_id is None:
            target_screen_id = 1  # Default to Screen 1 (TEST SCREEN)
            self.console.print(f"[yellow]üì∫ No screen selected, defaulting to Screen {target_screen_id} (TEST SCREEN)[/yellow]")
        
        # Find target screen
        target_screen = None
        for screen in self.screens:
            if screen['id'] == target_screen_id:
                target_screen = screen
                break
        
        if not target_screen:
            self.console.print(f"[red]‚ùå Screen {target_screen_id} not found[/red]")
            return None
        
        self.console.print(f"[cyan]üì∏ Capturing Screen {target_screen_id}: {target_screen['width']}√ó{target_screen['height']}[/cyan]")
        
        try:
            with mss.mss() as sct:
                # Capture screenshot
                monitor = target_screen['monitor_data']
                screenshot = sct.grab(monitor)
                
                # Convert to numpy array (BGR format for OpenCV compatibility)
                img_array = np.frombuffer(screenshot.bgra, dtype=np.uint8)
                img_array = img_array.reshape(screenshot.height, screenshot.width, 4)
                
                # Convert BGRA to BGR
                img_rgb = img_array[:, :, [0, 1, 2]]  # Remove alpha, keep RGB order
                
                return img_rgb
                
        except Exception as e:
            self.console.print(f"[red]‚ùå Error capturing screen {target_screen_id}: {e}[/red]")
            return None
    
    def cleanup_test_files(self) -> None:
        """Clean up test screenshot files"""
        self.console.print("\n[yellow]üßπ Cleaning up test files...[/yellow]")
        
        cleaned_count = 0
        for screen in self.screens:
            filename = f"test_screen_{screen['id']}.png"
            if os.path.exists(filename):
                os.remove(filename)
                cleaned_count += 1
                self.console.print(f"  [green]‚úÖ[/green] Removed {filename}")
        
        self.console.print(f"[green]üßπ Cleaned up {cleaned_count} test file(s)[/green]")


def test_screen_manager():
    """Test function for ScreenManager - DELTA 2 testing"""
    console = Console()
    
    console.print("\n[bold green]üöÄ DELTA 2: ScreenManager Test[/bold green]")
    console.print("=" * 50)
    
    try:
        # Import ConfigManager from DELTA 1
        from config_manager import ConfigManager
        
        # Test 1: Initialize with config
        console.print("[yellow]üîß Initializing ScreenManager...[/yellow]")
        config_manager = ConfigManager()
        screen_manager = ScreenManager(config_manager)
        console.print("[green]‚úÖ ScreenManager initialized successfully[/green]")
        
        # Test 2: Run screen detection test
        detection_result = screen_manager.test_screen_detection()
        
        # Test 3: Test screen selection (if screens detected)
        if detection_result and screen_manager.screens:
            console.print("\n[yellow]üéØ Testing screen selection...[/yellow]")
            selected = screen_manager.prompt_user_selection()
            
            if selected:
                console.print(f"[green]‚úÖ Screen {selected} selected successfully[/green]")
                
                # Test 4: Test screen capture
                console.print("\n[yellow]üì∏ Testing screen capture...[/yellow]")
                screenshot = screen_manager.capture_screen(selected)
                
                if screenshot is not None:
                    console.print(f"[green]‚úÖ Screenshot captured: {screenshot.shape}[/green]")
                    
                    # Save a test capture
                    from PIL import Image
                    # Convert BGR to RGB for PIL
                    screenshot_rgb = screenshot[:, :, [0, 1, 2]]
                    img = Image.fromarray(screenshot_rgb)
                    img.save(f"test_capture_screen_{selected}.png")
                    console.print(f"[green]ÔøΩÔøΩ Saved test_capture_screen_{selected}.png[/green]")
                else:
                    console.print("[red]‚ùå Screen capture failed[/red]")
                    detection_result = False
        
        # Test 5: Clean up test files
        screen_manager.cleanup_test_files()
        
        # Final result
        if detection_result:
            console.print("\n[bold green]üéâ DELTA 2 PASSED: ScreenManager is ready![/bold green]")
        else:
            console.print("\n[bold red]‚ùå DELTA 2 FAILED: Screen detection/capture issues[/bold red]")
            
        return detection_result
        
    except Exception as e:
        console.print(f"\n[bold red]üí• DELTA 2 FAILED: {e}[/bold red]")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="fDOM ScreenManager - Delta 2 Testing")
    parser.add_argument("--test-screens", action="store_true", help="Run comprehensive screen test")
    parser.add_argument("--interactive", action="store_true", help="Run interactive screen selection")
    
    args = parser.parse_args()
    
    if args.test_screens:
        success = test_screen_manager()
        exit(0 if success else 1)
    elif args.interactive:
        from config_manager import ConfigManager
        config = ConfigManager()
        sm = ScreenManager(config)
        selected = sm.prompt_user_selection()
        print(f"Selected screen: {selected}")
    else:
        print("Usage: python screen_manager.py --test-screens")
        print("       python screen_manager.py --interactive")


==================================================

Path: utils\fdom\screenshot_manager.py
File: screenshot_manager.py
Code:
"""Screenshot capture and management"""
import os
import time
from datetime import datetime
from pathlib import Path
from typing import Optional
from rich.console import Console
from PIL import Image
import mss


class ScreenshotManager:
    """Handles screenshot capture, storage, and cleanup"""
    
    def __init__(self, app_controller, visual_differ, debug_mode: bool = True):
        self.app_controller = app_controller
        self.visual_differ = visual_differ
        self.console = Console()
        self.debug_mode = debug_mode
        
    def take_screenshot(self, suffix: str) -> Optional[str]:
        """Take screenshot of the current app window"""
        try:
            if not self.app_controller or not self.app_controller.current_app_info:
                self.console.print("[red]‚ùå No app controller or app info available[/red]")
                return None
            
            # Generate custom filename with timestamp and suffix
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            custom_filename = f"interaction_{timestamp}_{suffix}.png"
            
            # Get window info
            window_id = self.app_controller.current_app_info["window_id"]
            window_info = self.app_controller.gui_api.get_window_info(window_id)
            
            if not window_info:
                self.console.print("[yellow]üîÑ Window lookup failed for screenshot[/yellow]")
                return None
            
            # Create bounding box for just the window
            pos = window_info['window_data']['position']
            size = window_info['window_data']['size']
            
            window_bbox = {
                'left': pos['x'],
                'top': pos['y'], 
                'width': size['width'],
                'height': size['height']
            }
            
            # Capture window area only using mss
            with mss.mss() as sct:
                window_screenshot = sct.grab(window_bbox)
                img = Image.frombytes('RGB', window_screenshot.size, window_screenshot.bgra, 'raw', 'BGRX')
                
                # Save screenshot
                screenshots_dir = self.app_controller.current_app_info["folder_paths"]["screenshots"]
                screenshot_path = screenshots_dir / custom_filename
                img.save(screenshot_path)
                
                self.console.print(f"[green]üì∏ Screenshot saved: {custom_filename}[/green]")
                return str(screenshot_path)
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Screenshot capture failed: {e}[/red]")
            return None
    
    def cleanup_screenshot(self, screenshot_path: str) -> None:
        """Delete a single screenshot file - skip in debug mode"""
        if self.debug_mode:
            self.console.print(f"[yellow]üö´ DEBUG: Keeping {os.path.basename(screenshot_path)}[/yellow]")
            return
        
        try:
            if screenshot_path and os.path.exists(screenshot_path):
                os.remove(screenshot_path)
                filename = os.path.basename(screenshot_path)
                self.console.print(f"[dim]üóëÔ∏è Cleaned temp: {filename}[/dim]")
        except Exception as e:
            self.console.print(f"[yellow]‚ö†Ô∏è Cleanup failed for {screenshot_path}: {e}[/yellow]")


==================================================

Path: utils\fdom\seraphine_integrator.py
File: seraphine_integrator.py
Code:
"""
SeraphineIntegrator - Processes seraphine output into fDOM structure
Transforms seraphine_gemini_groups into fDOM nodes and saves element crops
"""
import os
import sys
import json
from pathlib import Path
from typing import Dict, List, Optional, Any
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, TextColumn, BarColumn, TaskProgressColumn
from PIL import Image
import numpy as np

# Add parent directories to path for imports
current_file = Path(__file__).resolve()
utils_dir = current_file.parent.parent
sys.path.append(str(utils_dir))

from config_manager import ConfigManager
from seraphine import process_image_sync  # FIXED: Use actual function from seraphine.py

class SeraphineIntegrator:
    """
    Integrates seraphine analysis into fDOM framework
    """
    
    def __init__(self, app_name: str):
        self.app_name = app_name
        self.console = Console()
        self.config_manager = ConfigManager()
        self.config = self.config_manager.config
        
        # FIXED: Setup paths to point to root-level apps directory
        project_root = Path(__file__).parent.parent.parent  # utils/fdom -> utils -> project_root
        self.app_root = project_root / "apps" / app_name
        self.screenshots_dir = self.app_root / "screenshots"
        self.crops_dir = self.app_root / "crops"
        
        # Ensure directories exist
        self.crops_dir.mkdir(parents=True, exist_ok=True)
        
        self.console.print(f"[bold blue]üîç SeraphineIntegrator initialized for: {app_name}[/bold blue]")
    
    def analyze_screenshot(self, screenshot_path: str, state_id: str, source_element_name: Optional[str] = None) -> Dict:
        """Analyze screenshot and convert to fDOM format"""
        
        # Call Seraphine
        self.console.print(f"[cyan]üîç Analyzing screenshot: {screenshot_path}[/cyan]")
        seraphine_result = process_image_sync(screenshot_path)  # ‚úÖ FIXED: Use imported function directly
        
        if not seraphine_result:
            self.console.print("[red]‚ùå Seraphine analysis failed[/red]")
            return {}
        
        # ‚úÖ DEBUG: Show what Seraphine returned
        self.console.print(f"[cyan]üîç DEBUG: seraphine_result keys: {list(seraphine_result.keys())}[/cyan]")
        
        # ‚úÖ FIXED: Extract the correct groups structure
        seraphine_groups = seraphine_result.get('seraphine_gemini_groups', {})
        
        # ‚úÖ NEW: If seraphine_gemini_groups contains metadata, extract group_details
        if 'group_details' in seraphine_groups:
            self.console.print(f"[cyan]üîß Extracting group_details from seraphine_gemini_groups[/cyan]")
            actual_groups = seraphine_groups['group_details']
        else:
            # Fallback to the groups directly
            actual_groups = seraphine_groups
        
        # ‚úÖ DEBUG: Show actual groups structure
        self.console.print(f"[cyan]üîç DEBUG: actual_groups type: {type(actual_groups)}[/cyan]")
        if isinstance(actual_groups, dict) and actual_groups:
            sample_key = list(actual_groups.keys())[0]
            sample_value = actual_groups[sample_key]
            self.console.print(f"[cyan]üîç DEBUG: Sample group {sample_key}: type={type(sample_value)}[/cyan]")
            if isinstance(sample_value, dict):
                self.console.print(f"[cyan]üîç DEBUG: Sample group keys: {list(sample_value.keys())}[/cyan]")
        
        if not actual_groups:
            self.console.print("[red]‚ùå No actual groups found[/red]")
            return {}
        
        # Display results
        self._display_seraphine_results(seraphine_result)
        
        # Convert to fDOM format using the correct groups
        fdom_nodes = self._convert_seraphine_to_fdom(actual_groups, state_id)
        
        if not fdom_nodes:
            return {}
        
        # Save crops
        self._save_element_crops(screenshot_path, fdom_nodes, state_id, source_element_name)
        
        return {
            'nodes': fdom_nodes,
            'total_time': seraphine_result.get('total_time', 0),
            'total_icons_found': seraphine_result.get('total_icons_found', 0)
        }
    
    def _display_seraphine_results(self, seraphine_result: Dict):
        """Display seraphine analysis results in rich console"""
        
        # Summary panel
        summary_text = f"""
        [bold green]Analysis Complete![/bold green]
        
        ‚è±Ô∏è  Total Time: {seraphine_result.get('total_time', 0):.2f}s
        üéØ  Icons Found: {seraphine_result.get('total_icons_found', 0)}
        üîç  Groups Detected: {len(seraphine_result.get('seraphine_gemini_groups', {}))}
        """
        
        self.console.print(Panel(summary_text, title="üîç Seraphine Analysis Results"))
        
        # Detailed group table
        seraphine_groups = seraphine_result.get('seraphine_gemini_groups', {})
        # if seraphine_groups:
        #     table = Table(title="Detected UI Elements by Group")
        #     table.add_column("Group", style="cyan")
        #     table.add_column("Element", style="yellow")
        #     table.add_column("Name", style="green")
        #     table.add_column("Type", style="blue")
        #     table.add_column("IDs", style="magenta")
            
        #     for group_name, group_elements in seraphine_groups.items():
        #         for element_name, element_data in group_elements.items():
        #             ids_text = f"M:{element_data.get('m_id', 'None')} Y:{element_data.get('y_id', 'None')} O:{element_data.get('o_id', 'None')}"
        #             table.add_row(
        #                 group_name,
        #                 element_name,
        #                 element_data.get('g_icon_name', 'Unknown'),
        #                 element_data.get('type', 'unknown'),
        #                 ids_text
        #             )
            
        #     self.console.print(table)
    
    def _convert_seraphine_to_fdom(self, seraphine_groups: Dict, state_id: str) -> Dict:
        """Convert seraphine_gemini_groups to fDOM nodes format with dropdown merging"""
        
        # ‚úÖ DEBUG: Check the structure of seraphine_groups
        self.console.print(f"[cyan]üîç DEBUG: seraphine_groups type: {type(seraphine_groups)}[/cyan]")
        self.console.print(f"[cyan]üîç DEBUG: seraphine_groups keys: {list(seraphine_groups.keys()) if isinstance(seraphine_groups, dict) else 'Not a dict'}[/cyan]")
        
        # First pass: collect all elements
        all_elements = []
        for group_name, group_elements in seraphine_groups.items():
            # ‚úÖ DEFENSIVE: Check if group_elements is actually a dictionary
            if not isinstance(group_elements, dict):
                self.console.print(f"[red]‚ö†Ô∏è WARNING: group_elements for {group_name} is {type(group_elements)}, expected dict. Value: {group_elements}[/red]")
                self.console.print(f"[yellow]üîß Skipping malformed group: {group_name}[/yellow]")
                continue
            
            for element_name, element_data in group_elements.items():
                # ‚úÖ DEFENSIVE: Check if element_data is a dictionary
                if not isinstance(element_data, dict):
                    self.console.print(f"[red]‚ö†Ô∏è WARNING: element_data for {group_name}::{element_name} is {type(element_data)}, expected dict. Value: {element_data}[/red]")
                    continue
                
                element_data['group'] = group_name
                element_data['element_id'] = element_name
                all_elements.append(element_data)
        
        # ‚úÖ SAFETY: Check if we have any valid elements
        if not all_elements:
            self.console.print(f"[red]‚ùå No valid elements found in seraphine_groups[/red]")
            return {}
        
        # ‚úÖ NEW: Merge dropdown indicators
        merged_elements = self._merge_dropdown_indicators(all_elements)
        
        # Convert to fDOM format
        fdom_nodes = {}
        for element_data in merged_elements:
            element_name = element_data['element_id']
            
            fdom_node = {
                'bbox': element_data.get('bbox', []),
                'g_icon_name': element_data.get('g_icon_name', 'Unknown'),
                'g_brief': element_data.get('g_brief', 'No description'),
                'g_enabled': element_data.get('g_enabled', True),
                'g_interactive': element_data.get('g_interactive', True),
                'g_type': element_data.get('g_type', 'icon'),
                'explore': element_data.get('explore', True),  # NEW: Add explore field
                'm_id': element_data.get('m_id'),
                'y_id': element_data.get('y_id'),
                'o_id': element_data.get('o_id'),
                'type': element_data.get('type', 'unknown'),
                'source': element_data.get('source', 'unknown'),
                'group': element_data['group'],
                'interactivity': {
                    'click_result': None,
                    'type': self._guess_interaction_type(element_data)
                },
                'status': 'pending'
            }
            
            fdom_nodes[element_name] = fdom_node
        
        self.console.print(f"[green]‚úÖ Converted {len(fdom_nodes)} elements to fDOM format[/green]")
        return fdom_nodes
    
    def _merge_dropdown_indicators(self, elements: List[Dict]) -> List[Dict]:
        """Merge standalone dropdown indicators with adjacent elements"""
        
        dropdown_indicators = [">", "v", "‚ñº", "‚ñ≤", "‚åÑ", "‚åÉ", "‚Ä∫", "‚Äπ"]
        elements_to_remove = []
        
        for i, element in enumerate(elements):
            icon_name = element.get('g_icon_name', '').strip()
            
            if icon_name in dropdown_indicators:
                # Find adjacent element (usually to the left)
                target_element = self._find_adjacent_element(element, elements, direction='left')
                
                if target_element:
                    # Merge bboxes
                    orig_bbox = target_element['bbox']
                    arrow_bbox = element['bbox']
                    
                    merged_bbox = [
                        min(orig_bbox[0], arrow_bbox[0]),  # x1
                        min(orig_bbox[1], arrow_bbox[1]),  # y1
                        max(orig_bbox[2], arrow_bbox[2]),  # x2
                        max(orig_bbox[3], arrow_bbox[3])   # y2
                    ]
                    
                    # Update target element
                    target_element['bbox'] = merged_bbox
                    target_element['g_icon_name'] = f"{target_element['g_icon_name']} {icon_name}"
                    target_element['g_brief'] = f"{target_element['g_brief']} (expandable)"
                    
                    # Mark arrow for removal
                    elements_to_remove.append(element)
                    
                    self.console.print(f"[cyan]üîó Merged dropdown: {target_element['g_icon_name']}[/cyan]")
        
        # Remove merged elements
        for element in elements_to_remove:
            elements.remove(element)
        
        return elements
    
    def _find_adjacent_element(self, arrow_element: Dict, all_elements: List[Dict], direction: str = 'left') -> Optional[Dict]:
        """Find immediately adjacent element for merging (no distance limit)"""
        
        arrow_bbox = arrow_element['bbox']
        arrow_center_y = (arrow_bbox[1] + arrow_bbox[3]) / 2
        
        best_candidate = None
        best_distance = float('inf')
        
        for element in all_elements:
            if element == arrow_element:
                continue
            
            element_bbox = element['bbox']
            element_center_y = (element_bbox[1] + element_bbox[3]) / 2
            
            # Check if vertically aligned (same row) - be more flexible
            y_diff = abs(arrow_center_y - element_center_y)
            if y_diff > 30:  # Allow more vertical variance
                continue
            
            # Check horizontal adjacency
            if direction == 'left':
                # Element should be to the left of arrow
                if element_bbox[2] <= arrow_bbox[0]:  # element right edge <= arrow left edge
                    distance = arrow_bbox[0] - element_bbox[2]
                    # ‚úÖ FIXED: Find the CLOSEST left element, no distance limit
                    if distance < best_distance:
                        best_distance = distance
                        best_candidate = element
        
        if best_candidate:
            self.console.print(f"[dim]üîç Found immediate left element: {best_candidate.get('g_icon_name', 'unknown')} (distance: {best_distance}px)[/dim]")
        
        return best_candidate
    
    def _guess_interaction_type(self, element_data: Dict) -> str:
        """Guess interaction type based on element properties"""
        name = element_data.get('g_icon_name', '').lower()
        brief = element_data.get('g_brief', '').lower()
        
        if 'menu' in brief or 'opens the' in brief:
            return 'menu'
        elif 'button' in name or 'click' in brief:
            return 'button'
        elif 'text' in element_data.get('type', ''):
            return 'text_field'
        else:
            return 'unknown'
    
    def _save_element_crops(self, screenshot_path: str, fdom_nodes: Dict, state_id: str, source_element_name: Optional[str] = None):
        """FIXED: Handle semantic names and create proper subfolders"""
        try:
            # Determine crops subfolder
            if source_element_name and state_id != "root":
                # For child states: crops/View/, crops/File/, etc.
                clean_source = source_element_name.replace(' ', '_').replace('/', '_')
                crops_subfolder = self.crops_dir / clean_source
            else:
                # For root state: crops/ (no subfolder)
                crops_subfolder = self.crops_dir
            
            # Debug logging
            self.console.print(f"[yellow]üì∏ Cropping from: {screenshot_path}[/yellow]")
            self.console.print(f"[yellow]üìÅ Saving to: {crops_subfolder}[/yellow]")
            self.console.print(f"[yellow]üìä Processing {len(fdom_nodes)} nodes[/yellow]")
            
            # Ensure crops directory exists
            crops_subfolder.mkdir(parents=True, exist_ok=True)
            
            # Load original image
            original_image = Image.open(screenshot_path)
            self.console.print(f"[green]‚úÖ Image loaded: {original_image.size}[/green]")
            
            saved_count = 0
            
            with Progress(
                TextColumn("[progress.description]{task.description}"),
                BarColumn(),
                TaskProgressColumn(),
                console=self.console
            ) as progress:
                
                task = progress.add_task("Saving element crops...", total=len(fdom_nodes))
                
                for element_name, node_data in fdom_nodes.items():
                    bbox = node_data.get('bbox', [])
                    m_id = node_data.get('m_id', 'Unknown')
                    icon_name = self._sanitize_filename(node_data.get('g_icon_name', 'Unknown'))
                    
                    if len(bbox) == 4:
                        # Crop element
                        x1, y1, x2, y2 = bbox
                        
                        # Validate coordinates
                        if x1 >= 0 and y1 >= 0 and x2 > x1 and y2 > y1:
                            try:
                                cropped = original_image.crop((x1, y1, x2, y2))
                                
                                # Save with naming convention: ElementID_MID_IconName_StateID.png
                                crop_filename = f"{element_name}_{m_id}_{icon_name}_{state_id}.png"
                                crop_path = crops_subfolder / crop_filename
                                
                                cropped.save(crop_path)
                                saved_count += 1
                                
                                # Update node with crop path
                                node_data['crop_path'] = str(crop_path.relative_to(self.app_root))
                                
                                # self.console.print(f"[green]‚úÖ Saved: {crop_filename}[/green]")
                            
                            except Exception as e:
                                self.console.print(f"[red]‚ùå Failed to save {element_name}: {e}[/red]")
                        else:
                            self.console.print(f"[red]‚ùå Invalid bbox for {element_name}: {bbox}[/red]")
                    else:
                        self.console.print(f"[red]‚ùå Missing bbox for {element_name}[/red]")
                    
                    progress.update(task, advance=1)
            
            # self.console.print(f"[green]‚úÖ Saved {saved_count}/{len(fdom_nodes)} element crops to: {crops_subfolder}[/green]")
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Failed to save crops: {str(e)}[/red]")
    
    def _sanitize_filename(self, filename: str) -> str:
        """Sanitize filename for Windows compatibility"""
        # Windows invalid characters: < > : " | ? * \ /
        invalid_chars = '<>:"|?*\\/'
        
        for char in invalid_chars:
            filename = filename.replace(char, '_')
        
        # Also handle special cases and whitespace
        filename = filename.replace(' ', '_')
        filename = filename.replace('(', '').replace(')', '')
        filename = filename.replace('[', '').replace(']', '')
        
        return filename
    
    def test_analysis(self, screenshot_path: str):
        """Test seraphine integration with a specific screenshot"""
        self.console.print(f"\n[bold blue]üß™ TESTING SERAPHINE INTEGRATION[/bold blue]")
        self.console.print(f"[cyan]Screenshot: {screenshot_path}[/cyan]")
        
        if not Path(screenshot_path).exists():
            self.console.print(f"[red]‚ùå Screenshot not found: {screenshot_path}[/red]")
            return
        
        # Run analysis
        result = self.analyze_screenshot(screenshot_path, "TEST")
        
        # Display results summary
        nodes = result.get('nodes', {})
        metadata = result.get('analysis_metadata', {})
        
        summary_text = f"""
        [bold green]Test Complete![/bold green]
        
        üìä Nodes Created: {len(nodes)}
        ‚è±Ô∏è  Analysis Time: {metadata.get('total_time', 0):.2f}s
        üéØ Icons Found: {metadata.get('total_icons_found', 0)}
        üìÅ Crops Saved: {self.crops_dir}
        """
        
        self.console.print(Panel(summary_text, title="üß™ Test Results"))
        
        return result

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Test Seraphine Integration")
    parser.add_argument("--test-analysis", help="Test with specific screenshot")
    parser.add_argument("--app-name", default="notepad", help="App name for testing")
    
    args = parser.parse_args()
    
    if args.test_analysis:
        integrator = SeraphineIntegrator(args.app_name)
        integrator.test_analysis(args.test_analysis)
    else:
        print("Usage: python seraphine_integrator.py --test-analysis path/to/screenshot.png") 

==================================================

Path: utils\fdom\state_manager.py
File: state_manager.py
Code:
"""
StateManager - fDOM graph creation and state tracking for fDOM Framework
Manages NetworkX-based graph structure and node status tracking (pending/explored/non_interactive)
"""
import json
import os
from pathlib import Path
from typing import Dict, List, Optional, Any, Set
from dataclasses import dataclass
from datetime import datetime
import networkx as nx
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.tree import Tree
from rich.progress import Progress, TextColumn, BarColumn, TaskProgressColumn
from rich import print as rprint

from config_manager import ConfigManager
from seraphine_integrator import SeraphineIntegrator


@dataclass
class FDOMNode:
    """
    Individual fDOM node representing a UI element
    """
    # ‚úÖ FIELDS WITHOUT DEFAULTS (must come first)
    id: str                    # H0_1, H1_2, etc.
    bbox: List[int]           # [x1, y1, x2, y2]
    g_icon_name: str          # Seraphine-generated name
    g_brief: str              # Seraphine-generated description
    m_id: str                 # Master ID from seraphine
    type: str                 # "icon" or "text" (from yolo/ocr)
    source: str               # "yolo" or "ocr_det"
    group: str                # H0, H1, H2, etc.
    
    # ‚úÖ OPTIONAL FIELDS (can have None defaults)
    y_id: Optional[str] = None       # YOLO detection ID
    o_id: Optional[str] = None       # OCR detection ID
    
    # ‚úÖ FIELDS WITH DEFAULTS (must come last)
    g_enabled: bool = True           # Whether element is enabled (not grayed out)
    g_interactive: bool = True       # Whether element is interactive
    g_type: str = "icon"            # Gemini-analyzed type: "icon" or "text"
    status: str = "pending"          # "pending", "explored", "non_interactive"
    click_result: Optional[str] = None    # Points to next state ID
    interaction_type: Optional[str] = None # "menu", "dialog", "navigation", etc.
    
    def to_dict(self) -> Dict:
        """Convert to fDOM JSON format"""
        node_dict = {
            "bbox": self.bbox,
            "g_icon_name": self.g_icon_name,
            "g_brief": self.g_brief,
            "g_enabled": self.g_enabled,
            "g_interactive": self.g_interactive,
            "g_type": self.g_type,
            "m_id": self.m_id,
            "y_id": self.y_id,
            "o_id": self.o_id,
            "type": self.type,
            "source": self.source,
            "group": self.group,
            "status": self.status
        }
        
        # Add interactivity section if element has been explored
        if self.click_result or self.interaction_type:
            node_dict["interactivity"] = {}
            if self.click_result:
                node_dict["interactivity"]["click_result"] = self.click_result
            if self.interaction_type:
                node_dict["interactivity"]["type"] = self.interaction_type
                
        return node_dict


class StateManager:
    """
    Manages fDOM graph creation, state tracking, and NetworkX operations
    """
    
    def __init__(self, app_name: str):
        self.app_name = app_name
        self.config = ConfigManager()
        self.console = Console()
        self.seraphine = SeraphineIntegrator(app_name)
        
        # NetworkX graph for exploration logic
        self.exploration_graph = nx.DiGraph()
        
        # SEMANTIC NAMING: Start with root
        self.current_state_id = "root"  # ‚úÖ Not "S001"
        
        # Initialize fDOM with semantic structure
        self.fdom_data = {
            "app_name": app_name,
            "loaded": False,
            "creation_timestamp": datetime.now().isoformat(),
            "navigation_tree": {},  # Track semantic hierarchy
            "states": {},
            "edges": []
        }
        
        # Tracking
        self.total_nodes = 0
        self.pending_nodes: Set[str] = set()
        self.explored_nodes: Set[str] = set()
        self.non_interactive_nodes: Set[str] = set()
        
        self.console.print(f"[green]üß† StateManager initialized for: {app_name}[/green]")
    
    def create_initial_fdom_state(self, screenshot_path: str) -> Dict:
        """FIXED: Use semantic naming for root state"""
        self.console.print(f"\n[bold blue]üèóÔ∏è CREATING INITIAL ROOT STATE[/bold blue]")
        self.console.print(f"Screenshot: {screenshot_path}")
        
        # Process through seraphine - pass "root" instead of current_state_id
        seraphine_result = self.seraphine.analyze_screenshot(screenshot_path, "root")
        
        if not seraphine_result or not seraphine_result.get('nodes'):
            self.console.print("[red]‚ùå No nodes detected from screenshot[/red]")
            return {}
        
        # Create ROOT state data
        state_data = {
            "id": "root",  # ‚úÖ Semantic name
            "parent": None,
            "trigger_node": None,
            "trigger_element": "initial_state",
            "breadcrumb": "root",
            "image": screenshot_path,  # ‚úÖ This should be current screenshot, not S001.png
            "creation_timestamp": datetime.now().isoformat(),
            "analysis_time": seraphine_result.get('analysis_time', 0),
            "total_elements": len(seraphine_result['nodes']),
            "nodes": {}
        }
        
        # Convert seraphine nodes to fDOM nodes
        fdom_nodes = []
        for node_id, node_data in seraphine_result['nodes'].items():
            fdom_node = FDOMNode(
                id=node_id,
                bbox=node_data['bbox'],
                g_icon_name=node_data['g_icon_name'],
                g_brief=node_data['g_brief'],
                g_enabled=node_data.get('g_enabled', True),
                g_interactive=node_data.get('g_interactive', True),
                g_type=node_data.get('g_type', 'icon'),
                m_id=node_data['m_id'],
                y_id=node_data.get('y_id'),
                o_id=node_data.get('o_id'),
                type=node_data['type'],
                source=node_data['source'],
                group=node_data['group']
            )
            fdom_nodes.append(fdom_node)
            
            # Add to fDOM data
            state_data["nodes"][node_id] = fdom_node.to_dict()
            
            # Add to NetworkX graph
            self.exploration_graph.add_node(
                node_id,
                **fdom_node.__dict__
            )
            
            # Track as pending for exploration
            self.pending_nodes.add(f"root::{node_id}")
        
        # Save state to fDOM data
        self.fdom_data["states"]["root"] = state_data
        self.total_nodes = len(fdom_nodes)
        
        
        # ‚úÖ FIXED: Save the fDOM data to file
        self.save_fdom_to_file()
        
        return state_data
    
    def get_next_pending_node(self) -> Optional[str]:
        """
        Get the next node that needs to be explored (graph-based traversal)
        
        Returns:
            Node ID to explore next, or None if all explored
        """
        if not self.pending_nodes:
            return None
            
        # For now, return first pending node (can implement smarter strategies later)
        return next(iter(self.pending_nodes))
    
    def mark_node_explored(self, node_id: str, click_result: Optional[str] = None, 
                          interaction_type: Optional[str] = None) -> None:
        """
        Mark a node as explored and update its interaction results
        
        Args:
            node_id: Node to mark as explored
            click_result: Result state ID if clicking caused state change
            interaction_type: Type of interaction (menu, dialog, etc.)
        """
        if node_id in self.pending_nodes:
            self.pending_nodes.remove(node_id)
            
        if click_result:
            self.explored_nodes.add(node_id)
            # Update in graph
            if self.exploration_graph.has_node(node_id):
                self.exploration_graph.nodes[node_id]['status'] = 'explored'
                self.exploration_graph.nodes[node_id]['click_result'] = click_result
                self.exploration_graph.nodes[node_id]['interaction_type'] = interaction_type
                
            # Update in fDOM data
            for state_id, state_data in self.fdom_data["states"].items():
                if node_id in state_data.get("nodes", {}):
                    state_data["nodes"][node_id]["status"] = "explored"
                    if "interactivity" not in state_data["nodes"][node_id]:
                        state_data["nodes"][node_id]["interactivity"] = {}
                    state_data["nodes"][node_id]["interactivity"]["click_result"] = click_result
                    if interaction_type:
                        state_data["nodes"][node_id]["interactivity"]["type"] = interaction_type
                    break
        else:
            self.non_interactive_nodes.add(node_id)
            # Update status to non_interactive
            if self.exploration_graph.has_node(node_id):
                self.exploration_graph.nodes[node_id]['status'] = 'non_interactive'
                
            # Update in fDOM data
            for state_id, state_data in self.fdom_data["states"].items():
                if node_id in state_data.get("nodes", {}):
                    state_data["nodes"][node_id]["status"] = "non_interactive"
                    break
    
    def save_fdom_to_file(self, output_path: Optional[str] = None) -> str:
        """
        Save the current fDOM structure to JSON file
        
        Args:
            output_path: Custom output path, or auto-generate if None
            
        Returns:
            Path where fDOM was saved
        """
        if not output_path:
            app_dir = Path(__file__).parent.parent.parent / "apps" / self.app_name
            app_dir.mkdir(parents=True, exist_ok=True)
            output_path = app_dir / "fdom.json"
        
        # Update metadata
        self.fdom_data.update({
            "last_updated": datetime.now().isoformat(),
            "total_states": len(self.fdom_data["states"]),
            "exploration_stats": {
                "pending_nodes": len(self.pending_nodes),
                "explored_nodes": len(self.explored_nodes),
                "non_interactive_nodes": len(self.non_interactive_nodes),
                "total_nodes": self.total_nodes
            }
        })
        
        # Save to file
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.fdom_data, f, indent=2, ensure_ascii=False)
        
        self.console.print(f"[green]üíæ fDOM saved to: {output_path}[/green]")
        return str(output_path)
    
    def _rebuild_tracking_sets(self) -> None:
        """FIXED: Handle duplicate node IDs across states"""
        self.pending_nodes.clear()
        self.explored_nodes.clear()
        self.non_interactive_nodes.clear()
        
        # Use state-prefixed node IDs to avoid collisions
        for state_name, state_data in self.fdom_data.get("states", {}).items():
            nodes = state_data.get("nodes", {})
            for node_id, node_data in nodes.items():
                status = node_data.get("status", "pending")
                
                # Create unique ID: state_name::node_id
                unique_node_id = f"{state_name}::{node_id}"
                
                if status == "pending":
                    self.pending_nodes.add(unique_node_id)
                elif status == "explored":
                    self.explored_nodes.add(unique_node_id)
                elif status == "non_interactive":
                    self.non_interactive_nodes.add(unique_node_id)
        
        self.total_nodes = len(self.pending_nodes) + len(self.explored_nodes) + len(self.non_interactive_nodes)
        
        self.console.print(f"[green]üîÑ Rebuilt tracking sets: {len(self.pending_nodes)} pending, {len(self.explored_nodes)} explored, {len(self.non_interactive_nodes)} non-interactive[/green]")
        self.console.print(f"[cyan]üß≠ Current state: {self.current_state_id}[/cyan]")

    
    def display_exploration_status(self) -> None:
        """Display current exploration status and graph statistics"""
        
        # Status panel
        status_panel = Panel(
            f"[bold]Exploration Status[/bold]\n\n"
            f"üü° Pending: {len(self.pending_nodes)}\n"
            f"üü¢ Explored: {len(self.explored_nodes)}\n"
            f"üî¥ Non-Interactive: {len(self.non_interactive_nodes)}\n"
            f"üìä Total Nodes: {self.total_nodes}\n"
            f"üìà States Created: {len(self.fdom_data['states'])}",
            title="üß† fDOM Exploration Status",
            border_style="green"
        )
        self.console.print(status_panel)
        
        # Next node to explore
        next_node = self.get_next_pending_node()
        if next_node:
            self.console.print(f"[yellow]‚è≠Ô∏è  Next to explore: {next_node}[/yellow]")
        else:
            self.console.print("[green]‚úÖ All nodes explored![/green]")


def test_fdom_creation(screenshot_path: str, app_name: str = "test_app"):
    """Test function for DELTA 5"""
    console = Console()
    
    console.print(Panel(
        f"[bold]üß™ TESTING fDOM CREATION[/bold]\n"
        f"Screenshot: {screenshot_path}\n"
        f"App: {app_name}",
        title="DELTA 5 Test",
        border_style="yellow"
    ))
    
    # Initialize StateManager
    state_manager = StateManager(app_name)
    
    # Create initial fDOM state
    state_data = state_manager.create_initial_fdom_state(screenshot_path)
    
    if not state_data:
        console.print("[red]‚ùå Test failed - no state created[/red]")
        return
    
    # Display exploration status
    state_manager.display_exploration_status()
    
    # Save fDOM to file
    fdom_path = state_manager.save_fdom_to_file()
    
    # Test results
    test_panel = Panel(
        f"[bold]Test Complete![/bold]\n\n"
        f"üìä Nodes Created: {len(state_data.get('nodes', {}))}\n"
        f"‚è±Ô∏è  Analysis Time: {state_data.get('analysis_time', 0):.2f}s\n"
        f"üü° Pending: {len(state_manager.pending_nodes)}\n"
        f"üíæ fDOM Saved: {fdom_path}",
        title="üß™ Test Results",
        border_style="green"
    )
    console.print(test_panel)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="StateManager for fDOM Framework")
    parser.add_argument("--test-fdom-creation", type=str, help="Test fDOM creation with screenshot path")
    parser.add_argument("--app-name", type=str, default="test_app", help="App name for testing")
    
    args = parser.parse_args()
    
    if args.test_fdom_creation:
        test_fdom_creation(args.test_fdom_creation, args.app_name)
    else:
        print("Use --test-fdom-creation <screenshot_path> to test")


==================================================

Path: utils\fdom\state_processor.py
File: state_processor.py
Code:
"""State creation and processing logic"""
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional
from rich.console import Console


class StateProcessor:
    """Handles state creation, semantic naming, and metadata"""
    
    def __init__(self, state_manager, seraphine_integrator, visual_differ):
        self.state_manager = state_manager
        self.seraphine_integrator = seraphine_integrator
        self.visual_differ = visual_differ
        self.console = Console()
        
    def process_successful_click(self, node_id: str, source_element_name: str, 
                            current_state: str, before_screenshot: str, 
                            after_screenshot: str, diff_path: str, 
                            perfect_diff_result: Dict = None) -> Optional[str]:
        """Process a successful click that caused state change - REUSE PERFECT CROP"""
        
        # Generate semantic state name
        new_state_name = self._generate_semantic_state_name(source_element_name, current_state)
        
        # ‚úÖ REUSE PERFECT CROP from ClickEngine instead of creating new one
        if perfect_diff_result and perfect_diff_result.get("success"):
            diff_result = perfect_diff_result
            # Copy the perfect crop to our diff_path location
            import shutil
            perfect_crop_path = perfect_diff_result["diff_image_path"]
            shutil.copy2(perfect_crop_path, diff_path)
            self.console.print(f"[green]‚úÖ Reused perfect crop from ClickEngine[/green]")
        else:
            # Fallback: create new crop (shouldn't happen)
            diff_result = self.visual_differ.extract_change_regions(
                before_screenshot, after_screenshot, diff_path, (0, 0)
            )
        
        if not diff_result["success"]:
            self.console.print("[red]‚ùå Failed to extract change regions[/red]")
            return None
        
        # Analyze with Seraphine using the actual difference image
        popup_crop_path = diff_result["diff_image_path"]
        seraphine_result = self.seraphine_integrator.analyze_screenshot(
            popup_crop_path, new_state_name, source_element_name
        )
        
        if not seraphine_result or not seraphine_result.get('nodes'):
            self.console.print("[red]‚ùå Seraphine analysis failed[/red]")
            return None
        
        # Create new state data
        new_state_data = self._create_semantic_state_data(
            new_state_name, seraphine_result, diff_path,
            source_element_name, node_id, current_state
        )
        
        # Add elements with coordinate mapping and deduplication
        unified_region = diff_result["regions"][0]
        x_offset, y_offset = unified_region[0], unified_region[1]
        
        new_nodes_added = 0
        for popup_node_id, popup_node_data in seraphine_result['nodes'].items():
            crop_bbox = popup_node_data['bbox']
            full_bbox = [
                crop_bbox[0] + x_offset, crop_bbox[1] + y_offset,
                crop_bbox[2] + x_offset, crop_bbox[3] + y_offset
            ]
            popup_node_data['bbox'] = full_bbox
            
            if not self._is_duplicate_element(popup_node_data, current_state):
                new_state_data["nodes"][popup_node_id] = popup_node_data
                self.state_manager.pending_nodes.add(f"{new_state_name}::{popup_node_id}")
                new_nodes_added += 1
            else:
                self.console.print(f"[dim]üîÑ Skipped duplicate: {popup_node_data.get('g_icon_name', 'unknown')}[/dim]")
        
        self.console.print(f"[cyan]‚úÖ Added {new_nodes_added}/{len(seraphine_result['nodes'])} new elements[/cyan]")
        
        # Save state and update tracking
        self.state_manager.fdom_data["states"][new_state_name] = new_state_data
        self.state_manager.mark_node_explored(node_id, click_result=new_state_name, interaction_type="menu")
        self._add_interaction_edge(current_state, new_state_name, node_id)
        self.state_manager.save_fdom_to_file()
        
        return new_state_name

    
    def _generate_semantic_state_name(self, element_name: str, current_state: str) -> str:
        """Generate file-safe semantic state name"""
        clean_name = element_name.lower().replace(' ', '_').replace('(', '').replace(')', '').replace('/', '_')
        
        if current_state == "root":
            return f"root_{clean_name}"
        else:
            return f"{current_state}_{clean_name}"
    
    def _create_semantic_state_data(self, state_name: str, seraphine_result: Dict, 
                                   diff_path: str, source_element: str, 
                                   trigger_node: str, parent_state: str) -> Dict:
        """Create state with semantic metadata"""
        display_breadcrumb = state_name.replace('_', '>')
        
        return {
            "id": state_name,
            "parent": parent_state,
            "trigger_node": trigger_node,
            "trigger_element": source_element,
            "breadcrumb": display_breadcrumb,
            "image": str(diff_path),
            "creation_timestamp": datetime.now().isoformat(),
            "analysis_time": seraphine_result.get('total_time', 0),
            "total_elements": len(seraphine_result['nodes']),
            "nodes": {}
        }
    
    def _is_duplicate_element(self, node_data: Dict, current_state: str) -> bool:
        """ENHANCED: Check if element is duplicate with stronger logic"""
        element_name = node_data.get('g_icon_name', '').lower().strip()
        element_bbox = node_data.get('bbox', [])
        
        if not element_name or not element_bbox or len(element_bbox) != 4:
            return False
        
        # Calculate element dimensions for proportional tolerance
        element_width = element_bbox[2] - element_bbox[0]
        element_height = element_bbox[3] - element_bbox[1]
        
        # ‚úÖ FLEXIBLE: Tolerance based on element size (5% of width/height, min 10px, max 50px)
        position_tolerance = max(10, min(50, max(element_width * 0.05, element_height * 0.05)))
        
        # Check against ALL states in fDOM
        for state_name, state_data in self.state_manager.fdom_data.get("states", {}).items():
            for existing_node_id, existing_node_data in state_data.get("nodes", {}).items():
                existing_name = existing_node_data.get('g_icon_name', '').lower().strip()
                existing_bbox = existing_node_data.get('bbox', [])
                existing_status = existing_node_data.get('status', 'unknown')
                
                if not existing_name or len(existing_bbox) != 4:
                    continue
                
                # ‚úÖ STRONG: Multiple criteria for duplicate detection
                name_match = element_name == existing_name
                
                # Position similarity with proportional tolerance
                position_match = (
                    abs(element_bbox[0] - existing_bbox[0]) < position_tolerance and
                    abs(element_bbox[1] - existing_bbox[1]) < position_tolerance
                )
                
                # Size similarity (within 20% variance)
                existing_width = existing_bbox[2] - existing_bbox[0]
                existing_height = existing_bbox[3] - existing_bbox[1]
                
                size_match = (
                    abs(element_width - existing_width) < max(element_width * 0.2, 10) and
                    abs(element_height - existing_height) < max(element_height * 0.2, 10)
                )
                
                if name_match and position_match and size_match:
                    # ‚úÖ PRIORITY: If existing element is already explored, definitely skip
                    if existing_status == "explored":
                        self.console.print(f"[yellow]üîÑ Skipped duplicate (already explored): {element_name} in {state_name}[/yellow]")
                        return True
                    
                    # ‚úÖ SMART: Even if pending, avoid duplicates in different states
                    self.console.print(f"[yellow]üîÑ Skipped duplicate (already exists): {element_name} in {state_name}[/yellow]")
                    return True
        
        return False
    
    def _add_interaction_edge(self, from_state: str, to_state: str, node_id: str) -> None:
        """Add edge with enhanced semantic information"""
        # Extract clean node ID
        if "::" in node_id:
            _, clean_node_id = node_id.split("::", 1)
        else:
            clean_node_id = node_id
        
        # Get element info for better edge description
        node_data = self._find_node_in_fdom(node_id)
        element_name = node_data.get('g_icon_name', 'unknown') if node_data else 'unknown'
        
        edge = {
            "from": from_state,
            "to": to_state,
            "action": f"click:{clean_node_id}",
            "element_name": element_name,
            "navigation": f"{from_state} ‚Üí {to_state}",
            "timestamp": datetime.now().isoformat()
        }
        
        if "edges" not in self.state_manager.fdom_data:
            self.state_manager.fdom_data["edges"] = []
            
        self.state_manager.fdom_data["edges"].append(edge)
        
        self.console.print(f"[blue]üîó Edge added: {from_state} --[{element_name}]--> {to_state}[/blue]")
    
    def _find_node_in_fdom(self, node_id: str) -> Optional[Dict]:
        """Find node data in fDOM"""
        if "::" in node_id:
            state_name, actual_node_id = node_id.split("::", 1)
            state_data = self.state_manager.fdom_data.get("states", {}).get(state_name, {})
            return state_data.get("nodes", {}).get(actual_node_id)
        
        # Fallback: search all states
        for state_data in self.state_manager.fdom_data.get("states", {}).values():
            nodes = state_data.get("nodes", {})
            if node_id in nodes:
                return nodes[node_id]
        return None
    
    def _sanitize_filename(self, filename: str) -> str:
        """Sanitize filename for Windows compatibility"""
        # Windows invalid characters: < > : " | ? * \
        invalid_chars = '<>:"|?*\\'
        
        for char in invalid_chars:
            filename = filename.replace(char, '_')
        
        # Also handle special cases
        filename = filename.replace('(', '').replace(')', '')
        filename = filename.replace('[', '').replace(']', '')
        
        return filename 


==================================================

Path: utils\fdom\visual_differ.py
File: visual_differ.py
Code:
"""
VisualDiffer - Visual comparison and hash-based change detection for fDOM Framework
Handles screenshot comparison using hash and OpenCV-based region extraction
"""
import hashlib
import os
from pathlib import Path
from typing import Dict, Optional, Tuple
import numpy as np
from PIL import Image
from rich.console import Console
from rich.panel import Panel
import time

class VisualDiffer:
    """
    Handles visual comparison and change detection between screenshots
    """
    
    def __init__(self, config_manager):
        self.config = config_manager
        self.console = Console()
    
    def calculate_image_hash(self, image_path: str) -> str:
        """
        Calculate perceptual hash of an image
        
        Args:
            image_path: Path to image file
            
        Returns:
            Hash string for comparison
        """
        try:
            with Image.open(image_path) as img:
                # Convert to grayscale and resize for consistent hashing
                img = img.convert('L').resize((64, 64))
                
                # Calculate hash using pixel data
                pixels = np.array(img)
                hash_obj = hashlib.md5(pixels.tobytes())
                return hash_obj.hexdigest()
                
        except Exception as e:
            self.console.print(f"[red]‚ùå Error calculating hash for {image_path}: {e}[/red]")
            return ""

    def extract_change_regions(self, before_path: str, after_path: str, 
                              output_diff_path: str, click_coords: Optional[Tuple] = None) -> Dict:
        """
        Extract FULL difference region as single crop (following old.txt approach)
        """
        try:
            import cv2
            import numpy as np
            
            self.console.print(f"[yellow]üîç EXTRACTING FULL DIFFERENCE REGION...[/yellow]")
            self.console.print(f"Before: {Path(before_path).name}")
            self.console.print(f"After:  {Path(after_path).name}")
            
            # Load both images
            img1 = cv2.imread(before_path)
            img2 = cv2.imread(after_path)
            
            if img1 is None or img2 is None:
                return {"success": False, "error": "Could not load images"}
            
            # Match dimensions if needed
            if img1.shape != img2.shape:
                h = min(img1.shape[0], img2.shape[0])
                w = min(img1.shape[1], img2.shape[1])
                img1 = cv2.resize(img1, (w, h))
                img2 = cv2.resize(img2, (w, h))
                self.console.print(f"[yellow]‚ö†Ô∏è Resized both images to ({w}, {h})[/yellow]")

            # Convert to grayscale and compute absolute difference
            gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
            gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
            diff = cv2.absdiff(gray1, gray2)

            # Threshold and dilate
            _, thresh = cv2.threshold(diff, 15, 255, cv2.THRESH_BINARY)
            dilated = cv2.dilate(thresh, np.ones((5, 5), np.uint8), iterations=2)

            # Find contours
            contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            boxes = [cv2.boundingRect(cnt) for cnt in contours if cv2.contourArea(cnt) > 500]

            if not boxes:
                self.console.print("[red]‚ÑπÔ∏è No significant visual differences found.[/red]")
                return {"success": False, "reason": "No significant differences detected"}

            # Compute bounding box of ALL diffs (unified region)
            x_min = min(x for x, y, w, h in boxes)
            y_min = min(y for x, y, w, h in boxes)
            x_max = max(x + w for x, y, w, h in boxes)
            y_max = max(y + h for x, y, w, h in boxes)

            # Extract the unified changed region from AFTER image
            crop = img2[y_min:y_max, x_min:x_max]
            
            # Save ONLY the cropped popup/menu region
            cv2.imwrite(output_diff_path, crop)
            
            # self.console.print(f"[green]‚úÖ Saved popup/menu region: {Path(output_diff_path).name}[/green]")
            # self.console.print(f"[cyan]üì¶ Crop region: ({x_min}, {y_min}) to ({x_max}, {y_max})[/cyan]")
            # self.console.print(f"[cyan]üìê Crop size: {x_max-x_min} x {y_max-y_min}[/cyan]")
            
            # Return the unified region as a single tuple (x, y, width, height)
            unified_region = (x_min, y_min, x_max - x_min, y_max - y_min)
            
            return {
                "success": True,
                "regions": [unified_region],  # Single unified region
                "change_percentage": 100,  # Always significant since we found changes
                "detection_method": "opencv_unified_crop",
                "total_regions": 1,
                "diff_image_path": output_diff_path,
                "crop_bounds": (x_min, y_min, x_max, y_max)
            }
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Full difference extraction failed: {e}[/red]")
            import traceback
            traceback.print_exc()
            return {"success": False, "error": str(e)}

    def calculate_similarity_percentage(self, image1_path: str, image2_path: str, threshold: int = 15) -> float:
        """
        Calculate similarity percentage between two images using pixel difference analysis
        
        Args:
            image1_path: Path to first image
            image2_path: Path to second image  
            threshold: Pixel difference threshold (lower = more sensitive)
            
        Returns:
            Similarity percentage (0-100, where 100 = identical)
        """
        try:
            import cv2
            import numpy as np
            
            # Load images
            img1 = cv2.imread(image1_path)
            img2 = cv2.imread(image2_path)
            
            if img1 is None or img2 is None:
                self.console.print(f"[red]‚ùå Could not load images for comparison[/red]")
                return 0.0
            
            # Ensure same dimensions
            if img1.shape != img2.shape:
                h = min(img1.shape[0], img2.shape[0])
                w = min(img1.shape[1], img2.shape[1])
                img1 = cv2.resize(img1, (w, h))
                img2 = cv2.resize(img2, (w, h))
            
            # Convert to grayscale and calculate difference
            gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
            gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
            diff = cv2.absdiff(gray1, gray2)
            
            # Count pixels that differ significantly
            different_pixels = np.sum(diff > threshold)
            total_pixels = diff.shape[0] * diff.shape[1]
            
            # Calculate similarity percentage
            similarity = ((total_pixels - different_pixels) / total_pixels) * 100
            
            return round(similarity, 2)
            
        except Exception as e:
            self.console.print(f"[red]‚ùå Similarity calculation failed: {e}[/red]")
            return 0.0


# Test function
def test_visual_differ():
    """Test the VisualDiffer functionality"""
    from config_manager import ConfigManager
    
    config = ConfigManager()
    differ = VisualDiffer(config)
    
    print("üß™ Testing VisualDiffer...")
    
    # Test hash calculation
    test_image = "../../apps/notepad/screenshots/S001.png"
    if Path(test_image).exists():
        hash_result = differ.calculate_image_hash(test_image)
        print(f"‚úÖ Hash calculation: {hash_result[:16]}...")
    else:
        print("‚ùå Test image not found")

if __name__ == "__main__":
    test_visual_differ()


==================================================

Path: utils\gui_controller.py
File: gui_controller.py
Code:
"""
Simple Window API - Clean interface for window management
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from windowManager.window_functions import WindowController
from typing import Optional, Tuple, List, Dict

class SimpleWindowAPI:
    def __init__(self):
        self.controller = WindowController()
        self.controller.refresh_windows()
    
    # Window Discovery
    def get_windows(self) -> Dict:
        """Get all windows - returns clean dictionary"""
        self.controller.refresh_windows()
        return self.controller.window_lookup
    
    def find_window(self, title_contains: str) -> Optional[str]:
        """Find window by title - returns window ID or None"""
        self.controller.refresh_windows()
        for window_id, window_info in self.controller.window_lookup.items():
            if title_contains.lower() in window_info['window_data']['title'].lower():
                return window_id
        return None
    
    def list_windows(self):
        """Print all windows with their IDs for easy discovery"""
        self.controller.print_windows_summary()
    
    # Window Control (return True/False for simplicity)
    def focus_window(self, window_id: str) -> bool:
        """Focus a window"""
        success, _ = self.controller._execute_single_command(f"{window_id} f")
        return success
    
    def close_window(self, window_id: str) -> bool:
        """Close a window"""
        success, _ = self.controller._execute_single_command(f"{window_id} c")
        return success
    
    def minimize_window(self, window_id: str) -> bool:
        """Minimize a window"""
        success, _ = self.controller._execute_single_command(f"{window_id} m")
        return success
    
    def maximize_window(self, window_id: str) -> bool:
        """Maximize a window"""
        success, _ = self.controller._execute_single_command(f"{window_id} M")
        return success
    
    def resize_window(self, window_id: str, width: int, height: int) -> bool:
        """Resize a window"""
        success, _ = self.controller._execute_single_command(f"{window_id} resize {width} {height}")
        return success
    
    def move_window(self, window_id: str, x: int, y: int) -> bool:
        """Move a window"""
        success, _ = self.controller._execute_single_command(f"{window_id} move {x} {y}")
        return success
    
    def move_window_to_monitor(self, window_id: str, monitor_id: int) -> bool:
        """Move window to specific monitor"""
        success, _ = self.controller._execute_single_command(f"{window_id} monitor {monitor_id}")
        return success
    
    # Mouse Control
    def click(self, x: int = None, y: int = None, button: str = "left") -> bool:
        """Click at position (or current cursor if no position)"""
        if x is not None and y is not None:
            success, _ = self.controller._execute_single_command(f"click {button} {x} {y}")
        else:
            success, _ = self.controller._execute_single_command(f"click {button}")
        return success
    
    def double_click(self, x: int = None, y: int = None, button: str = "left") -> bool:
        """Double click at position"""
        if x is not None and y is not None:
            success, _ = self.controller._execute_single_command(f"doubleclick {button} {x} {y}")
        else:
            success, _ = self.controller._execute_single_command(f"doubleclick {button}")
        return success
    
    def long_click(self, duration: float = 1.0, x: int = None, y: int = None, button: str = "left") -> bool:
        """Long click (hold) at position"""
        if x is not None and y is not None:
            success, _ = self.controller._execute_single_command(f"longclick {button} {duration} {x} {y}")
        else:
            success, _ = self.controller._execute_single_command(f"longclick {button} {duration}")
        return success
    
    def drag(self, start_x: int, start_y: int, end_x: int, end_y: int, button: str = "left", duration: float = 0.5) -> bool:
        """Drag from start to end position"""
        success, _ = self.controller._execute_single_command(f"drag {start_x} {start_y} {end_x} {end_y} {button} {duration}")
        return success
    
    def scroll(self, direction: str, amount: int = 3, x: int = None, y: int = None) -> bool:
        """Scroll up/down/left/right"""
        if x is not None and y is not None:
            success, _ = self.controller._execute_single_command(f"scroll {direction} {amount} {x} {y}")
        else:
            success, _ = self.controller._execute_single_command(f"scroll {direction} {amount}")
        return success
    
    # Keyboard Control
    def type_text(self, text: str) -> bool:
        """Type text"""
        success, _ = self.controller._execute_single_command(f"type {text}")
        return success
    
    def send_keys(self, keys: str) -> bool:
        """Send key combination (e.g., 'ctrl+c', 'alt+tab')"""
        success, _ = self.controller._execute_single_command(f"send {keys}")
        return success
    
    # Cursor Control
    def get_cursor_position(self) -> Optional[Tuple[int, int]]:
        """Get current cursor position"""
        success, message, pos = self.controller.wm.get_cursor_position()
        return pos if success else None
    
    def set_cursor_position(self, x: int, y: int) -> bool:
        """Set cursor position"""
        success, _ = self.controller._execute_single_command(f"cursor {x} {y}")
        return success
    
    # Introspection and Detection
    def inspect_cursor(self) -> Tuple[bool, str]:
        """Inspect element under cursor"""
        return self.controller._handle_introspection_command()
    
    def inspect_window(self, window_id: str) -> Tuple[bool, str]:
        """Inspect specific window"""
        if window_id not in self.controller.window_lookup:
            return False, f"Window ID '{window_id}' not found"
        
        window_info = self.controller.window_lookup[window_id]
        hwnd = window_info['window_data']['hwnd']
        return self.controller._handle_introspection_command(hwnd)
    
    def get_window_hierarchy(self, window_id: str) -> Tuple[bool, str]:
        """Get window hierarchy tree"""
        success, _ = self.controller._execute_single_command(f"{window_id} tree")
        return success
    
    # System Information
    def get_computer_name(self) -> str:
        """Get computer name"""
        success, message = self.controller._execute_single_command("computer")
        return message if success else ""
    
    def get_user_name(self) -> str:
        """Get current user name"""
        success, message = self.controller._execute_single_command("user")
        return message if success else ""
    
    # Application Launcher
    def launch_app(self, app_name: str, screen_id: int, fullscreen: bool = True) -> bool:
        """Launch application on specific screen"""
        mode = "fullscreen" if fullscreen else "normal"
        success, _ = self.controller._execute_single_command(f"launch {app_name} {screen_id} {mode}")
        return success
    
    # Message Box
    def show_message(self, title: str, message: str, x: int = None, y: int = None) -> bool:
        """Show message box"""
        if x is not None and y is not None:
            success, _ = self.controller._execute_single_command(f"msgbox {title} {message} {x} {y}")
        else:
            success, _ = self.controller._execute_single_command(f"msgbox {title} {message}")
        return success
    
    # Command Chaining
    def execute_chain(self, commands: List[str]) -> bool:
        """Execute a chain of commands"""
        command_string = " : ".join(commands)
        continue_running, message = self.controller.process_command(command_string)
        print(message)  # Print the chain execution results
        return continue_running
    
    # Utility Methods
    def get_window_info(self, window_id: str) -> Optional[Dict]:
        """Get detailed window information"""
        if window_id in self.controller.window_lookup:
            return self.controller.window_lookup[window_id]
        return None
    
    def get_window_state(self, window_id: str) -> Optional[str]:
        """Get window state (minimized, maximized, normal)"""
        if window_id not in self.controller.window_lookup:
            return None
        
        window_info = self.controller.window_lookup[window_id]
        hwnd = window_info['window_data']['hwnd']
        return self.controller.wm.get_window_state(hwnd)
    
    def get_window_position(self, window_id: str) -> Optional[Tuple[int, int]]:
        """Get window position"""
        info = self.get_window_info(window_id)
        if info:
            pos = info['window_data']['position']
            return (pos['x'], pos['y'])
        return None
    
    def get_window_size(self, window_id: str) -> Optional[Tuple[int, int]]:
        """Get window size"""
        info = self.get_window_info(window_id)
        if info:
            size = info['window_data']['size']
            return (size['width'], size['height'])
        return None
    
    def refresh(self):
        """Refresh window list"""
        self.controller.refresh_windows()
    
    def send_esc_enhanced(self) -> bool:
        """Enhanced ESC key for dialogs and modal windows"""
        success, _ = self.controller.wm.send_esc_enhanced()
        return success

# Convenience function for quick access
def get_window_api() -> SimpleWindowAPI:
    """Get a SimpleWindowAPI instance"""
    return SimpleWindowAPI()

# Quick test function
def quick_test():
    """Quick test to verify the API works"""
    print("üöÄ Testing Simple Window API...")
    api = get_window_api()
    
    # List available windows
    print("\nüìã Available Windows:")
    api.list_windows()
    
    # Get cursor position
    pos = api.get_cursor_position()
    print(f"\nüñ±Ô∏è Current cursor position: {pos}")
    
    # Get system info
    computer = api.get_computer_name()
    user = api.get_user_name()
    print(f"\nüíª System: {computer} (User: {user})")
    
    print("\n‚úÖ Simple Window API is working!")

if __name__ == "__main__":
    quick_test()


==================================================

Path: utils\seraphine.py
File: seraphine.py
Code:
"""
Pipeline V1: Configuration Setup + YOLO/OCR Detection + Merging + Seraphine Grouping + Visualizations
Building the complete pipeline step by step - with intelligent ID tracking and JSON export
Set mode = "debug" for prints and files to work, else deploy_mcp
"""
import os
import sys
import time
import json
import cv2
import numpy as np
from functools import wraps
from PIL import Image
from datetime import datetime
from seraphine_pipeline.yolo_detector import YOLODetector, YOLOConfig
from seraphine_pipeline.ocr_detector import OCRDetector, OCRDetConfig
from seraphine_pipeline.bbox_merger import BBoxMerger
from seraphine_pipeline.beautiful_visualizer import BeautifulVisualizer
from seraphine_pipeline.seraphine_processor import FinalSeraphineProcessor, BBoxProcessor
from seraphine_pipeline.seraphine_generator import FinalGroupImageGenerator
import asyncio
from seraphine_pipeline.gemini_integration import run_gemini_analysis, integrate_gemini_results
from seraphine_pipeline.pipeline_exporter import save_enhanced_pipeline_json, create_enhanced_seraphine_structure
from concurrent.futures import ThreadPoolExecutor
from seraphine_pipeline.parallel_processor import ParallelProcessor
from seraphine_pipeline.helpers import load_configuration, debug_print
from seraphine_pipeline.seraphine_preprocessor import create_group_visualization, analyze_supergroups_with_gemini, integrate_supergroup_analysis
from seraphine_pipeline.splashscreen_handler import handle_splash_screen_if_needed

# Add this right after the imports, before the main() function
class PipelineRestartRequired(Exception):
    """Exception to signal that the entire pipeline needs to restart with a new screenshot"""
    def __init__(self, new_screenshot_path: str, message: str = "Pipeline restart required"):
        self.new_screenshot_path = new_screenshot_path
        super().__init__(message)

def setup_detector_configs(config):
    """Setup YOLO and OCR configurations from config.json"""
    
    # Configure YOLO from config.json
    yolo_config = YOLOConfig(
        model_path=config.get("yolo_model_path", "models/model_dynamic.onnx"),
        conf_threshold=config.get("yolo_conf_threshold", 0.1),
        iou_threshold=config.get("yolo_iou_threshold", 0.1),
        enable_timing=config.get("yolo_enable_timing", True),
        enable_debug=config.get("yolo_enable_debug", False)
    )
    
    # Configure OCR from config.json
    ocr_config = OCRDetConfig(
        model_path=config.get("ocr_model_path", "models/ch_PP-OCRv3_det_infer.onnx"),
        det_threshold=config.get("ocr_det_threshold", 0.3),
        max_side_len=config.get("ocr_max_side_len", 960),
        enable_timing=config.get("ocr_enable_timing", True),
        enable_debug=config.get("ocr_enable_debug", False),
        use_dilation=config.get("ocr_use_dilation", True)
    )
    
    debug_print(f"üéØ YOLO Config: conf={yolo_config.conf_threshold}, iou={yolo_config.iou_threshold}")
    debug_print(f"üìù OCR Config: threshold={ocr_config.det_threshold}, max_len={ocr_config.max_side_len}")
    
    return yolo_config, ocr_config

def load_image_opencv(image_path):
    """Load image using OpenCV (no PIL)"""
    if not os.path.exists(image_path):
        debug_print(f"‚ùå Error: Image file '{image_path}' not found!")
        return None
    
    # Load with OpenCV
    img_bgr = cv2.imread(image_path, cv2.IMREAD_COLOR)
    if img_bgr is None:
        debug_print(f"‚ùå Error: Could not load image '{image_path}'")
        return None
    
    debug_print(f"üì∏ Image loaded: {img_bgr.shape[1]}x{img_bgr.shape[0]} pixels")
    return img_bgr


def assign_intelligent_ids(yolo_detections, ocr_detections):
    """
    Assign clean, simple IDs for tracking throughout pipeline
    YOLO: y_id only (remove redundant 'id')
    OCR: o_id only (remove redundant 'id')
    """
    debug_print("üîñ Assigning simple, clean IDs for pipeline tracking...")
    
    # Assign YOLO IDs - CLEAN VERSION (remove 'id' field)
    for i, detection in enumerate(yolo_detections):
        detection['y_id'] = f"Y{i+1:03d}"
        # Remove redundant 'id' field completely
        if 'id' in detection:
            del detection['id']
    
    # Assign OCR IDs - CLEAN VERSION (remove 'id' field)
    for i, detection in enumerate(ocr_detections):
        detection['o_id'] = f"O{i+1:03d}"
        # Remove redundant 'id' field completely  
        if 'id' in detection:
            del detection['id']
    
    debug_print(f"  ‚úÖ Assigned {len(yolo_detections)} YOLO IDs (Y001-Y{len(yolo_detections):03d})")
    debug_print(f"  ‚úÖ Assigned {len(ocr_detections)} OCR IDs (O001-O{len(ocr_detections):03d})")
    
    return yolo_detections, ocr_detections

def run_parallel_detection_and_merge(img_bgr, yolo_config, ocr_config, config):
    """
    Step 1: Run YOLO + OCR detection + intelligent merging (FIXED - using ParallelProcessor!)
    """
    debug_print("\nüîÑ Step 1: Parallel YOLO + OCR Detection + Intelligent Merging (FIXED)")
    debug_print("=" * 60)
    
    # üéØ FIXED: Use ParallelProcessor properly (like temp_main.py)
    parallel_processor = ParallelProcessor(
        yolo_config=yolo_config,
        ocr_config=ocr_config,
        merger_iou_threshold=config.get("merger_iou_threshold"),
        enable_timing=config.get("yolo_enable_timing", True),
        create_visualizations=False,  # We handle visualizations separately
        save_intermediate_results=False  # We handle JSON separately
    )
    
    # For now, save BGR as temp file for ParallelProcessor 
    # (until ParallelProcessor supports direct PIL/numpy input)
    temp_image_path = "temp_detection_image.jpg"
    cv2.imwrite(temp_image_path, img_bgr)
    
    try:
        detection_start = time.time()
        
        # üéØ Use the PROPER ParallelProcessor with full merging logic!
        results = parallel_processor.process_image(temp_image_path, "temp")
        
        total_detection_time = time.time() - detection_start
        
        # Extract results (ParallelProcessor returns proper structure)
        yolo_detections = results['yolo_detections']
        ocr_detections = results['ocr_detections'] 
        merged_detections = results['merged_detections']
        merge_stats = results['merge_stats']
        
        # Assign intelligent IDs for tracking (same as before)
        yolo_detections, ocr_detections = assign_intelligent_ids(yolo_detections, ocr_detections)
        
        # Update merged detections with proper IDs
        for i, detection in enumerate(merged_detections):
            detection['m_id'] = f"M{i+1:03d}"
        
        debug_print(f"\nüìä FIXED Detection + Merge Results:")
        debug_print(f"  üéØ YOLO detections: {len(yolo_detections)} (Y001-Y{len(yolo_detections):03d})")
        debug_print(f"  üìù OCR detections: {len(ocr_detections)} (O001-O{len(ocr_detections):03d})")
        debug_print(f"  üîó MERGED detections: {len(merged_detections)} (M001-M{len(merged_detections):03d})")
        debug_print(f"  ‚è±Ô∏è  Total time: {total_detection_time:.3f}s")
        debug_print(f"  üéØ PROPER 3-stage merging logic restored!")
        debug_print(f"  üìà Merge efficiency: {len(yolo_detections) + len(ocr_detections)} ‚Üí {len(merged_detections)} ({len(yolo_detections) + len(ocr_detections) - len(merged_detections)} removed)")
        
        return {
            'yolo_detections': yolo_detections,
            'ocr_detections': ocr_detections, 
            'merged_detections': merged_detections,
            'merge_stats': merge_stats,
            'timing': {
                'total_detection_time': total_detection_time,
                'parallel_detection_time': results['timing']['parallel_detection_time'],
                'merge_time': results['timing']['merge_time']
            }
        }
        
    finally:
        # Clean up temporary file
        if os.path.exists(temp_image_path):
            os.remove(temp_image_path)

def run_seraphine_grouping(merged_detections, config, image_path=None):
    """
    Step 2: Run Seraphine intelligent grouping with perfect m_id tracking
    """
    debug_print("üß† Step 2: Running Seraphine Intelligent Grouping")
    debug_print("=" * 60)
    
    # ‚úÖ DEBUG: Check input data
    # import pdb; pdb.set_trace()
    # print(f"[DEBUG] merged_detections count: {len(merged_detections) if merged_detections else 'None'}")
    # print(f"[DEBUG] config: {config}")
    # print(f"[DEBUG] image_path: {image_path}")
    
    if not merged_detections:
        debug_print("‚ö†Ô∏è  No merged detections provided to seraphine")
        return None
    
    seraphine_start = time.time()
    
    # Convert merged detections to seraphine format
    seraphine_detections = convert_merged_to_seraphine_format(merged_detections)
    
    # ‚úÖ DEBUG: Check conversion
    # import pdb; pdb.set_trace()
    print(f"[DEBUG] seraphine_detections count: {len(seraphine_detections) if seraphine_detections else 'None'}")
    
    # Initialize BBoxProcessor
    try:
        bbox_processor = BBoxProcessor()
        print(f"[DEBUG] BBoxProcessor created successfully: {bbox_processor}")
    except Exception as e:
        print(f"[DEBUG ERROR] Failed to create BBoxProcessor: {e}")
        import traceback
        traceback.print_exc()
        return None
    
    # Initialize seraphine processor
    seraphine_processor = FinalSeraphineProcessor(
        enable_timing=config.get("seraphine_enable_timing", True),
        enable_debug=config.get("seraphine_enable_debug", False)
    )
    
    # Process detections into groups
    seraphine_analysis = seraphine_processor.process_detections(seraphine_detections)
    
    # Create enhanced analysis with perfect m_id ‚Üí group tracking
    enhanced_analysis = create_seraphine_id_mapping(seraphine_analysis, merged_detections)
    
    # ‚úÖ SUPERGROUP VISUALIZATION + GEMINI ANALYSIS + INTEGRATION (if image_path provided)
    if image_path and enhanced_analysis and 'bbox_processor' in enhanced_analysis:
        bbox_processor = enhanced_analysis['bbox_processor']  # Extract bbox_processor from enhanced_analysis
        
        if hasattr(bbox_processor, 'final_groups') and bbox_processor.final_groups:
            app_name = os.path.splitext(os.path.basename(image_path))[0]
            visualization_path = create_group_visualization(bbox_processor.final_groups, image_path, 
                                     config.get("output_dir", "outputs"), app_name)
            enhanced_analysis['supergroup_visualization_path'] = visualization_path
            
            # Run Gemini analysis and integrate results into existing structure
            try:
                # Handle event loop correctly
                try:
                    loop = asyncio.get_running_loop()
                    # We're in an existing loop, so schedule the coroutine
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(asyncio.run, analyze_supergroups_with_gemini(visualization_path))
                        supergroup_analysis_text = future.result()
                except RuntimeError:
                    # No event loop, create new one
                    supergroup_analysis_text = asyncio.run(analyze_supergroups_with_gemini(visualization_path))
                
                if supergroup_analysis_text:
                    # ‚úÖ INTEGRATE supergroup analysis
                    enhanced_analysis = integrate_supergroup_analysis(enhanced_analysis, supergroup_analysis_text)
                    print(f"[SERAPHINE] ‚úÖ Supergroup analysis integrated into group_details")
                    
                    # ‚úÖ CHECK FOR SPLASH SCREEN AND HANDLE IT  
                    splash_result = handle_splash_screen_if_needed(enhanced_analysis, image_path, "fdom.json")
                    if splash_result['restart_required']:
                        print(f"üîÑ Splash screen handled, restarting seraphine grouping with: {splash_result['new_screenshot_path']}")
                        
                        # ‚úÖ RECURSIVELY RESTART WITH NEW SCREENSHOT (don't return restart signal)
                        return run_seraphine_grouping(merged_detections, config, splash_result['new_screenshot_path'])
                    
                else:
                    print(f"[SERAPHINE] ‚ö†Ô∏è  No supergroup analysis received")
                    
            except Exception as e:
                print(f"[SERAPHINE ERROR] Supergroup analysis failed: {e}")
                import traceback
                traceback.print_exc()
    
    # ‚úÖ DEBUG POINT: See the integrated results
    # import pdb; pdb.set_trace()
    
    seraphine_time = time.time() - seraphine_start
    
    # FIXED: Access nested analysis values correctly
    analysis = enhanced_analysis['analysis']
    
    # Results summary  
    debug_print(f"\nüìä Seraphine Grouping Results:")
    debug_print(f"  üß† Input: {len(merged_detections)} merged detections (M001-M{len(merged_detections):03d})")
    debug_print(f"  üì¶ Groups created: {analysis['total_groups']}")
    debug_print(f"  üìê Horizontal groups: {analysis['horizontal_groups']}")
    debug_print(f"  üìè Vertical groups: {analysis['vertical_groups']}")
    debug_print(f"  üìè Long box groups: {analysis['long_box_groups']}")
    debug_print(f"  ‚è±Ô∏è  Seraphine time: {seraphine_time:.3f}s")
    debug_print(f"  üîó Perfect m_id tracking: M001 ‚Üí H1_1, M002 ‚Üí H1_2, etc.")
    
    # Add timing info to enhanced analysis
    enhanced_analysis['seraphine_timing'] = seraphine_time
    
    return enhanced_analysis

def convert_merged_to_seraphine_format(merged_detections):
    """
    Convert merged detections to seraphine format with PERFECT m_id preservation
    This is the CRITICAL step where m_id tracking must not break!
    """
    debug_print("üîó Converting merged detections to seraphine format (preserving m_ids)...")
    
    seraphine_detections = []
    
    for detection in merged_detections:
        # CRITICAL: Use m_id as the primary ID for seraphine
        m_id = detection['m_id']  # e.g., "M001"
        
        seraphine_detection = {
            'bbox': detection['bbox'],
            'id': m_id,  # CRITICAL: This will be used by seraphine for group mapping
            'merged_id': m_id,  # Keep reference
            'type': detection.get('type', 'unknown'),
            'source': detection.get('source', 'merged'),
            'confidence': detection.get('confidence', 1.0),
            # Keep original tracking info for reference
            'y_id': detection.get('y_id', 'NA'),
            'o_id': detection.get('o_id', 'NA')
        }
        
        seraphine_detections.append(seraphine_detection)
    
    debug_print(f"  ‚úÖ Converted {len(seraphine_detections)} detections with preserved m_ids")
    return seraphine_detections

def create_seraphine_id_mapping(seraphine_analysis, merged_detections):
    """
    Create enhanced analysis with perfect m_id ‚Üí seraphine group tracking
    """
    debug_print("üó∫Ô∏è  Creating enhanced m_id ‚Üí seraphine group mapping...")
    
    # Get the bbox processor from seraphine analysis  
    bbox_processor = seraphine_analysis['bbox_processor']
    
    # Get the mapping: m_id ‚Üí group_label (e.g., "M001" ‚Üí "H1_1")
    m_id_to_group = bbox_processor.bbox_to_group_mapping
    
    # Create reverse mapping for easy lookup
    group_to_m_ids = {}
    for m_id, group_label in m_id_to_group.items():
        if group_label not in group_to_m_ids:
            group_to_m_ids[group_label] = []
        group_to_m_ids[group_label].append(m_id)
    
    # Enhance the original analysis with tracking info
    enhanced_analysis = seraphine_analysis.copy()
    enhanced_analysis.update({
        'm_id_to_group_mapping': m_id_to_group,  # "M001" ‚Üí "H1_1"
        'group_to_m_ids_mapping': group_to_m_ids,  # "H1_1" ‚Üí ["M001", "M002"]
        'total_m_ids_grouped': len(m_id_to_group),
        'seraphine_timing': seraphine_analysis.get('processing_time', 0)
    })
    
    debug_print(f"  ‚úÖ Enhanced mapping created:")
    debug_print(f"     üì¶ {len(group_to_m_ids)} groups with m_id tracking")
    debug_print(f"     üîó {len(m_id_to_group)} m_ids mapped to groups")
    
    # debug_print sample mappings for verification
    debug_print(f"  üìã Sample m_id ‚Üí group mappings:")
    for i, (m_id, group_label) in enumerate(list(m_id_to_group.items())[:5]):
        debug_print(f"     {m_id} ‚Üí {group_label}")
    if len(m_id_to_group) > 5:
        debug_print(f"     ... and {len(m_id_to_group) - 5} more")
    
    return enhanced_analysis

def create_visualizations(image_path, detection_results, seraphine_analysis, config, gemini_results=None):
    """
    Step 6: Create beautiful visualizations (respecting config settings)
    """
    if not config.get("save_visualizations", False):
        debug_print("\n‚è≠Ô∏è  Visualizations disabled in config (save_visualizations: false)")
        return None
    
    debug_print("\nüé® Step 6: Creating Enhanced Visualizations (with Seraphine Groups)")
    debug_print("=" * 70)
    
    output_dir = config.get("output_dir", "outputs")
    filename_base = os.path.splitext(os.path.basename(image_path))[0]
    
    viz_start = time.time()
    
    # Initialize visualizer with config
    visualizer = BeautifulVisualizer(output_dir=output_dir, config=config)
    
    # Create traditional visualizations (respecting config)
    viz_results = {
        'yolo_detections': detection_results['yolo_detections'],     # Blue boxes
        'ocr_detections': detection_results['ocr_detections'],       # Green boxes
        'merged_detections': detection_results['merged_detections']  # Purple boxes (intelligently merged)
    }
    
    # Create traditional visualizations using existing method
    visualization_paths = visualizer.create_all_visualizations(
        image_path=image_path,
        results=viz_results,
        filename_base=f"v1_{filename_base}"
    )
    
    # Create seraphine group visualization using existing method
    if seraphine_analysis and config.get("save_seraphine_viz", True):
        seraphine_path = visualizer.create_seraphine_group_visualization(
            image_path=image_path,
            seraphine_analysis=seraphine_analysis,
            filename_base=f"v1_{filename_base}"
        )
        if seraphine_path:
            visualization_paths['seraphine_groups'] = seraphine_path
    
    # üÜï Create Gemini visualization using correct format
    if gemini_results and config.get("save_gemini_visualization", True):
        debug_print("üé® Creating Gemini analysis visualization...")
        try:
            from PIL import Image as PILImage
            original_image = PILImage.open(image_path)
            
            # Use the EXACT gemini_results format - the visualizer expects this!
            gemini_viz_path = visualizer._create_gemini_visualization(
                image=original_image,
                gemini_analysis=gemini_results,  # Pass the full results object!
                seraphine_analysis=seraphine_analysis,
                filename_base=f"v1_{filename_base}"
            )
            
            if gemini_viz_path:
                visualization_paths['gemini_analysis'] = gemini_viz_path
                debug_print(f"‚úÖ Gemini visualization created: {os.path.basename(gemini_viz_path)}")
        except Exception as e:
            debug_print(f"‚ö†Ô∏è  Failed to create Gemini visualization: {e}")
            import traceback
            traceback.print_exc()
    
    viz_time = time.time() - viz_start
    
    debug_print(f"‚úÖ Enhanced visualizations created in {viz_time:.3f}s:")
    for viz_type, path in visualization_paths.items():
        if isinstance(path, str):
            debug_print(f"   üì∑ {viz_type.upper()}: {os.path.basename(path)}")
        else:
            debug_print(f"   üì∑ {viz_type.upper()}: {len(path)} files")
    
    return visualization_paths

def display_enhanced_pipeline_summary(image_path, detection_results, seraphine_analysis, gemini_results, visualization_paths, json_path, config):
    """Display enhanced pipeline summary with seraphine integration"""
    merge_stats = detection_results['merge_stats']
    
    # FIXED: Access nested analysis values correctly
    analysis = seraphine_analysis['analysis']
    
    debug_print(f"\nüìä ENHANCED PIPELINE V1.2 SUMMARY (with Seraphine and Gemini):")
    debug_print("=" * 65)
    debug_print(f"  üì∏ Image: {os.path.basename(image_path)}")
    debug_print(f"  üéØ YOLO detections: {len(detection_results['yolo_detections'])} (Y001-Y{len(detection_results['yolo_detections']):03d})")
    debug_print(f"  üìù OCR detections: {len(detection_results['ocr_detections'])} (O001-O{len(detection_results['ocr_detections']):03d})")
    debug_print(f"  üîó MERGED detections: {len(detection_results['merged_detections'])} (M001-M{len(detection_results['merged_detections']):03d})")
    debug_print(f"  üß† SERAPHINE groups: {analysis['total_groups']} intelligent groups")
    debug_print(f"     üìê Horizontal: {analysis['horizontal_groups']}")
    debug_print(f"     üìè Vertical: {analysis['vertical_groups']}")
    debug_print(f"     üìè Long boxes: {analysis['long_box_groups']}")
    
    # Handle None gemini_results properly
    gemini_time = gemini_results.get('analysis_duration_seconds', 0) if gemini_results else 0
    total_time = detection_results['timing']['total_detection_time'] + seraphine_analysis.get('seraphine_timing', 0) + gemini_time
    
    debug_print(f"  ‚è±Ô∏è  Total pipeline time: {total_time:.3f}s")
    debug_print(f"     Detection + merge: {detection_results['timing']['total_detection_time']:.3f}s")
    debug_print(f"     Seraphine grouping: {seraphine_analysis.get('seraphine_timing', 0):.3f}s")
    debug_print(f"     Gemini analysis: {gemini_time:.3f}s")
    
    # Show Gemini status
    if gemini_results:
        debug_print(f"  ü§ñ GEMINI analysis: ‚úÖ {gemini_results.get('successful_analyses', 0)}/{gemini_results.get('total_images_analyzed', 0)} images analyzed")
        debug_print(f"     üéØ Total icons found: {gemini_results.get('total_icons_found', 0)}")
    else:
        debug_print(f"  ü§ñ GEMINI analysis: ‚è≠Ô∏è Disabled or failed")
    
    if json_path:
        debug_print(f"  üíæ Enhanced JSON: {os.path.basename(json_path)}")
        debug_print(f"     - Complete pipeline with seraphine group tracking and Gemini analysis")
        debug_print(f"     - Perfect m_id ‚Üí seraphine_group mapping")
        debug_print(f"     - {seraphine_analysis['total_m_ids_grouped']} m_ids tracked through {analysis['total_groups']} groups")
    
    if visualization_paths:
        debug_print(f"  üé® Visualizations: {len(visualization_paths)} types created")
        debug_print(f"     - Traditional: YOLO, OCR, MERGED overlays")
        if 'seraphine_groups' in visualization_paths:
            seraphine_count = len(visualization_paths['seraphine_groups']) if isinstance(visualization_paths['seraphine_groups'], list) else 1
            debug_print(f"     - Seraphine: {seraphine_count} intelligent group images")
        debug_print(f"  üìÅ Output directory: {config.get('output_dir', 'outputs')}/")

    debug_print(f"üîó Perfect ID Traceability: Y/O IDs ‚Üí M IDs ‚Üí Seraphine Groups ‚Üí Gemini Analysis")

async def main(image_path=None):
    """Main enhanced pipeline execution - MODE AWARE"""
    pipeline_start = time.time()
    
    config = load_configuration()
    if not config:
        return None
    
    mode = config.get("mode", "debug")
    
    # Force disable ALL debug output in deploy mode
    if mode == "deploy_mcp":
        config.update({
            "yolo_enable_debug": False,
            "yolo_enable_timing": False,
            "ocr_enable_debug": False,
            "ocr_enable_timing": False,
            "seraphine_enable_debug": False,
            "seraphine_timing": False,
            "save_visualizations": False,
            "save_json": False,
            "save_gemini_visualization": False,
            "save_gemini_json": False,
        })
    
    debug_print("üöÄ ENHANCED AI PIPELINE V1.2: Detection + Merging + Seraphine + Gemini + Export")
    debug_print("=" * 90)
    
    yolo_config, ocr_config = setup_detector_configs(config)
    
    # Use provided image_path or default from config or fallback
    if image_path is None:
        image_path = config.get("default_image_path", "images/notepad.png")
    
    img_bgr = load_image_opencv(image_path)
    if img_bgr is None:
        return None
    
    debug_print(f"üì∏ Image loaded: {img_bgr.shape[1]}x{img_bgr.shape[0]} pixels")
    
    # ‚úÖ PIPELINE RESTART HANDLING
    max_restarts = 2
    restart_count = 0
    
    while restart_count < max_restarts:
        # Reset pipeline start time for each attempt
        pipeline_start = time.time()
        
        try:
            # Step 1: Detection + Merging
            detection_results = run_parallel_detection_and_merge(img_bgr, yolo_config, ocr_config, config)
            
            # Step 2: Seraphine Grouping (may raise PipelineRestartRequired)
            seraphine_analysis = run_seraphine_grouping(detection_results['merged_detections'], config, image_path)
            
            # Continue with normal pipeline
            # Step 3: Generate Grouped Images for Gemini Analysis
            debug_print("\nüé® Step 3: Generate Grouped Images for Gemini Analysis")
            grouped_image_paths = None
            if config.get("generate_grouped_images", True):
                debug_print("\nüñºÔ∏è  Step 3: Generating Seraphine Grouped Images")
                
                from seraphine_pipeline.seraphine_generator import FinalGroupImageGenerator
                
                output_dir = config.get("output_dir", "outputs")
                filename_base = os.path.splitext(os.path.basename(image_path))[0]
                
                final_group_generator = FinalGroupImageGenerator(
                    output_dir=output_dir,
                    save_mapping=False
                )
                
                grouped_image_paths = final_group_generator.create_grouped_images(
                    image_path, 
                    seraphine_analysis, 
                    filename_base
                )
                
                debug_print(f"‚úÖ Generated {len(grouped_image_paths)} grouped images")
            
            # Step 4: Gemini Analysis
            gemini_results = None
            if config.get("gemini_enabled", False):
                try:
                    gemini_results = await run_gemini_analysis(
                        seraphine_analysis, grouped_image_paths, image_path, config
                    )
                    
                    if gemini_results:
                        # Store original merged detections for proper ID lookup
                        seraphine_analysis['original_merged_detections'] = detection_results['merged_detections']
                        seraphine_analysis = integrate_gemini_results(seraphine_analysis, gemini_results)
                        
                except Exception as e:
                    debug_print(f"‚ö†Ô∏è  Gemini analysis failed: {str(e)}")
            
            # Calculate total time BEFORE mode check
            total_time = time.time() - pipeline_start
            
            # Get icon count BEFORE mode check
            icon_count = gemini_results.get('total_icons_found', 0) if gemini_results else 0
            
            # MODE-SPECIFIC OUTPUTS
            if mode == "deploy_mcp":
                # üéØ DEPLOY MODE: Clean, emoji-free output
                print(f"Pipeline completed in {total_time:.3f}s, found {icon_count} icons.")
                
                # üßπ COMPLETE FILE CLEANUP
                output_dir = config.get("output_dir", "outputs")
                if os.path.exists(output_dir):
                    import shutil
                    shutil.rmtree(output_dir)
                    os.makedirs(output_dir, exist_ok=True)
                
                # Return only essential data
                field_name = 'seraphine_gemini_groups' if gemini_results else 'seraphine_groups'
                result = {
                    'total_time': total_time,
                    'total_icons_found': icon_count,
                }
                
                # ‚úÖ FIX: Get the actual element groups with proper bbox data
                if gemini_results and 'seraphine_gemini_groups' in seraphine_analysis:
                    result[field_name] = seraphine_analysis['seraphine_gemini_groups']
                else:
                    # Create the enhanced structure from bbox_processor if it doesn't exist
                    from utils.seraphine_pipeline.pipeline_exporter import create_enhanced_seraphine_structure
                    
                    # Get original merged detections for proper ID mapping
                    merged_detections = seraphine_analysis.get('original_merged_detections', [])
                    if not merged_detections:
                        merged_detections = detection_results.get('merged_detections', [])
                    
                    enhanced_groups = create_enhanced_seraphine_structure(seraphine_analysis, merged_detections)
                    result[field_name] = enhanced_groups
                
                return result
            
            else:  # DEBUG MODE - Full verbose output with emojis
                # Step 5: Save JSON
                json_path = save_enhanced_pipeline_json(image_path, detection_results, seraphine_analysis, gemini_results, config)
                
                # Step 6: Create Visualizations
                visualization_paths = create_visualizations(image_path, detection_results, seraphine_analysis, config, gemini_results)
                
                # Summary
                display_enhanced_pipeline_summary(image_path, detection_results, seraphine_analysis, gemini_results, visualization_paths, json_path, config)
                
                return {
                    'detection_results': detection_results,
                    'seraphine_analysis': seraphine_analysis,
                    'gemini_results': gemini_results,
                    'grouped_image_paths': grouped_image_paths,
                    'visualization_paths': visualization_paths,
                    'json_path': json_path,
                    'config': config,
                    'total_time': total_time
                }
            
            # If we get here, pipeline completed successfully
            break  # Exit the retry loop
            
        except PipelineRestartRequired as restart_exception:
            restart_count += 1
            new_screenshot_path = restart_exception.new_screenshot_path
            
            print(f"üîÑ Pipeline restart #{restart_count}: {restart_exception}")
            print(f"üì∏ Using new screenshot: {new_screenshot_path}")
            
            if restart_count >= max_restarts:
                print(f"‚ö†Ô∏è Maximum restarts ({max_restarts}) reached, continuing with last screenshot")
                break
            
            # Update paths and reload image for restart
            image_path = new_screenshot_path
            img_bgr = load_image_opencv(image_path)
            if img_bgr is None:
                print(f"‚ùå Could not load new screenshot: {image_path}")
                break
            
            print(f"‚úÖ Reloaded image: {img_bgr.shape[1]}x{img_bgr.shape[0]} pixels")
            # Continue the while loop to restart the pipeline
            
        except Exception as e:
            # Calculate time even on error
            total_time = time.time() - pipeline_start
            
            if mode == "deploy_mcp":
                # Clean error message without emojis
                print(f"Pipeline failed after {total_time:.3f}s: {str(e)}")
            else:
                debug_print(f"‚ùå Error during pipeline execution: {str(e)}")
                import traceback
                traceback.print_exc()
            
            return None
    
    # If max restarts reached without success, return None
    return None

# Add a convenience function for easy module usage
async def process_image(image_path, config_path=None):
    """
    Convenience function for processing a single image
    
    Args:
        image_path (str): Path to the image to process
        config_path (str, optional): Path to config file. Uses default if None.
    
    Returns:
        dict: Processing results or None if failed
    """
    if config_path:
        # Temporarily update config path (you might need to modify load_configuration)
        # For now, assume load_configuration() uses a default path
        pass
    
    return await main(image_path)

def process_image_sync(image_path, config_path=None):
    """Synchronous wrapper with built-in restart handling"""
    max_attempts = 2
    attempt = 0
    
    while attempt < max_attempts:
        attempt += 1
        try:
            return asyncio.run(process_image(image_path, config_path))
        except Exception as e:
            if "PipelineRestartRequired" in str(e) and attempt < max_attempts:
                print(f"üîÑ Splash screen handled, retrying analysis...")
                continue
            else:
                raise e
    
    return None

if __name__ == "__main__":
    import argparse
    
    # Parse command line arguments
    parser = argparse.ArgumentParser(description="Seraphine AI Pipeline - Enhanced Detection & Analysis")
    parser.add_argument("--image", "-i", type=str, help="Path to input image")
    parser.add_argument("--config", "-c", type=str, help="Path to config file")
    args = parser.parse_args()
    
    try:
        if args.image:
            results = asyncio.run(main(args.image))
        else:
            # Use default image if no argument provided
            results = asyncio.run(main())

        # Remove debug breakpoint for production use
        # import pdb; pdb.set_trace()
        print("Processing completed")
    except Exception as e:
        print(f"Critical startup error: {e}")

# Usage Example
# # In another file
# from utils.seraphine import process_image_sync, process_image
# import asyncio

# # Synchronous usage
# results = process_image_sync("path/to/your/image.jpg")

# # Async usage
# results = await process_image("path/to/your/image.jpg")


# # With specific image
# python utils/seraphine.py --image "path/to/image.jpg"

# # With default image
# python utils/seraphine.py

# # With config file
# python utils/seraphine.py --image "image.jpg" --config "custom_config.json"

==================================================

Path: utils\seraphine_pipeline\__init__.py
File: __init__.py
Code:


==================================================

Path: utils\seraphine_pipeline\bbox_merger.py
File: bbox_merger.py
Code:
"""
Intelligent bounding box merger utility
Implements overlap rules for YOLO and OCR detection results.
No imports from original files allowed.
"""
import numpy as np
from typing import List, Dict, Any, Tuple
from .helpers import debug_print

def calculate_iou(box1: List[int], box2: List[int]) -> float:
    """Calculate IoU between two boxes in [x1, y1, x2, y2] format"""
    x1_1, y1_1, x2_1, y2_1 = box1
    x1_2, y1_2, x2_2, y2_2 = box2
    
    # Calculate intersection
    x1_i = max(x1_1, x1_2)
    y1_i = max(y1_1, y1_2)
    x2_i = min(x2_1, x2_2)
    y2_i = min(y2_1, y2_2)
    
    if x2_i <= x1_i or y2_i <= y1_i:
        return 0.0
    
    intersection = (x2_i - x1_i) * (y2_i - y1_i)
    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
    union = area1 + area2 - intersection
    
    return intersection / union if union > 0 else 0.0

def is_box_inside(inner_box: List[int], outer_box: List[int], threshold: float = 0.8) -> bool:
    """Check if inner_box is inside outer_box with given threshold"""
    x1_i, y1_i, x2_i, y2_i = inner_box
    x1_o, y1_o, x2_o, y2_o = outer_box
    
    # Calculate intersection
    x1_int = max(x1_i, x1_o)
    y1_int = max(y1_i, y1_o)
    x2_int = min(x2_i, x2_o)
    y2_int = min(y2_i, y2_o)
    
    if x2_int <= x1_int or y2_int <= y1_int:
        return False
    
    intersection = (x2_int - x1_int) * (y2_int - y1_int)
    inner_area = (x2_i - x1_i) * (y2_i - y1_i)
    
    # Check if most of the inner box is contained in outer box
    return (intersection / inner_area) >= threshold if inner_area > 0 else False

def calculate_box_area(box: List[int]) -> float:
    """Calculate the area of a bounding box in [x1, y1, x2, y2] format"""
    x1, y1, x2, y2 = box
    width = x2 - x1
    height = y2 - y1
    
    # Return 0 for invalid boxes
    if width <= 0 or height <= 0:
        return 0.0
    
    return width * height

def filter_valid_boxes(detections: List[Dict[str, Any]], min_area: float = 1.0) -> List[Dict[str, Any]]:
    """
    Filter out boxes with zero or very small areas
    
    Args:
        detections: List of detection dictionaries with 'bbox' key
        min_area: Minimum area threshold (default: 1.0 pixel)
        
    Returns:
        List of valid detections with area > min_area
    """
    valid_detections = []
    
    for detection in detections:
        bbox = detection['bbox']
        area = calculate_box_area(bbox)
        
        if area > min_area:
            valid_detections.append(detection)
    
    return valid_detections

class BBoxMerger:
    """
    Intelligent bounding box merger that combines YOLO and OCR detections
    according to specified overlap rules.
    """
    
    def __init__(self, iou_threshold: float = 0.9, containment_threshold: float = 0.8, 
                 min_area: float = 1.0, enable_timing: bool = True):
        """
        Initialize merger with thresholds
        
        Args:
            iou_threshold: IoU threshold for considering boxes as overlapping (default: 0.9, matching OmniParser)
            containment_threshold: Threshold for considering one box inside another
            min_area: Minimum box area in pixels (default: 1.0)
            enable_timing: Whether to print timing information
        """
        self.iou_threshold = iou_threshold
        self.containment_threshold = containment_threshold
        self.min_area = min_area
        self.enable_timing = enable_timing
    
    def _remove_yolo_self_overlaps(self, yolo_detections: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Stage 1: Remove overlapping YOLO boxes among themselves
        Keep the smaller box when there's significant overlap (following OmniParser logic)
        
        Args:
            yolo_detections: List of YOLO detection dictionaries
            
        Returns:
            List of non-overlapping YOLO detections
        """
        if self.enable_timing:
            debug_print(f"  üîÑ Stage 1: Removing YOLO self-overlaps...")
        
        filtered_yolo = []
        
        for i, yolo1 in enumerate(yolo_detections):
            bbox1 = yolo1['bbox']
            area1 = calculate_box_area(bbox1)
            is_valid_box = True
            
            # Check against all other YOLO boxes
            for j, yolo2 in enumerate(yolo_detections):
                if i == j:
                    continue
                    
                bbox2 = yolo2['bbox']
                area2 = calculate_box_area(bbox2)
                
                iou = calculate_iou(bbox1, bbox2)
                
                # If significant overlap and current box is larger, discard it (keep smaller box)
                if iou > self.iou_threshold and area1 > area2:
                    is_valid_box = False
                    if self.enable_timing:
                        debug_print(f"    üóëÔ∏è Discarding larger YOLO box (area: {area1:.1f}) in favor of smaller (area: {area2:.1f}), IoU: {iou:.3f}")
                    break
            
            if is_valid_box:
                filtered_yolo.append(yolo1)
        
        if self.enable_timing:
            debug_print(f"    ‚úÖ YOLO self-overlap removal: {len(yolo_detections)} -> {len(filtered_yolo)} boxes")
        
        return filtered_yolo
    
    def _filter_yolo_with_many_ocr(self, yolo_detections: List[Dict[str, Any]], 
                                   ocr_detections: List[Dict[str, Any]], 
                                   max_ocr_inside: int = 2) -> List[Dict[str, Any]]:
        """
        Stage 1.5: Filter out YOLO boxes containing more than max_ocr_inside OCR boxes
        This prevents false positive YOLO detections that encompass large text regions
        
        Args:
            yolo_detections: YOLO detections after self-overlap removal
            ocr_detections: OCR detections
            max_ocr_inside: Maximum number of OCR boxes allowed inside a YOLO box (default: 2)
            
        Returns:
            Filtered YOLO detections
        """
        if self.enable_timing:
            debug_print(f"  üîÑ Stage 1.5: Filtering YOLO boxes with >{max_ocr_inside} OCR inside...")
        
        filtered_yolo = []
        
        for yolo_det in yolo_detections:
            yolo_bbox = yolo_det['bbox']
            ocr_inside_count = 0
            
            # Count how many OCR boxes are inside this YOLO box
            for ocr_det in ocr_detections:
                ocr_bbox = ocr_det['bbox']
                
                # Check if OCR box is inside YOLO box
                if is_box_inside(ocr_bbox, yolo_bbox, self.containment_threshold):
                    ocr_inside_count += 1
                    
                    # Early exit if we exceed the threshold
                    if ocr_inside_count > max_ocr_inside:
                        break
            
            if ocr_inside_count <= max_ocr_inside:
                filtered_yolo.append(yolo_det)
                if self.enable_timing and ocr_inside_count > 0:
                    debug_print(f"    ‚úÖ Keeping YOLO box with {ocr_inside_count} OCR inside")
            else:
                if self.enable_timing:
                    debug_print(f"    üóëÔ∏è Discarding YOLO box with {ocr_inside_count} OCR inside (>{max_ocr_inside})")
        
        if self.enable_timing:
            removed_count = len(yolo_detections) - len(filtered_yolo)
            debug_print(f"    ‚úÖ YOLO OCR-density filter: {len(yolo_detections)} -> {len(filtered_yolo)} boxes ({removed_count} removed)")
        
        return filtered_yolo
    
    def _merge_yolo_ocr_relationships(self, yolo_detections: List[Dict[str, Any]], 
                                    ocr_detections: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Stage 2: Handle YOLO-OCR relationships
        Apply containment rules and content aggregation
        
        Args:
            yolo_detections: Filtered YOLO detections from stage 1
            ocr_detections: OCR detections
            
        Returns:
            Final merged detections
        """
        if self.enable_timing:
            debug_print(f"  üîÑ Stage 2: Merging YOLO-OCR relationships...")
        
        merged_detections = []
        ocr_used = [False] * len(ocr_detections)
        
        # Process each YOLO box
        for yolo_det in yolo_detections:
            yolo_bbox = yolo_det['bbox']
            box_added = False
            
            # Check relationships with all OCR boxes
            for j, ocr_det in enumerate(ocr_detections):
                if ocr_used[j]:
                    continue
                    
                ocr_bbox = ocr_det['bbox']
                iou = calculate_iou(yolo_bbox, ocr_bbox)
                
                if iou > self.iou_threshold:
                    # Check containment relationships
                    yolo_inside_ocr = is_box_inside(yolo_bbox, ocr_bbox, self.containment_threshold)
                    ocr_inside_yolo = is_box_inside(ocr_bbox, yolo_bbox, self.containment_threshold)
                    
                    if yolo_inside_ocr:
                        # YOLO inside OCR -> Keep OCR, discard YOLO
                        if not box_added:  # Only add once
                            merged_detections.append(ocr_det.copy())
                            box_added = True
                            if self.enable_timing:
                                debug_print(f"    üîÑ YOLO inside OCR -> Keeping OCR (IoU: {iou:.3f})")
                        ocr_used[j] = True
                        break  # YOLO can only be inside one OCR box
                        
                    elif ocr_inside_yolo:
                        # OCR inside YOLO -> Keep YOLO, mark OCR as used
                        yolo_det['type'] = 'text'  # ‚Üê ONLY CHANGE: Set type to text
                        # Note: We'll add the YOLO box after checking all OCR boxes
                        ocr_used[j] = True
                        if self.enable_timing:
                            debug_print(f"    üîÑ OCR inside YOLO -> Will keep YOLO as TEXT (IoU: {iou:.3f})")
            
            # If YOLO wasn't absorbed into an OCR box, add it
            if not box_added:
                merged_detections.append(yolo_det.copy())
        
        # Add remaining unused OCR detections
        for j, ocr_det in enumerate(ocr_detections):
            if not ocr_used[j]:
                merged_detections.append(ocr_det.copy())
        
        if self.enable_timing:
            debug_print(f"    ‚úÖ YOLO-OCR relationship merge: {len(yolo_detections)} YOLO + {len(ocr_detections)} OCR -> {len(merged_detections)} final")
        
        return merged_detections
    
    def merge_detections(self, yolo_detections: List[Dict[str, Any]], 
                        ocr_detections: List[Dict[str, Any]]) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        """
        Merge YOLO and OCR detections using enhanced three-stage processing:
        Stage 1: Remove YOLO self-overlaps (keep smaller boxes)
        Stage 1.5: Filter YOLO boxes containing too many OCR boxes
        Stage 2: Handle YOLO-OCR relationships with containment rules
        
        Args:
            yolo_detections: List of YOLO detection dictionaries
            ocr_detections: List of OCR detection dictionaries
            
        Returns:
            Tuple of (merged_detections, merge_stats)
        """
        import time
        start_time = time.time()
        
        # Pre-filtering: Remove zero-area boxes
        original_yolo_count = len(yolo_detections)
        original_ocr_count = len(ocr_detections)
        
        yolo_detections = filter_valid_boxes(yolo_detections, self.min_area)
        ocr_detections = filter_valid_boxes(ocr_detections, self.min_area)
        
        filtered_yolo_count = len(yolo_detections)
        filtered_ocr_count = len(ocr_detections)
        
        if self.enable_timing:
            debug_print(f"\nüîó Starting enhanced three-stage bbox merging...")
            debug_print(f"  üìè Pre-filtering (zero-area removal):")
            debug_print(f"    YOLO: {original_yolo_count} -> {filtered_yolo_count} ({original_yolo_count - filtered_yolo_count} removed)")
            debug_print(f"    OCR: {original_ocr_count} -> {filtered_ocr_count} ({original_ocr_count - filtered_ocr_count} removed)")
            debug_print(f"  ‚öôÔ∏è Thresholds: IoU={self.iou_threshold}, Containment={self.containment_threshold}, MinArea={self.min_area}")
        
        # üîß STAGE 1: Remove YOLO self-overlaps
        stage1_start = time.time()
        yolo_after_stage1 = self._remove_yolo_self_overlaps(yolo_detections)
        stage1_time = time.time() - stage1_start
        
        # üîß STAGE 1.5: Filter YOLO boxes with too many OCR inside (NEW!)
        stage1_5_start = time.time()
        yolo_after_stage1_5 = self._filter_yolo_with_many_ocr(yolo_after_stage1, ocr_detections, max_ocr_inside=2)
        stage1_5_time = time.time() - stage1_5_start
        
        # üîß STAGE 2: Handle YOLO-OCR relationships  
        stage2_start = time.time()
        final_detections = self._merge_yolo_ocr_relationships(yolo_after_stage1_5, ocr_detections)
        stage2_time = time.time() - stage2_start
        
        # Reassign IDs to final detections
        for i, det in enumerate(final_detections):
            det['merged_id'] = i
        
        # Compile comprehensive statistics
        merge_stats = {
            'total_input': original_yolo_count + original_ocr_count,
            'total_filtered_input': filtered_yolo_count + filtered_ocr_count,
            'total_output': len(final_detections),
            'yolo_input': original_yolo_count,
            'yolo_filtered_input': filtered_yolo_count,
            'yolo_after_stage1': len(yolo_after_stage1),
            'yolo_after_stage1_5': len(yolo_after_stage1_5),
            'ocr_input': original_ocr_count,
            'ocr_filtered_input': filtered_ocr_count,
            'zero_area_removed': (original_yolo_count - filtered_yolo_count) + (original_ocr_count - filtered_ocr_count),
            'yolo_self_overlaps_removed': filtered_yolo_count - len(yolo_after_stage1),
            'yolo_ocr_density_removed': len(yolo_after_stage1) - len(yolo_after_stage1_5),
            'stage1_time': stage1_time,
            'stage1_5_time': stage1_5_time,
            'stage2_time': stage2_time,
            'total_merge_time': time.time() - start_time
        }
        
        if self.enable_timing:
            debug_print(f"\nüéØ Enhanced three-stage merge completed in {merge_stats['total_merge_time']:.3f}s")
            debug_print(f"  üìä Processing pipeline:")
            debug_print(f"    Input: {merge_stats['total_input']} boxes")
            debug_print(f"    After area filtering: {merge_stats['total_filtered_input']} boxes")
            debug_print(f"    After Stage 1 (YOLO self-overlap): {merge_stats['yolo_after_stage1']} YOLO + {merge_stats['ocr_filtered_input']} OCR")
            debug_print(f"    After Stage 1.5 (YOLO OCR-density filter): {merge_stats['yolo_after_stage1_5']} YOLO + {merge_stats['ocr_filtered_input']} OCR")
            debug_print(f"    Final output: {merge_stats['total_output']} boxes")
            debug_print(f"  ‚è±Ô∏è Timing: Stage1={stage1_time:.3f}s, Stage1.5={stage1_5_time:.3f}s, Stage2={stage2_time:.3f}s")
            debug_print(f"  üóëÔ∏è Removed: {merge_stats['zero_area_removed']} zero-area, {merge_stats['yolo_self_overlaps_removed']} YOLO self-overlaps, {merge_stats['yolo_ocr_density_removed']} YOLO with >2 OCR")
        
        return final_detections, merge_stats

==================================================

Path: utils\seraphine_pipeline\beautiful_visualizer.py
File: beautiful_visualizer.py
Code:
"""
Beautiful visualization utility inspired by omni_utils.py
Creates stunning bounding box visualizations for all pipeline results
"""

import os
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from datetime import datetime
from typing import List, Dict, Any, Tuple, Optional
from .helpers import debug_print


class BeautifulVisualizer:
    """
    Creates beautiful visualizations for detection pipeline results
    Inspired by omni_utils.py with enhanced styling and Seraphine integration
    """
    
    def __init__(self, output_dir: str = "outputs", config: Dict = None):
        self.output_dir = output_dir
        self.config = config or {}
        os.makedirs(output_dir, exist_ok=True)
        
        # Color schemes
        self.colors = {
            'yolo': (63, 81, 181),      # Blue - YOLO detections
            'ocr': (46, 125, 50),       # Green - OCR detections  
            'merged': (156, 39, 176),   # Purple - Merged results
            'complete': (255, 152, 0),  # Orange - Complete results
            'grouped': (244, 67, 54),   # Red - Grouped items
            'ungrouped': (96, 125, 139) # Gray - Ungrouped items
        }
        
        # Group colors for Seraphine visualization (from seraphine_check.py)
        self.seraphine_colors = [
            (255, 0, 0),    # Red
            (0, 255, 0),    # Green
            (0, 0, 255),    # Blue
            (255, 255, 0),  # Yellow
            (255, 0, 255),  # Magenta
            (0, 255, 255),  # Cyan
            (255, 165, 0),  # Orange
            (128, 0, 128),  # Purple
            (255, 192, 203), # Pink
            (0, 128, 0),    # Dark Green
            (128, 128, 0),  # Olive
            (0, 0, 128),    # Navy
            (128, 0, 0),    # Maroon
            (0, 128, 128),  # Teal
            (192, 192, 192), # Silver
            (255, 20, 147), # Deep Pink
            (50, 205, 50),  # Lime Green
            (255, 140, 0),  # Dark Orange
            (138, 43, 226), # Blue Violet
            (220, 20, 60),  # Crimson
        ]
    
    def create_all_visualizations(self, image_path: str, results: Dict[str, Any], 
                                filename_base: str = None) -> Dict[str, str]:
        """
        Create all visualizations based on config settings
        
        Args:
            image_path: Path to original image
            results: Dictionary containing all detection results
            filename_base: Base filename (auto-detected if None)
            
        Returns:
            Dictionary mapping visualization type to saved file path
        """
        # Check if visualizations are enabled in config
        if not self.config.get("save_visualizations", True):
            debug_print("‚è≠Ô∏è  Visualizations disabled in config (save_visualizations: false)")
            return {}
        
        debug_print(f"üé® Creating beautiful visualizations...")
        
        # Load image
        image = Image.open(image_path).convert('RGB')
        
        # Auto-detect filename if not provided
        if filename_base is None:
            filename_base = os.path.splitext(os.path.basename(image_path))[0]
        
        visualization_paths = {}
        
        # 1. YOLO Results Visualization
        if 'yolo_detections' in results and self.config.get("save_yolo_viz", True):
            yolo_path = self._create_detection_visualization(
                image, results['yolo_detections'], 'yolo', filename_base
            )
            visualization_paths['yolo'] = yolo_path
        
        # 2. OCR Detection Results Visualization  
        if 'ocr_detections' in results and self.config.get("save_ocr_viz", True):
            ocr_path = self._create_detection_visualization(
                image, results['ocr_detections'], 'ocr', filename_base
            )
            visualization_paths['ocr'] = ocr_path
        
        # 3. Merged Results Visualization
        if 'merged_detections' in results and self.config.get("save_merged_viz", True):
            merged_path = self._create_detection_visualization(
                image, results['merged_detections'], 'merged', filename_base
            )
            visualization_paths['merged'] = merged_path
        
        # 4. Complete Results Visualization (final summary - all detections)
        if self.config.get("save_complete_viz", True):
            complete_detections = []
            if 'yolo_detections' in results:
                complete_detections.extend(results['yolo_detections'])
            if 'ocr_detections' in results:
                complete_detections.extend(results['ocr_detections'])
            
            if complete_detections:
                complete_path = self._create_detection_visualization(
                    image, complete_detections, 'complete', filename_base
                )
                visualization_paths['complete'] = complete_path
        
        debug_print(f"‚úÖ Created {len(visualization_paths)} beautiful visualizations")
        return visualization_paths
    
    def create_seraphine_group_visualization(self, image_path: str, seraphine_analysis: Dict, 
                                           filename_base: str = None) -> Optional[str]:
        """
        Create CLEAN seraphine group visualization (same style as YOLO/OCR visualizations)
        """
        # Check if seraphine visualization is enabled in config
        if not self.config.get("save_seraphine_viz", True):
            debug_print("‚è≠Ô∏è  Seraphine visualization disabled in config")
            return None
        
        if not seraphine_analysis:
            debug_print("‚ö†Ô∏è  No seraphine analysis provided")
            return None
        
        debug_print("üß† Creating Seraphine group visualization...")
        
        # Load image
        image = Image.open(image_path).convert('RGB')
        
        # Auto-detect filename if not provided
        if filename_base is None:
            filename_base = os.path.splitext(os.path.basename(image_path))[0]
        
        current_time = datetime.now().strftime("%H-%M")
        output_filename = f"{filename_base}_seraphine_groups_{current_time}.jpg"
        output_path = os.path.join(self.output_dir, output_filename)
        
        # Convert PIL to OpenCV for drawing
        img_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        h, w = img_cv.shape[:2]
        
        # Get the bbox processor from seraphine analysis
        bbox_processor = seraphine_analysis.get('bbox_processor')
        if not bbox_processor:
            debug_print("‚ùå No bbox_processor found in seraphine analysis")
            return None
        
        # USE SAME CLEAN STYLE AS YOLO/OCR VISUALIZATIONS
        font = cv2.FONT_HERSHEY_DUPLEX
        text_scale = 0.35          # Same as other visualizations
        thickness = 1              # THIN borders like YOLO (not 3!)
        text_thickness = 1
        text_padding = 2
        
        color_idx = 0
        
        # Draw each group with CLEAN styling
        for group_id, boxes in bbox_processor.final_groups.items():
            # Get color for this group
            color_rgb = self.seraphine_colors[color_idx % len(self.seraphine_colors)]
            color_bgr = (color_rgb[2], color_rgb[1], color_rgb[0])  # RGB to BGR
            color_idx += 1
            
            # Draw all boxes in this group with THIN borders
            for i, bbox in enumerate(boxes):
                x1, y1, x2, y2 = bbox.x1, bbox.y1, bbox.x2, bbox.y2
                
                # Draw THIN bounding box (same as YOLO style)
                cv2.rectangle(img_cv, (x1, y1), (x2, y2), color_bgr, thickness)
                
                # Create clean label (same format as other visualizations)
                label = f"{group_id}_{i+1}"
                
                # Calculate text size and position (same as other visualizations)
                (text_w, text_h), baseline = cv2.getTextSize(label, font, text_scale, text_thickness)
                
                # Position label above the box, or below if no space above
                label_x = x1
                label_y = y1 - text_padding
                
                if label_y - text_h < 0:
                    label_y = y2 + text_h + text_padding
                
                # Draw CLEAN label background (same style as YOLO)
                bg_x1, bg_y1 = label_x, label_y - text_h - text_padding
                bg_x2, bg_y2 = label_x + text_w + text_padding * 2, label_y + text_padding
                
                cv2.rectangle(img_cv, (bg_x1, bg_y1), (bg_x2, bg_y2), color_bgr, cv2.FILLED)
                
                # Draw clean label text (white text like YOLO)
                text_color = (255, 255, 255)  # White text
                cv2.putText(img_cv, label, (label_x + text_padding, label_y), font, text_scale, 
                           text_color, text_thickness, cv2.LINE_AA)
        
        # Add CLEAN summary overlay (same style as detection count overlay)
        analysis = seraphine_analysis['analysis']
        summary_text = f"SERAPHINE: {analysis['total_groups']} groups ({analysis['horizontal_groups']}H + {analysis['vertical_groups']}V)"
        
        # Draw clean summary background (same as YOLO detection count)
        cv2.rectangle(img_cv, (10, 10), (500, 40), (0, 0, 0), cv2.FILLED)
        cv2.rectangle(img_cv, (10, 10), (500, 40), (255, 255, 255), 2)
        cv2.putText(img_cv, summary_text, (20, 30), font, 0.6, (255, 255, 255), 1, cv2.LINE_AA)
        
        # Convert back to PIL and save
        img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)
        result_img = Image.fromarray(img_rgb)
        result_img.save(output_path, quality=95)
        
        debug_print(f"üíæ Saved SERAPHINE GROUPS: {analysis['total_groups']} groups ‚Üí {output_filename}")
        return output_path

    def _create_detection_visualization(self, image: Image.Image, detections: List[Dict], 
                                      viz_type: str, filename_base: str) -> str:
        """Create beautiful visualization for detection results"""
        
        # Get current time for filename
        current_time = datetime.now().strftime("%H-%M")
        output_filename = f"{filename_base}_{viz_type}_result_{current_time}.jpg"
        output_path = os.path.join(self.output_dir, output_filename)
        
        # Convert PIL to OpenCV for drawing
        img_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        h, w = img_cv.shape[:2]
        
        # Get color for this visualization type
        color_rgb = self.colors.get(viz_type, self.colors['complete'])
        color_bgr = (color_rgb[2], color_rgb[1], color_rgb[0])  # RGB to BGR
        
        # Drawing parameters
        font = cv2.FONT_HERSHEY_DUPLEX
        text_scale = 0.35
        thickness = 1
        text_thickness = 1
        text_padding = 2
        
        # Draw each detection
        for i, detection in enumerate(detections):
            # Get bbox coordinates
            if 'bbox' in detection:
                bbox = detection['bbox']
            elif 'box' in detection:
                bbox = detection['box']
            else:
                continue
            
            # Handle different coordinate formats
            if len(bbox) == 4:
                if all(0 <= coord <= 1 for coord in bbox):
                    # Normalized coordinates
                    x1, y1, x2, y2 = int(bbox[0] * w), int(bbox[1] * h), int(bbox[2] * w), int(bbox[3] * h)
                else:
                    # Pixel coordinates
                    x1, y1, x2, y2 = map(int, bbox)
            else:
                continue
            
            # Draw bounding box
            cv2.rectangle(img_cv, (x1, y1), (x2, y2), color_bgr, thickness)
            
            # Prepare label text
            label_parts = []
            
            # Add ID if available (prioritize m_id, y_id, o_id)
            if 'm_id' in detection:
                label_parts.append(detection['m_id'])
            elif 'y_id' in detection:
                label_parts.append(detection['y_id'])
            elif 'o_id' in detection:
                label_parts.append(detection['o_id'])
            else:
                label_parts.append(str(i+1))
            
            # Add confidence if available
            if 'confidence' in detection:
                conf = detection['confidence']
                label_parts.append(f"{conf:.2f}")
            elif 'conf' in detection:
                conf = detection['conf']
                label_parts.append(f"{conf:.2f}")
            
            label = ": ".join(label_parts)
            
            # Calculate text size and position
            (text_w, text_h), baseline = cv2.getTextSize(label, font, text_scale, text_thickness)
            
            # Position label above the box, or below if no space above
            label_x = x1
            label_y = y1 - text_padding
            
            if label_y - text_h < 0:
                label_y = y2 + text_h + text_padding
            
            # Draw label background
            bg_x1, bg_y1 = label_x, label_y - text_h - text_padding
            bg_x2, bg_y2 = label_x + text_w + text_padding * 2, label_y + text_padding
            
            cv2.rectangle(img_cv, (bg_x1, bg_y1), (bg_x2, bg_y2), color_bgr, cv2.FILLED)
            
            # Draw label text
            text_color = (255, 255, 255)  # White text
            cv2.putText(img_cv, label, (label_x + text_padding, label_y), font, text_scale, 
                       text_color, text_thickness, cv2.LINE_AA)
        
        # Add detection count overlay
        count_text = f"{viz_type.upper()}: {len(detections)} detections"
        cv2.rectangle(img_cv, (10, 10), (300, 40), (0, 0, 0), cv2.FILLED)
        cv2.rectangle(img_cv, (10, 10), (300, 40), color_bgr, 2)
        cv2.putText(img_cv, count_text, (20, 30), font, 0.6, (255, 255, 255), 1, cv2.LINE_AA)
        
        # Convert back to PIL and save
        img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)
        result_img = Image.fromarray(img_rgb)
        result_img.save(output_path, quality=95)
        
        debug_print(f"üíæ Saved {viz_type.upper()}: {len(detections)} detections ‚Üí {output_filename}")
        return output_path

    
    def _create_gemini_visualization(self, image: Image.Image, gemini_analysis, 
                                   seraphine_analysis: Dict, filename_base: str) -> str:
        """Create beautiful Gemini analysis visualization with Seraphine group mapping"""
        
        # Safety check and type handling
        if not gemini_analysis:
            debug_print("‚ö†Ô∏è  Gemini analysis is empty or None, skipping visualization")
            return None
        
        # Handle if gemini_analysis is a JSON string
        if isinstance(gemini_analysis, str):
            try:
                import json
                gemini_analysis = json.loads(gemini_analysis)
                debug_print("üìã Parsed Gemini analysis from JSON string")
            except json.JSONDecodeError as e:
                debug_print(f"‚ùå Failed to parse Gemini JSON: {e}")
                return None
        
        # Extract icons from the nested structure - COLLECT FROM ALL IMAGES
        if isinstance(gemini_analysis, dict):
            # Get icons from ALL successful image analyses
            if 'images' in gemini_analysis and len(gemini_analysis['images']) > 0:
                all_icons = []
                for image_data in gemini_analysis['images']:
                    if image_data.get('analysis_success', True) and 'icons' in image_data:
                        icons = image_data['icons']
                        all_icons.extend(icons)
                        debug_print(f"üìã Added {len(icons)} icons from {image_data.get('image_name', 'unknown')}")
                
                if all_icons:
                    gemini_analysis = all_icons
                    debug_print(f"‚úÖ Total extracted: {len(gemini_analysis)} icons from {len([img for img in gemini_analysis if img.get('analysis_success', True)])} images")
                else:
                    debug_print("‚ùå No icons found in any successful image analysis")
                    return None
            else:
                debug_print("‚ùå No images found in Gemini analysis")
                return None
        
        # Ensure it's a list
        if not isinstance(gemini_analysis, list):
            debug_print(f"‚ùå Gemini analysis expected list, got {type(gemini_analysis)}")
            return None
            
        if len(gemini_analysis) == 0:
            debug_print("‚ö†Ô∏è  Gemini analysis list is empty, skipping visualization")
            return None
        
        debug_print(f"‚úÖ Processing {len(gemini_analysis)} Gemini items for visualization")
        
        current_time = datetime.now().strftime("%H-%M")
        output_filename = f"{filename_base}_gemini_analysis_{current_time}.jpg"
        output_path = os.path.join(self.output_dir, output_filename)
        
        # Convert PIL to OpenCV
        img_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        h, w = img_cv.shape[:2]
        
        font = cv2.FONT_HERSHEY_DUPLEX
        text_scale = 0.25
        thickness = 1
        text_thickness = 1
        
        # Get group details from seraphine analysis
        group_details = seraphine_analysis['analysis']['group_details']
        
        # Create mapping from Gemini analysis
        gemini_labels = {}
        for item in gemini_analysis:
            gemini_labels[item['id']] = {
                'name': item['name'],
                'usage': item['usage'],
                'group_type': item['group_type']
            }
        
        color_idx = 0
        
        # Draw each group with its Gemini labels
        for group_key, group_info in group_details.items():
            # Get color for this group
            color_rgb = self.seraphine_colors[color_idx % len(self.seraphine_colors)]
            color_bgr = (color_rgb[2], color_rgb[1], color_rgb[0])
            color_idx += 1
            
            # Draw all bboxes in this group
            for i, bbox_info in enumerate(group_info['bboxes']):
                bbox = bbox_info['bbox']
                
                if len(bbox) == 4:
                    x1, y1, x2, y2 = map(int, bbox)
                    
                    # Draw thick border for grouped items
                    cv2.rectangle(img_cv, (x1, y1), (x2, y2), color_bgr, thickness)
                    
                    # Get Gemini label for this specific item
                    item_id = f"{group_key}_{i+1}"
                    gemini_info = gemini_labels.get(item_id, {})
                    gemini_name = gemini_info.get('name', 'Unlabeled')
                    
                    # Create label text
                    full_label = f"{item_id}: {gemini_name}"
                    # skipping item_id due to low space
                    # full_label = f"{gemini_name}"
                    
                    # Calculate label dimensions
                    (text_w, text_h), _ = cv2.getTextSize(full_label, font, text_scale, text_thickness)
                    
                    # Position label (try above, fallback to inside)
                    label_x = x1 + 5
                    label_y = y1 - 10
                    bg_x1, bg_y1 = x1, y1 - text_h - 15
                    bg_x2, bg_y2 = x1 + text_w + 10, y1 - 5
                    
                    # Adjust if label goes outside image bounds
                    if bg_y1 < 0:
                        label_y = y1 + text_h + 10
                        bg_y1, bg_y2 = y1 + 5, y1 + text_h + 15
                    
                    if bg_x2 > w:
                        label_x = x2 - text_w - 5
                        bg_x1, bg_x2 = x2 - text_w - 10, x2
                    
                    # Draw label background with group color
                    cv2.rectangle(img_cv, (bg_x1, bg_y1), (bg_x2, bg_y2), color_bgr, cv2.FILLED)
                    cv2.rectangle(img_cv, (bg_x1, bg_y1), (bg_x2, bg_y2), (255, 255, 255), 1)
                    
                    # Draw label text
                    text_color = (255, 255, 255)  # White text
                    cv2.putText(img_cv, full_label, (label_x, label_y), font, text_scale, 
                               text_color, text_thickness, cv2.LINE_AA)
        
        # Add comprehensive legend showing all Gemini labels
        legend_x = w - 350
        legend_y = 20
        legend_height = min(len(gemini_analysis) * 20 + 40, h - 100)  # Limit height
        
        show_gemini_analysis_box = False
        if show_gemini_analysis_box: 
            cv2.rectangle(img_cv, (legend_x, legend_y), (w - 10, legend_y + legend_height), 
                        (0, 0, 0), cv2.FILLED)
            cv2.rectangle(img_cv, (legend_x, legend_y), (w - 10, legend_y + legend_height), 
                        (255, 255, 255), 2)
            
            cv2.putText(img_cv, "Gemini Analysis:", (legend_x + 10, legend_y + 20), 
                    font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)
            
            # Show first 15 items to avoid overcrowding
            visible_items = gemini_analysis[:15]
            for idx, item in enumerate(visible_items):
                y_pos = legend_y + 40 + idx * 20
                if y_pos > legend_y + legend_height - 25:
                    # Add "..." if more items exist
                    cv2.putText(img_cv, "...", (legend_x + 10, y_pos), 
                            font, 0.4, (255, 255, 255), 1, cv2.LINE_AA)
                    break
                    
                legend_text = f"{item['id']}: {item['name']}"
                # Truncate if too long
                if len(legend_text) > 35:
                    legend_text = legend_text[:32] + "..."
                    
                cv2.putText(img_cv, legend_text, (legend_x + 10, y_pos), 
                        font, 0.35, (255, 255, 255), 1, cv2.LINE_AA)
            
            # Add summary at bottom
            summary_lines = [
                f"Total Items: {len(gemini_analysis)}",
                f"Groups: {len(set(item['group_type'] for item in gemini_analysis))} types",
                f"Items per Group: {len(gemini_analysis)/len(group_details):.1f} avg"
            ]
            
            summary_bg_height = len(summary_lines) * 25 + 20
            cv2.rectangle(img_cv, (10, h - summary_bg_height - 10), 
                        (300, h - 10), (0, 0, 0), cv2.FILLED)
            cv2.rectangle(img_cv, (10, h - summary_bg_height - 10), 
                        (300, h - 10), (255, 255, 255), 2)
            
            for i, line in enumerate(summary_lines):
                cv2.putText(img_cv, line, (20, h - summary_bg_height + 15 + i*25), 
                        font, 0.5, (255, 255, 255), 1, cv2.LINE_AA)
        
        # Convert back to PIL and save
        img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)
        result_img = Image.fromarray(img_rgb)
        result_img.save(output_path, quality=95)
        
        total_items = len(gemini_analysis)
        debug_print(f"üíæ Saved GEMINI: {total_items} labeled items ‚Üí {output_filename}")
        return output_path

==================================================

Path: utils\seraphine_pipeline\create_crops.py
File: create_crops.py
Code:
import cv2
import json
import os
import random
import numpy as np
from typing import List, Dict, Tuple
from .helpers import debug_print


class StochasticCropExtractor:
    """
    Extracts crops from an image based on bounding boxes with stochastic variations.
    """
    
    def __init__(self, image_path: str, output_dir: str = "utils/crops"):
        self.image_path = image_path
        self.output_dir = output_dir
        self.image = None
        self.image_height = 0
        self.image_width = 0
        
        # Create output directory
        os.makedirs(output_dir, exist_ok=True)
        
        # Load the image
        self._load_image()
    
    def _load_image(self):
        """Load the source image"""
        self.image = cv2.imread(self.image_path)
        if self.image is None:
            raise ValueError(f"Could not load image: {self.image_path}")
        
        self.image_height, self.image_width = self.image.shape[:2]
        debug_print(f"üì∑ Loaded image: {self.image_width}x{self.image_height}")
    
    def _apply_stochastic_padding(self, bbox: List[int]) -> List[int]:
        """
        Apply random padding to bbox coordinates (3-8px variation)
        
        Args:
            bbox: [x1, y1, x2, y2] coordinates
            
        Returns:
            Modified bbox with stochastic padding
        """
        x1, y1, x2, y2 = bbox
        
        # Random padding between 3-8 pixels
        pad_left = random.randint(1, 3)
        pad_top = random.randint(1, 3)
        pad_right = random.randint(1, 3)
        pad_bottom = random.randint(1, 3)
        
        # Apply padding with random direction (expand or contract)
        # 70% chance to expand, 30% chance to contract
        expand_left = random.random() < 0.5
        expand_top = random.random() < 0.5
        expand_right = random.random() < 0.5
        expand_bottom = random.random() < 0.5
        
        new_x1 = x1 - pad_left if expand_left else x1 + pad_left
        new_y1 = y1 - pad_top if expand_top else y1 + pad_top
        new_x2 = x2 + pad_right if expand_right else x2 - pad_right
        new_y2 = y2 + pad_bottom if expand_bottom else y2 - pad_bottom
        
        # Ensure coordinates stay within image bounds
        new_x1 = max(0, min(new_x1, self.image_width - 1))
        new_y1 = max(0, min(new_y1, self.image_height - 1))
        new_x2 = max(new_x1 + 1, min(new_x2, self.image_width))
        new_y2 = max(new_y1 + 1, min(new_y2, self.image_height))
        
        return [new_x1, new_y1, new_x2, new_y2]
    
    def extract_crop(self, bbox: List[int], merged_id: int, item_info: Dict = None) -> str:
        """
        Extract a single crop with stochastic variations
        
        Args:
            bbox: [x1, y1, x2, y2] coordinates
            merged_id: Unique identifier for the crop
            item_info: Additional info about the item
            
        Returns:
            Path to saved crop image
        """
        # Apply stochastic padding
        stoch_bbox = self._apply_stochastic_padding(bbox)
        x1, y1, x2, y2 = stoch_bbox
        
        # Extract the crop
        crop = self.image[y1:y2, x1:x2]
        
        # Generate filename with additional info
        item_type = item_info.get('type', 'unknown') if item_info else 'unknown'
        source = item_info.get('source', 'unknown') if item_info else 'unknown'
        
        filename = f"crop_{merged_id:03d}_{item_type}_{source}.png"
        output_path = os.path.join(self.output_dir, filename)
        
        # Save the crop
        cv2.imwrite(output_path, crop)
        
        # Log the extraction
        original_size = f"{bbox[2]-bbox[0]}x{bbox[3]-bbox[1]}"
        stoch_size = f"{x2-x1}x{y2-y1}"
        padding_info = f"({x1-bbox[0]:+d},{y1-bbox[1]:+d},{x2-bbox[2]:+d},{y2-bbox[3]:+d})"
        
        debug_print(f"‚úÇÔ∏è  Crop {merged_id:03d}: {original_size} ‚Üí {stoch_size} {padding_info} ‚Üí {filename}")
        
        return output_path
    
    def extract_all_crops(self, json_file_path: str) -> Dict[int, str]:
        """
        Extract all crops from JSON detection results
        
        Args:
            json_file_path: Path to JSON file with detection results
            
        Returns:
            Dictionary mapping merged_id to crop file path
        """
        debug_print(f"üìÇ Loading detection results from: {json_file_path}")
        
        # Load JSON data
        with open(json_file_path, 'r') as f:
            detections = json.load(f)
        
        debug_print(f"üìä Found {len(detections)} detections to process")
        
        # Track extracted crops
        extracted_crops = {}
        
        # Process each detection
        for detection in detections:
            try:
                bbox = detection['bbox']
                merged_id = detection['merged_id']
                
                # Extract crop with stochastic variations
                crop_path = self.extract_crop(bbox, merged_id, detection)
                extracted_crops[merged_id] = crop_path
                
            except Exception as e:
                debug_print(f"‚ùå Error processing detection {detection.get('merged_id', 'unknown')}: {e}")
        
        debug_print(f"‚úÖ Successfully extracted {len(extracted_crops)} crops")
        return extracted_crops
    
    def create_summary_report(self, extracted_crops: Dict[int, str], json_file_path: str):
        """Create a summary report of extracted crops"""
        
        # Load original detections for analysis
        with open(json_file_path, 'r') as f:
            detections = json.load(f)
        
        # Group by type and source
        type_counts = {}
        source_counts = {}
        
        for detection in detections:
            item_type = detection.get('type', 'unknown')
            source = detection.get('source', 'unknown')
            
            type_counts[item_type] = type_counts.get(item_type, 0) + 1
            source_counts[source] = source_counts.get(source, 0) + 1
        
        # Create summary
        summary_path = os.path.join(self.output_dir, "crop_extraction_summary.txt")
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("STOCHASTIC CROP EXTRACTION SUMMARY\n")
            f.write("=" * 50 + "\n\n")
            
            f.write(f"Source Image: {self.image_path}\n")
            f.write(f"Image Dimensions: {self.image_width}x{self.image_height}\n")
            f.write(f"Total Detections: {len(detections)}\n")
            f.write(f"Successfully Extracted: {len(extracted_crops)}\n")
            f.write(f"Output Directory: {self.output_dir}\n\n")
            
            f.write("BREAKDOWN BY TYPE:\n")
            for item_type, count in sorted(type_counts.items()):
                f.write(f"  {item_type}: {count}\n")
            
            f.write(f"\nBREAKDOWN BY SOURCE:\n")
            for source, count in sorted(source_counts.items()):
                f.write(f"  {source}: {count}\n")
            
            f.write(f"\nSTOCHASTIC VARIATIONS:\n")
            f.write(f"  Padding Range: 3-8 pixels\n")
            f.write(f"  Expansion Probability: 70%\n")
            f.write(f"  Contraction Probability: 30%\n")
            f.write(f"  Boundary Clamping: Enabled\n")
        
        debug_print(f"Summary report saved: {summary_path}")


def main():
    """Main execution function"""
    debug_print("üöÄ Starting Stochastic Crop Extraction")
    debug_print("=" * 50)
    
    # Configuration
    IMAGE_PATH = "word.png"
    JSON_PATH = "utils/word_merged_result_08-35.json"
    OUTPUT_DIR = "utils/crops"
    
    # Verify input files exist
    if not os.path.exists(IMAGE_PATH):
        debug_print(f"‚ùå Error: Image file not found: {IMAGE_PATH}")
        return
    
    if not os.path.exists(JSON_PATH):
        debug_print(f"‚ùå Error: JSON file not found: {JSON_PATH}")
        return
    
    try:
        # Initialize the crop extractor
        extractor = StochasticCropExtractor(IMAGE_PATH, OUTPUT_DIR)
        
        # Extract all crops
        extracted_crops = extractor.extract_all_crops(JSON_PATH)
        
        # Create summary report
        extractor.create_summary_report(extracted_crops, JSON_PATH)
        
        debug_print(f"\nüéâ Crop extraction complete!")
        debug_print(f"üìÅ Crops saved to: {OUTPUT_DIR}/")
        debug_print(f"üìä Total crops: {len(extracted_crops)}")
        
        # Show some examples
        if extracted_crops:
            debug_print(f"\nüì∏ Sample crops:")
            sample_ids = list(extracted_crops.keys())[:5]
            for crop_id in sample_ids:
                crop_path = extracted_crops[crop_id]
                filename = os.path.basename(crop_path)
                debug_print(f"  ID {crop_id:03d}: {filename}")
            
            if len(extracted_crops) > 5:
                debug_print(f"  ... and {len(extracted_crops) - 5} more crops")
    
    except Exception as e:
        debug_print(f"‚ùå Fatal error: {e}")


if __name__ == "__main__":
    main()


==================================================

Path: utils\seraphine_pipeline\crop_test.py
File: crop_test.py
Code:
import cv2
import numpy as np
import time
from typing import Tuple, List
import concurrent.futures
import os
import glob
from .helpers import debug_print


class UltraFastTemplateMatcher:
    """
    Ultra-optimized template matching for finding small crop images in larger images.
    Uses coarse-to-fine search and grayscale processing for maximum speed.
    """
    
    def __init__(self, save_results: bool = True):
        self.cached_templates = {}
        self.cached_grayscale_templates = {}
        self.cached_small_templates = {}
        self.save_results = save_results  # Global toggle for saving files
        
        # Beautiful color scheme inspired by beautiful_visualizer.py
        self.colors = {
            'match': (46, 125, 50),      # Green - Successful match
            'no_match': (244, 67, 54),   # Red - No match found
            'border': (255, 255, 255),   # White - Border
            'text_bg': (33, 33, 33),     # Dark gray - Text background
            'text': (255, 255, 255)      # White - Text
        }
        
    def preprocess_template(self, template_path: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        Preprocess and cache multiple versions of template for ultra-fast matching.
        """
        if template_path in self.cached_templates:
            return (self.cached_templates[template_path], 
                   self.cached_grayscale_templates[template_path],
                   self.cached_small_templates[template_path])
        
        template = cv2.imread(template_path, cv2.IMREAD_COLOR)
        if template is None:
            raise ValueError(f"Could not load template image: {template_path}")
        
        # Create grayscale version (much faster)
        gray_template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)
        
        # Create small version for initial coarse search - handle tiny images
        h, w = gray_template.shape
        if h >= 4 and w >= 4:  # Only resize if template is big enough
            small_template = cv2.resize(gray_template, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)
        else:
            # For tiny templates, use original size
            small_template = gray_template.copy()
        
        # Cache all versions
        self.cached_templates[template_path] = template
        self.cached_grayscale_templates[template_path] = gray_template
        self.cached_small_templates[template_path] = small_template
        
        return template, gray_template, small_template
    
    def ultra_fast_match(self, 
                        screenshot: np.ndarray, 
                        template_path: str,
                        threshold: float = 0.99) -> Tuple[bool, float, Tuple[int, int]]:
        """
        Ultra-fast single template matching with coarse-to-fine optimization.
        """
        # Get preprocessed templates
        _, gray_template, small_template = self.preprocess_template(template_path)
        
        # Convert screenshot to grayscale once
        gray_screenshot = cv2.cvtColor(screenshot, cv2.COLOR_BGR2GRAY)
        
        # Method 1: Coarse search at half resolution (4x faster)
        small_screenshot = cv2.resize(gray_screenshot, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)
        
        # Quick coarse match
        res_small = cv2.matchTemplate(small_screenshot, small_template, cv2.TM_CCOEFF_NORMED)
        _, max_val_small, _, max_loc_small = cv2.minMaxLoc(res_small)
        
        if max_val_small < threshold * 0.99:  # Lower threshold for coarse search
            return False, max_val_small, (0, 0)
        
        # Method 2: Refined search in ROI around coarse match
        scale = 2  # We downscaled by 0.5
        roi_size = max(gray_template.shape) * 2  # Search area around coarse match
        
        center_x = max_loc_small[0] * scale
        center_y = max_loc_small[1] * scale
        
        x1 = max(0, center_x - roi_size // 2)
        y1 = max(0, center_y - roi_size // 2)
        x2 = min(gray_screenshot.shape[1], center_x + roi_size // 2)
        y2 = min(gray_screenshot.shape[0], center_y + roi_size // 2)
        
        roi_screenshot = gray_screenshot[y1:y2, x1:x2]
        
        if roi_screenshot.size == 0:
            return False, 0.0, (0, 0)
        
        # Fine match in ROI
        res = cv2.matchTemplate(roi_screenshot, gray_template, cv2.TM_CCOEFF_NORMED)
        _, max_val, _, max_loc = cv2.minMaxLoc(res)
        
        found = max_val >= threshold
        if found:
            # Convert ROI coordinates back to full image coordinates
            abs_x = max_loc[0] + x1
            abs_y = max_loc[1] + y1
            return found, max_val, (abs_x, abs_y)
        
        return found, max_val, max_loc
    
    def parallel_batch_match(self, 
                           screenshot: np.ndarray, 
                           template_paths: List[str],
                           threshold: float = 0.99,
                           max_workers: int = 8) -> List[Tuple[str, bool, float, Tuple[int, int]]]:
        """
        Process multiple templates in parallel for maximum speed.
        """
        def match_single(template_path):
            found, confidence, location = self.ultra_fast_match(screenshot, template_path, threshold)
            return template_path, found, confidence, location
        
        results = []
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_template = {executor.submit(match_single, path): path for path in template_paths}
            
            for future in concurrent.futures.as_completed(future_to_template):
                results.append(future.result())
        
        return results

    def create_beautiful_visualization(self, 
                                     screenshot: np.ndarray, 
                                     template_path: str, 
                                     found: bool,
                                     confidence: float,
                                     location: Tuple[int, int], 
                                     output_path: str = "utils/ultra_fast_result.jpg"):
        """
        Create beautiful box visualization - simple and clean
        """
        if not self.save_results:
            return
            
        template = cv2.imread(template_path)
        if template is None:
            debug_print(f"Could not load template for visualization: {template_path}")
            return
        
        img_cv = screenshot.copy()
        
        if found:
            # Get template dimensions
            template_h, template_w = template.shape[:2]
            x1, y1 = location
            x2, y2 = x1 + template_w, y1 + template_h
            
            # Beautiful double border box only
            main_color = self.colors['match']  # Green
            border_color = self.colors['border']  # White
            
            # Draw beautiful bounding box with double border effect
            cv2.rectangle(img_cv, (x1-1, y1-1), (x2+1, y2+1), border_color, 2)  # White outer border
            cv2.rectangle(img_cv, (x1, y1), (x2, y2), main_color, 2)            # Green inner border
            
            # # Add subtle corner markers
            # corner_size = 2
            # cv2.line(img_cv, (x1, y1), (x1 + corner_size, y1), main_color, 2)
            # cv2.line(img_cv, (x1, y1), (x1, y1 + corner_size), main_color, 2)
            # cv2.line(img_cv, (x2, y2), (x2 - corner_size, y2), main_color, 2)
            # cv2.line(img_cv, (x2, y2), (x2, y2 - corner_size), main_color, 2)
        
        # Save with high quality
        cv2.imwrite(output_path, img_cv, [cv2.IMWRITE_JPEG_QUALITY, 95])
        debug_print(f"üé® Beautiful box saved: {output_path}")


if __name__ == "__main__":
    # Ultra-fast template matching example with beautiful visualization
    debug_print("üöÄ Ultra-Fast Template Matching with Beautiful Visualization")
    debug_print("=" * 60)
    
    # Load images
    screenshot = cv2.imread("word.png")
    template_path = "utils\crops\crop_004_icon_yolo.png"
    
    if screenshot is None:
        debug_print("‚ùå Error: Could not load word.png")
        exit(1)
    
    # Initialize matcher with save toggle (set to True for saving, False to disable)
    SAVE_RESULTS = True  # üéõÔ∏è Global toggle for saving files
    matcher = UltraFastTemplateMatcher(save_results=SAVE_RESULTS)
    
    # Single ultra-fast match
    start_time = time.perf_counter()
    found, confidence, location = matcher.ultra_fast_match(screenshot, template_path, threshold=0.99)
    end_time = time.perf_counter()
    
    match_time = (end_time - start_time) * 1000
    
    debug_print(f"üìä Single Match Results:")
    debug_print(f"   ‚è±Ô∏è  Time: {match_time:.2f}ms")
    debug_print(f"   ‚úÖ Found: {found}")
    debug_print(f"   üéØ Confidence: {confidence:.3f}")
    debug_print(f"   üìç Location: {location}")
    
    # Create beautiful visualization
    if SAVE_RESULTS:
        matcher.create_beautiful_visualization(
            screenshot, template_path, found, confidence, location
        )
    else:
        debug_print("üíæ File saving disabled (SAVE_RESULTS = False)")
    
    # Batch processing example (100 icons)
    debug_print(f"\nüîÑ Batch Processing (100 icons):")
    template_paths = [template_path] * 100
    
    start_time = time.perf_counter()
    batch_results = matcher.parallel_batch_match(screenshot, template_paths, max_workers=8)
    end_time = time.perf_counter()
    
    batch_time = (end_time - start_time) * 1000
    matches_found = sum(1 for _, found, _, _ in batch_results if found)
    throughput = 100 / (batch_time / 1000)
    
    debug_print(f"   ‚è±Ô∏è  Total time: {batch_time:.2f}ms")
    debug_print(f"   ‚úÖ Matches found: {matches_found}/100")
    debug_print(f"   üöÑ Throughput: {throughput:.1f} matches/second")
    debug_print(f"   üìä Average per match: {batch_time/100:.2f}ms")
    
    debug_print(f"\n‚ú® Ultra-fast template matching complete!")
    if SAVE_RESULTS:
        debug_print(f"üìÅ Results saved to: utils/ultra_fast_result.jpg")

    # NEW: Ultra-fast batch crop detection 
    debug_print(f"\n" + "=" * 60)
    debug_print("üîç ULTRA-FAST BATCH CROP DETECTION")
    debug_print("=" * 60)
    
    # Get all crop files
    crops_dir = "utils/crops"
    crop_files = glob.glob(os.path.join(crops_dir, "crop_*.png"))
    crop_files.sort()
    
    total_crops = len(crop_files)
    debug_print(f"üìÅ Found {total_crops} crops in {crops_dir}/")
    
    if total_crops > 0:
        # PURE COMPUTATION TIMING - No I/O or visualization
        debug_print(f"üöÄ Starting pure computation timing...")
        start_pure = time.perf_counter()
        
        # Use existing parallel batch processing for maximum speed
        batch_results = matcher.parallel_batch_match(
            screenshot, crop_files, threshold=0.7, max_workers=8
        )
        
        end_pure = time.perf_counter()
        pure_computation_time = (end_pure - start_pure) * 1000
        
        # Count successful matches
        successful_matches = sum(1 for _, found, _, _ in batch_results if found)
        
        # Pure computation stats
        debug_print(f"\n‚ö° PURE COMPUTATION PERFORMANCE:")
        debug_print(f"   ‚è±Ô∏è  Pure computation: {pure_computation_time:.1f}ms ({pure_computation_time/1000:.2f}s)")
        debug_print(f"   üöÑ Pure throughput: {total_crops/(pure_computation_time/1000):.1f} crops/second")
        debug_print(f"   üìä Average per crop: {pure_computation_time/total_crops:.2f}ms")
        debug_print(f"   ‚úÖ Found: {successful_matches}/{total_crops} ({(successful_matches/total_crops)*100:.1f}%)")
        
        # Now do visualization separately (if needed)
        if successful_matches > 0:
            debug_print(f"\nüé® Creating visualization overlay...")
            start_viz = time.perf_counter()
            
            final_overlay = screenshot.copy()
            
            for template_path, found, confidence, location in batch_results:
                if found:
                    # Extract crop ID from filename
                    crop_name = os.path.basename(template_path)
                    crop_id = "?"
                    try:
                        parts = crop_name.replace('.png', '').split('_')
                        if len(parts) >= 2:
                            crop_id = parts[1]
                    except:
                        pass
                    
                    # Get template size from cache (fast!)
                    if template_path in matcher.cached_templates:
                        template = matcher.cached_templates[template_path]
                        template_h, template_w = template.shape[:2]
                        
                        x1, y1 = location
                        x2, y2 = x1 + template_w, y1 + template_h
                        
                        # Same beautiful box style
                        main_color = matcher.colors['match']
                        border_color = matcher.colors['border']
                        
                        # Beautiful double border box
                        cv2.rectangle(final_overlay, (x1-2, y1-2), (x2+2, y2+2), border_color, 4)
                        cv2.rectangle(final_overlay, (x1, y1), (x2, y2), main_color, 2)
                        
                        # Corner markers
                        corner_size = 15
                        cv2.line(final_overlay, (x1, y1), (x1 + corner_size, y1), main_color, 4)
                        cv2.line(final_overlay, (x1, y1), (x1, y1 + corner_size), main_color, 4)
                        cv2.line(final_overlay, (x2, y2), (x2 - corner_size, y2), main_color, 4)
                        cv2.line(final_overlay, (x2, y2), (x2, y2 - corner_size), main_color, 4)
                        
                        # Add crop ID label
                        label_x = x1 + 2
                        label_y = y1 - 5
                        if label_y < 15:
                            label_y = y1 + 15
                        
                        cv2.putText(final_overlay, crop_id, (label_x, label_y), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, main_color, 1, cv2.LINE_AA)
            
            end_viz = time.perf_counter()
            viz_time = (end_viz - start_viz) * 1000
            
            # Save overlay
            overlay_path = "utils/all_crops_detected.jpg"
            cv2.imwrite(overlay_path, final_overlay, [cv2.IMWRITE_JPEG_QUALITY, 95])
            
            debug_print(f"   üé® Visualization time: {viz_time:.1f}ms")
            debug_print(f"   üíæ Overlay saved: {overlay_path}")
        
        # Total timing breakdown
        total_time = pure_computation_time + (viz_time if successful_matches > 0 else 0)
        debug_print(f"\nüìä TIMING BREAKDOWN:")
        debug_print(f"   ‚ö° Pure computation: {pure_computation_time:.1f}ms ({pure_computation_time/total_time*100:.1f}%)")
        if successful_matches > 0:
            debug_print(f"   üé® Visualization: {viz_time:.1f}ms ({viz_time/total_time*100:.1f}%)")
        debug_print(f"   üìà Total: {total_time:.1f}ms")
        
    else:
        debug_print("‚ùå No crop files found in utils/crops/")


==================================================

Path: utils\seraphine_pipeline\gemini_analyzer.py
File: gemini_analyzer.py
Code:
"""
Gemini LLM analyzer utility for grouped icon images
Sends Seraphine-generated grouped images to Gemini for intelligent analysis
"""

import os
import json
import asyncio
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from PIL import Image
from datetime import datetime
from .helpers import debug_print

try:
    from google import genai
    from google.genai.errors import ServerError
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    debug_print("‚ö†Ô∏è  Warning: google-genai not installed. Gemini analysis will be skipped.")

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    debug_print("‚ö†Ô∏è  Warning: python-dotenv not installed. Make sure GEMINI_API_KEY is set manually.")


class GeminiIconAnalyzer:
    """
    Analyzes grouped icon images using Gemini LLM
    Takes Seraphine-generated final_*.png images and identifies icons with usage descriptions
    """
    
    def __init__(self, prompt_path: str = None, 
                 output_dir: str = "outputs", 
                 max_concurrent_requests: int = 4,
                 save_results: bool = True):
        self.output_dir = output_dir
        
        # Fix: Handle prompt path correctly
        if prompt_path is None:
            # Default case: find prompt.txt in the same directory as this module
            module_dir = os.path.dirname(os.path.abspath(__file__))
            self.prompt_path = os.path.join(module_dir, "prompt.txt")
        else:
            # Custom case: use the provided path as-is (relative to working directory)
            # Don't append to module directory!
            self.prompt_path = prompt_path
        
        self.max_concurrent_requests = max_concurrent_requests
        self.save_results = save_results
        
        if not GEMINI_AVAILABLE:
            raise ImportError("google-genai package not installed. Install with: pip install google-genai")
        
        # Initialize Gemini client
        self.api_key = os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY not found in environment variables")
        
        self.client = genai.Client(api_key=self.api_key)
        self.prompt = self._load_prompt()
        
        debug_print(f"ü§ñ Gemini analyzer initialized with prompt from: {self.prompt_path}")
    
    def _load_prompt(self) -> str:
        """Load the analysis prompt from file"""
        try:
            with open(self.prompt_path, "r", encoding="utf-8") as f:
                prompt_content = f.read().strip()
            debug_print(f"‚úÖ Loaded prompt ({len(prompt_content)} characters)")
            return prompt_content
        except FileNotFoundError:
            raise FileNotFoundError(f"Prompt file not found: {self.prompt_path}")
    
    async def analyze_grouped_images(self, grouped_image_paths: List[str] = None, 
                                   filename_base: str = None,
                                   direct_images: List[Tuple] = None) -> Dict[str, Any]:
        """
        Analyze grouped images generated by Seraphine
        
        Args:
            grouped_image_paths: List of paths to final_*.png images (traditional method)
            filename_base: Base filename for saving results
            direct_images: List of (PIL.Image, filename) tuples (optimized method)
            
        Returns:
            Dictionary containing analysis results
        """
        if direct_images:
            debug_print(f"\nü§ñ Starting Gemini analysis of {len(direct_images)} grouped images (direct mode)...")
            valid_images = [(img, name) for img, name in direct_images if "combined" in name]
        else:
            debug_print(f"\nü§ñ Starting Gemini analysis of {len(grouped_image_paths)} grouped images (file mode)...")
            valid_image_paths = [
                image_path for image_path in sorted(grouped_image_paths) 
                if "combined" in os.path.basename(image_path)
            ]
            valid_images = [(path, os.path.basename(path)) for path in valid_image_paths]
        
        if not valid_images:
            debug_print("‚ùå No valid combined images found for analysis")
            return {'images': [], 'total_icons': 0, 'analysis_time': 0}
        
        # Start timing
        start_time = datetime.now()
        
        debug_print(f"  üì∏ Starting parallel analysis of {len(valid_images)} images...")
        
        # Execute all tasks in parallel with concurrency limit
        semaphore = asyncio.Semaphore(self.max_concurrent_requests)
        
        # Modified analysis function with semaphore for direct images
        async def analyze_and_process_image_direct(image_data, filename: str, index: int) -> Dict[str, Any]:
            """Analyze a single image with concurrency control - supports both file paths and PIL images"""
            async with semaphore:
                debug_print(f"  üì∏ Analyzing image {index+1}/{len(valid_images)}: {filename}")
                
                try:
                    # Analyze with Gemini - supports both PIL and file path
                    response = await self._analyze_single_image_direct(image_data, filename)
                    
                    if response:
                        icons = self._parse_gemini_response(response)
                        
                        image_result = {
                            'image_path': filename if isinstance(image_data, str) else f"direct:{filename}",
                            'image_name': filename,
                            'icons_found': len(icons),
                            'icons': icons,
                            'raw_response': response,
                            'analysis_success': True
                        }
                        
                        debug_print(f"    ‚úÖ Found {len(icons)} icons in {filename}")
                        return image_result
                    else:
                        image_result = {
                            'image_path': filename if isinstance(image_data, str) else f"direct:{filename}",
                            'image_name': filename,
                            'icons_found': 0,
                            'icons': [],
                            'raw_response': None,
                            'analysis_success': False,
                            'error': 'Failed to get response from Gemini'
                        }
                        debug_print(f"    ‚ùå Analysis failed for {filename}")
                        return image_result
                    
                except Exception as e:
                    debug_print(f"    ‚ùå Error analyzing {filename}: {str(e)}")
                    return {
                        'image_path': filename if isinstance(image_data, str) else f"direct:{filename}",
                        'image_name': filename,
                        'icons_found': 0,
                        'icons': [],
                        'raw_response': None,
                        'analysis_success': False,
                        'error': str(e)
                    }
        
        # Create tasks for all images
        tasks = []
        for i, (image_data, filename) in enumerate(valid_images):
            tasks.append(analyze_and_process_image_direct(image_data, filename, i))
        
        debug_print(f"üöÄ Executing {len(tasks)} requests to Gemini (max {self.max_concurrent_requests} concurrent)...")
        image_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Handle any exceptions from gather
        processed_results = []
        total_icons_found = 0
        
        for i, result in enumerate(image_results):
            if isinstance(result, Exception):
                error_result = {
                    'image_path': f"direct:{valid_images[i][1]}" if direct_images else valid_images[i][0],
                    'image_name': valid_images[i][1],
                    'icons_found': 0,
                    'icons': [],
                    'raw_response': None,
                    'analysis_success': False,
                    'error': f'Task exception: {str(result)}'
                }
                processed_results.append(error_result)
                debug_print(f"    ‚ùå Task exception for {valid_images[i][1]}: {result}")
            else:
                processed_results.append(result)
                if result['analysis_success']:
                    total_icons_found += result['icons_found']
        
        image_results = processed_results
        
        end_time = datetime.now()
        analysis_duration = (end_time - start_time).total_seconds()
        
        # Compile final results
        results = {
            'filename_base': filename_base,
            'analysis_timestamp': end_time.isoformat(),
            'analysis_duration_seconds': analysis_duration,
            'total_images_analyzed': len(valid_images),
            'total_input_images': len(direct_images) if direct_images else len(grouped_image_paths),
            'analysis_mode': 'direct' if direct_images else 'file',
            'successful_analyses': len([r for r in image_results if r['analysis_success']]),
            'total_icons_found': total_icons_found,
            'images': image_results
        }
        
        # Save results
        results_path = self._save_analysis_results(results, filename_base)
        results['results_saved_to'] = results_path
        
        # Display summary
        self._display_analysis_summary(results)
        
        debug_print(f"üéâ Gemini analysis completed in {analysis_duration:.2f}s")
        return results
    
    async def _analyze_single_image_direct(self, image_data, filename: str) -> Optional[str]:
        """Analyze a single image with Gemini - supports both PIL images and file paths"""
        try:
            if isinstance(image_data, str):
                # Traditional file path method
                image = Image.open(image_data)
            else:
                # Direct PIL image method (optimization!)
                image = image_data
            
            # Call Gemini API
            response = await self.client.aio.models.generate_content(
                model="gemini-2.0-flash-exp",
                contents=[self.prompt, image],
            )
            
            return response.text
            
        except ServerError as e:
            debug_print(f"    ‚ö†Ô∏è  Server error: {e}")
            return None
        except Exception as e:
            debug_print(f"    ‚ùå Analysis error: {e}")
            return None
    
    def _parse_gemini_response(self, response_text: str) -> List[Dict[str, str]]:
        """Parse Gemini response into structured icon data"""
        if not response_text:
            return []
        
        icons = []
        lines = response_text.strip().split('\n')
        
        for line in lines:
            line = line.strip()
            
            # Skip empty lines and lines that don't start with group identifiers
            if not line or not line.startswith(('H', 'V', 'U')):
                continue
            
            try:
                # Parse format: ID: "icon_name" | Usage: "brief explanation" | Enabled: "true/false" | Interactive: "true/false" | Type: "icon/text"
                if line.count('|') >= 4 and ':' in line:  # Now expect 5 parts
                    parts = line.split('|')
                    id_part = parts[0]
                    usage_part = parts[1] 
                    enabled_part = parts[2]
                    interactive_part = parts[3]
                    type_part = parts[4]
                    
                    # Extract ID and name
                    id_section = id_part.split(':', 1)
                    if len(id_section) == 2:
                        icon_id = id_section[0].strip()
                        icon_name = id_section[1].strip().strip('"')
                        
                        # Extract usage
                        usage = usage_part.replace('Usage:', '').strip().strip('"')
                        
                        # Extract enabled and interactive
                        enabled = enabled_part.replace('Enabled:', '').strip().strip('"').lower() == 'true'
                        interactive = interactive_part.replace('Interactive:', '').strip().strip('"').lower() == 'true'
                        
                        # Extract type
                        g_type = type_part.replace('Type:', '').strip().strip('"').lower()
                        if g_type not in ['icon', 'text']:
                            g_type = 'icon'  # Default fallback
                        
                        icons.append({
                            'id': icon_id,
                            'name': icon_name,
                            'usage': usage,
                            'enabled': enabled,
                            'interactive': interactive,
                            'type': g_type,  # New field
                            'group_type': icon_id[0] if icon_id else 'unknown'
                        })
                        
            except Exception as e:
                debug_print(f"    ‚ö†Ô∏è  Failed to parse line: '{line}' - {e}")
                continue
        
        return icons
    
    def _save_analysis_results(self, results: Dict[str, Any], filename_base: str) -> str:
        """Save analysis results to JSON file (only if enabled) - SINGLE FILE ONLY"""
        if not self.save_results:
            return None  # Skip saving if disabled
        
        current_time = datetime.now().strftime("%H-%M")
        
        # Save only ONE file with all the details (remove redundant summary)
        analysis_path = os.path.join(self.output_dir, f"{filename_base}_gemini_analysis_{current_time}.json")
        
        # Save complete results (with structured data AND raw responses for debugging)
        with open(analysis_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        debug_print(f"üíæ Saved Gemini analysis: {os.path.basename(analysis_path)}")
        
        return analysis_path
    
    def _display_analysis_summary(self, results: Dict[str, Any]):
        """Display a formatted summary of analysis results"""
        debug_print(f"\nü§ñ GEMINI ANALYSIS SUMMARY:")
        debug_print("=" * 60)
        debug_print(f"  üìä Images analyzed: {results['successful_analyses']}/{results['total_images_analyzed']}")
        debug_print(f"  üéØ Total icons found: {results['total_icons_found']}")
        debug_print(f"  ‚è±Ô∏è  Analysis time: {results['analysis_duration_seconds']:.2f}s")
        
        # Group icons by type
        icon_counts = {'H': 0, 'V': 0, 'U': 0}
        all_icons = []
        
        for image_result in results['images']:
            if image_result['analysis_success']:
                for icon in image_result['icons']:
                    all_icons.append(icon)
                    group_type = icon.get('group_type', 'U')
                    icon_counts[group_type] = icon_counts.get(group_type, 0) + 1
        
        debug_print(f"\nüìã ICON BREAKDOWN:")
        debug_print(f"  üîÑ Horizontal groups (H): {icon_counts['H']} icons")
        debug_print(f"  üìä Vertical groups (V): {icon_counts['V']} icons") 
        debug_print(f"  üîç Ungrouped (U): {icon_counts['U']} icons")
        
        # Show sample icons
        if all_icons:
            debug_print(f"\nüé® SAMPLE ICONS FOUND:")
            for i, icon in enumerate(all_icons[:5]):  # Show first 5
                debug_print(f"  {icon['id']}: \"{icon['name']}\" | {icon['usage'][:50]}...")
            
            if len(all_icons) > 5:
                debug_print(f"  ... and {len(all_icons) - 5} more icons")
        
        debug_print("=" * 60)


==================================================

Path: utils\seraphine_pipeline\gemini_integration.py
File: gemini_integration.py
Code:
"""
Gemini Integration Utility
Handles integration of Gemini LLM results into seraphine structure
"""
from .helpers import debug_print

def integrate_gemini_results(seraphine_analysis, gemini_results):
    """
    Integrate Gemini results into seraphine structure at individual bbox level
    """
    if not gemini_results or not gemini_results.get('images'):
        debug_print("‚ö†Ô∏è  No Gemini results to integrate")
        return seraphine_analysis
    
    debug_print("\nüîó Integrating Gemini results into seraphine structure...")
    
    # Create mapping from ALL Gemini results across all images
    id_to_gemini = {}
    
    for image_result in gemini_results['images']:
        if image_result['analysis_success'] and image_result.get('icons'):
            for icon in image_result['icons']:
                icon_id = icon.get('id')  # Like "H1_1", "H12_3", etc.
                if icon_id:
                    id_to_gemini[icon_id] = {
                        'icon_name': icon.get('name', 'unknown'),
                        'brief': icon.get('usage', 'No description'),
                        'enabled': icon.get('enabled', True),
                        'interactive': icon.get('interactive', True),
                        'type': icon.get('type', 'icon')  # New field
                    }
    
    debug_print(f"   üìã Found {len(id_to_gemini)} Gemini mappings to integrate")
    
    # Integrate results into seraphine bbox_processor
    bbox_processor = seraphine_analysis['bbox_processor']
    total_integrated = 0
    
    for group_id, boxes in bbox_processor.final_groups.items():
        # Process each box in the group
        for i, bbox in enumerate(boxes):
            item_id = f"{group_id}_{i+1}"  # H1_1, H1_2, etc.
            
            if item_id in id_to_gemini:
                # Found exact match!
                gemini_data = id_to_gemini[item_id]
                bbox.g_icon_name = gemini_data['icon_name']
                bbox.g_brief = gemini_data['brief']
                bbox.g_enabled = gemini_data['enabled']
                bbox.g_interactive = gemini_data['interactive']
                bbox.g_type = gemini_data['type']  # New field
                total_integrated += 1
                
                if total_integrated <= 5:  # Show first 5 for debugging
                    debug_print(f"   ‚úÖ {item_id}: '{gemini_data['icon_name']}' - {gemini_data['brief'][:50]}...")
            else:
                # Default values if no Gemini result available
                bbox.g_icon_name = 'unanalyzed'
                bbox.g_brief = 'Not analyzed by Gemini'
    
    debug_print(f"‚úÖ Integrated Gemini results: {total_integrated}/{sum(len(boxes) for boxes in bbox_processor.final_groups.values())} items updated")
    
    # üéØ NEW: REGENERATE SERAPHINE_GEMINI_GROUPS WITH UPDATED DATA
    from .pipeline_exporter import create_enhanced_seraphine_structure
    
    # Get the merged_detections from analysis for proper ID lookup
    merged_detections = seraphine_analysis.get('original_merged_detections', [])
    
    # Create the enhanced structure with integrated Gemini data
    seraphine_gemini_groups = create_enhanced_seraphine_structure(
        seraphine_analysis, 
        merged_detections
    )
    
    # Add it to the analysis
    seraphine_analysis['seraphine_gemini_groups'] = seraphine_gemini_groups
    
    debug_print(f"üéØ Generated seraphine_gemini_groups with {len(seraphine_gemini_groups)} groups")
    
    return seraphine_analysis

async def run_gemini_analysis(seraphine_analysis, grouped_image_paths, image_path, config):
    """
    Run Gemini LLM analysis with optimized image sharing
    """
    if not config.get("gemini_enabled", False):
        debug_print("\n‚è≠Ô∏è  Gemini analysis disabled in config")
        return None
    
    debug_print("\nü§ñ Step 4: Gemini LLM Analysis (Optimized Image Sharing)")
    debug_print("=" * 70)
    
    try:
        from .gemini_analyzer import GeminiIconAnalyzer
        import os
        
        output_dir = config.get("output_dir", "outputs")
        filename_base = os.path.splitext(os.path.basename(image_path))[0]
        
        # Initialize analyzer - let it use default prompt path (relative to module)
        analyzer = GeminiIconAnalyzer(
            prompt_path=config.get("gemini_prompt_path"),  # Pass None to use default
            output_dir=output_dir,
            max_concurrent_requests=config.get("gemini_max_concurrent", 4),
            save_results=config.get("save_gemini_json", True)
        )
        
        # Use direct image mode for optimized sharing
        if config.get("gemini_return_images_b64", True):
            debug_print("   üì∏ Using optimized direct image mode (faster, less I/O)")
            
            from .seraphine_generator import FinalGroupImageGenerator
            
            # Create generator to get direct images
            final_group_generator = FinalGroupImageGenerator(
                output_dir=output_dir,
                save_mapping=False  # Don't save files, just get images
            )
            
            # Get direct images using the correct method
            result = final_group_generator.create_grouped_images(
                image_path=image_path,
                seraphine_analysis=seraphine_analysis,
                filename_base=filename_base,
                return_direct_images=True
            )
            
            # Extract direct images from result
            direct_images = result['direct_images']
            
            debug_print(f"   üñºÔ∏è  Generated {len(direct_images)} direct images for Gemini analysis")
            
            # Analyze with direct images (no file I/O)
            gemini_results = await analyzer.analyze_grouped_images(
                grouped_image_paths=None,
                filename_base=filename_base,
                direct_images=direct_images
            )
        else:
            debug_print("   üìÅ Using file mode (traditional)")
            # Use traditional file mode
            gemini_results = await analyzer.analyze_grouped_images(
                grouped_image_paths=grouped_image_paths,
                filename_base=filename_base,
                direct_images=None
            )
        
        debug_print(f"‚úÖ Gemini analysis complete:")
        debug_print(f"   üñºÔ∏è  Analyzed: {gemini_results['successful_analyses']}/{gemini_results['total_images_analyzed']} images")
        debug_print(f"   üéØ Total icons found: {gemini_results['total_icons_found']}")
        debug_print(f"   ‚è±Ô∏è  Analysis time: {gemini_results['analysis_duration_seconds']:.2f}s")
        
        return gemini_results
        
    except ImportError:
        debug_print("‚ùå Gemini analyzer not available (missing dependencies)")
        return None
    except Exception as e:
        debug_print(f"‚ùå Gemini analysis failed: {str(e)}")
        return None


==================================================

Path: utils\seraphine_pipeline\helpers.py
File: helpers.py
Code:
import os
import json
from functools import wraps

def load_configuration():
    """Load and validate configuration from config.json"""
    config_path = "utils/seraphine_pipeline/config.json"
    
    if not os.path.exists(config_path):
        print(f"Error: Configuration file '{config_path}' not found!")
        return None
    
    try:
        with open(config_path, "r") as f:
            config = json.load(f)
        return config
    except Exception as e:
        print(f"Error loading configuration: {e}")
        return None

def debug_only(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        config = load_configuration()
        if config and config.get("mode", "").lower() == "debug":
            return func(*args, **kwargs)
    return wrapper

@debug_only
def debug_print(*args, **kwargs):
    print(*args, **kwargs)

==================================================

Path: utils\seraphine_pipeline\ocr_detector.py
File: ocr_detector.py
Code:
"""
Clean OCR detection utility - extracted from ocr_onnx.py
Only detection, no text recognition.
No imports from original files allowed.
"""
import time
import numpy as np
import cv2
import onnxruntime as ort
from PIL import Image
from dataclasses import dataclass
from typing import List, Dict, Any, Tuple
import requests
import os
from .helpers import debug_print

@dataclass
class OCRDetConfig:
    """Configuration for OCR detection pipeline"""
    det_threshold: float = 0.3
    max_side_len: int = 960
    enable_timing: bool = True
    enable_debug: bool = False
    model_path: str = "models/ch_PP-OCRv3_det_infer.onnx"
    min_box_size: int = 3
    use_dilation: bool = True
    padding_x: int = 5  # Fixed horizontal padding
    padding_y_percent: float = 0.30  # Vertical padding percentage
    min_padding_y: int = 5

class OCRDetMemoryPool:
    """Memory pool for OCR detection"""
    def __init__(self, max_boxes=200):
        self.box_pool = [np.empty((4, 2), dtype=np.float32) for _ in range(max_boxes)]
        self.used_boxes = 0
        self.max_boxes = max_boxes
    
    def get_box_array(self):
        if self.used_boxes < self.max_boxes:
            arr = self.box_pool[self.used_boxes]
            self.used_boxes += 1
            return arr
        return np.empty((4, 2), dtype=np.float32)
    
    def reset(self):
        self.used_boxes = 0

class OCRModelCache:
    """Singleton cache for OCR detection model"""
    _instance = None
    _session = None
    _model_path = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def get_session(self, model_path):
        if self._session is None or self._model_path != model_path:
            if self._session is None:
                debug_print("  Loading CPU-optimized OCR detection model...")
            else:
                debug_print("  Reloading OCR detection model...")
            load_start = time.time()
            
            so = ort.SessionOptions()
            so.log_severity_level = 3
            so.enable_mem_pattern = True
            so.enable_mem_reuse = True
            so.enable_cpu_mem_arena = True
            so.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
            
            providers = [("CPUExecutionProvider", {
                "enable_cpu_mem_arena": True,
                "arena_extend_strategy": "kSameAsRequested",
                "initial_chunk_size_bytes": 1024 * 1024 * 32,
                "max_mem": 1024 * 1024 * 512
            })]
            
            self._session = ort.InferenceSession(model_path, sess_options=so, providers=providers)
            self._model_path = model_path
            
            load_time = time.time() - load_start
            debug_print(f"  OCR detection model loading: {load_time:.3f}s")
        
        return self._session

# Global instances
ocr_memory_pool = OCRDetMemoryPool()
ocr_model_cache = OCRModelCache()

def preprocess_det(image, max_side_len, enable_timing=True):
    """Detection preprocessing"""
    preprocess_start = time.time()
    
    img = np.array(image)
    height, width, _ = img.shape
    
    ratio = min(max_side_len / float(width), max_side_len / float(height))
    resize_w = int(width * ratio)
    resize_h = int(height * ratio)

    resize_w = resize_w if resize_w % 32 == 0 else (resize_w // 32) * 32
    resize_h = resize_h if resize_h % 32 == 0 else (resize_h // 32) * 32

    resized_img = image.resize((resize_w, resize_h), resample=Image.BILINEAR)
    
    norm_img = np.array(resized_img).astype(np.float32) / 255.0
    norm_img -= np.array([0.485, 0.456, 0.406])
    norm_img /= np.array([0.229, 0.224, 0.225])
    norm_img = norm_img.transpose(2, 0, 1)[np.newaxis, :]

    ratio_h = height / float(resize_h)
    ratio_w = width / float(resize_w)
    
    if enable_timing:
        preprocess_time = time.time() - preprocess_start
        debug_print(f"  OCR image scaled: {width}x{height} -> {resize_w}x{resize_h} (ratio: {ratio:.3f}) in {preprocess_time:.3f}s")
    
    return norm_img, ratio_h, ratio_w, time.time() - preprocess_start

def extract_boxes_opencv(score_map, ratio_w, ratio_h, det_threshold, min_box_size, use_dilation, enable_timing=True):
    """Extract boxes using OpenCV with dilation"""
    extraction_start = time.time()
    
    binary = (score_map > det_threshold).astype(np.uint8) * 255

    # Apply dilation to improve text detection
    if use_dilation:
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
        binary = cv2.dilate(binary, kernel, iterations=1)

    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    boxes = []
    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        
        if w >= min_box_size and h >= min_box_size:
            box = np.array([
                [x * ratio_w, y * ratio_h],
                [(x + w) * ratio_w, y * ratio_h],
                [(x + w) * ratio_w, (y + h) * ratio_h],
                [x * ratio_w, (y + h) * ratio_h]
            ], dtype=np.float32)
            boxes.append(box)
    
    if enable_timing:
        extraction_time = time.time() - extraction_start
        debug_print(f"  OCR box extraction: {extraction_time:.3f}s -> {len(boxes)} boxes")
    
    return boxes, time.time() - extraction_start

class OCRDetector:
    """Clean OCR detector class - detection only, no recognition"""
    
    def __init__(self, config: OCRDetConfig = None):
        self.config = config or OCRDetConfig()
        self.memory_pool = OCRDetMemoryPool()
    
    def detect(self, image_input):
        """
        Run OCR detection on image (no text recognition)
        
        Args:
            image_input: Path to image file or numpy array
            
        Returns:
            List of detection dictionaries with 'bbox' and metadata
        """
        total_start = time.time()
        
        if self.config.enable_timing:
            debug_print(f"\nüìù Starting OCR detection pipeline...")
            debug_print(f"ü§ñ Model: {self.config.model_path}")
            debug_print("=" * 60)
        
        # Load image
        if isinstance(image_input, np.ndarray):
            # Convert BGR numpy to PIL RGB
            img_rgb = cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB) 
            image = Image.fromarray(img_rgb)
        elif isinstance(image_input, str):
            image = Image.open(image_input).convert("RGB")
        else:
            image = image_input.convert("RGB")
        
        # Image setup
        setup_start = time.time()
        np_img = np.array(image)
        img_height, img_width = np_img.shape[:2]
        setup_time = time.time() - setup_start
        
        # Detection preprocessing
        det_input, ratio_h, ratio_w, det_preprocess_time = preprocess_det(
            image, self.config.max_side_len, self.config.enable_timing
        )
        
        # Detection inference
        det_inference_start = time.time()
        session = ocr_model_cache.get_session(self.config.model_path)
        det_output = session.run(None, {"x": det_input})[0]
        det_inference_time = time.time() - det_inference_start
        
        if self.config.enable_timing:
            debug_print(f"  OCR detection inference: {det_inference_time:.3f}s")
        
        # Extract boxes
        score_map = det_output[0][0]
        boxes, box_extraction_time = extract_boxes_opencv(
            score_map, ratio_w, ratio_h, 
            self.config.det_threshold, self.config.min_box_size, 
            self.config.use_dilation, self.config.enable_timing
        )
        
        if not boxes:
            if self.config.enable_timing:
                debug_print("‚ö†Ô∏è  OCR: No text regions detected")
            return []
        
        # Convert to standardized format with padding (same as ocr_onnx.py)
        detections = []
        for i, box in enumerate(boxes):
            x1, y1 = int(np.min(box[:, 0])), int(np.min(box[:, 1]))
            x2, y2 = int(np.max(box[:, 0])), int(np.max(box[:, 1]))
            
            # Apply padding (same logic as ocr_onnx.py)
            box_height = y2 - y1
            padding_x = self.config.padding_x
            padding_y = max(int(box_height * self.config.padding_y_percent), self.config.min_padding_y)
            
            x1_padded = max(0, x1 - padding_x)
            y1_padded = max(0, y1 - padding_y)
            x2_padded = min(img_width, x2 + padding_x)
            y2_padded = min(img_height, y2 + padding_y)
            
            detections.append({
                "bbox": [x1_padded, y1_padded, x2_padded, y2_padded],
                "type": "text",
                "source": "ocr_det",
                "confidence": 1.0,  # We don't have individual confidences
                "id": i
            })
        
        if self.config.enable_timing:
            total_time = time.time() - total_start
            debug_print("=" * 60)
            debug_print(f"  üìù OCR Detection Pipeline completed in {total_time:.3f}s")
            debug_print(f"  Found {len(detections)} OCR detections")
            debug_print(f"  Timing breakdown:")
            debug_print(f"   - Setup: {setup_time:.3f}s")
            debug_print(f"   - Preprocessing: {det_preprocess_time:.3f}s")
            debug_print(f"   - Inference: {det_inference_time:.3f}s")
            debug_print(f"   - Box extraction: {box_extraction_time:.3f}s")
        
        return detections

==================================================

Path: utils\seraphine_pipeline\parallel_processor.py
File: parallel_processor.py
Code:
"""
Parallel processor for running YOLO and OCR detection simultaneously
No imports from original files allowed.
"""
import time
import threading
import json
import os
from typing import List, Dict, Any, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from .helpers import debug_print

from .yolo_detector import YOLODetector, YOLOConfig
from .ocr_detector import OCRDetector, OCRDetConfig
from .bbox_merger import BBoxMerger
try:
    from .yolo_visualizer import DetectionVisualizer
except ImportError:
    DetectionVisualizer = None  # We'll handle this in __init__

class ParallelProcessor:
    """
    Coordinates parallel execution of YOLO and OCR detection,
    then merges the results according to specified rules.
    """
    
    def __init__(self, 
                 yolo_config: YOLOConfig = None,
                 ocr_config: OCRDetConfig = None,
                 merger_iou_threshold: float = 0.1,
                 enable_timing: bool = True,
                 create_visualizations: bool = True,
                 save_intermediate_results: bool = True):
        """
        Initialize parallel processor
        
        Args:
            yolo_config: Configuration for YOLO detector
            ocr_config: Configuration for OCR detector
            merger_iou_threshold: IoU threshold for bbox merging
            enable_timing: Whether to print timing information
            create_visualizations: Whether to create visualization images
            save_intermediate_results: Whether to save intermediate JSON files
        """
        self.yolo_config = yolo_config or YOLOConfig()
        self.ocr_config = ocr_config or OCRDetConfig()
        self.enable_timing = enable_timing
        self.create_visualizations = create_visualizations
        self.save_intermediate_results = save_intermediate_results
        
        # Initialize detectors
        self.yolo_detector = YOLODetector(self.yolo_config)
        self.ocr_detector = OCRDetector(self.ocr_config)
        self.merger = BBoxMerger(iou_threshold=merger_iou_threshold, enable_timing=enable_timing)
        
        # Initialize visualizer if needed
        if self.create_visualizations and DetectionVisualizer is not None:
            self.visualizer = DetectionVisualizer()
        elif self.create_visualizations:
            debug_print("‚ö†Ô∏è  DetectionVisualizer not available, skipping visualizations")
            self.create_visualizations = False
    
    def process_image(self, image_path: str, output_dir: str = "outputs") -> Dict[str, Any]:
        """
        Process image with parallel YOLO and OCR detection, then merge results
        
        Args:
            image_path: Path to input image
            output_dir: Directory to save results
            
        Returns:
            Dictionary containing all results and timing information
        """
        total_start = time.time()
        
        if self.enable_timing:
            debug_print(f"\nüöÄ Starting parallel detection pipeline...")
            debug_print(f"üìÅ Image: {image_path}")
            debug_print(f"üìÅ Output directory: {output_dir}")
            debug_print("=" * 80)
        
        # Ensure output directory exists
        os.makedirs(output_dir, exist_ok=True)
        
        # Prepare result containers
        results = {
            'image_path': image_path,
            'yolo_detections': [],
            'ocr_detections': [],
            'merged_detections': [],
            'timing': {},
            'merge_stats': {},
            'visualization_paths': {}
        }
        
        # Run YOLO and OCR detection in parallel
        parallel_start = time.time()
        
        def run_yolo():
            if self.enable_timing:
                debug_print(f"üéØ Thread: Starting YOLO detection...")
            return self.yolo_detector.detect(image_path)
        
        def run_ocr():
            if self.enable_timing:
                debug_print(f"üìù Thread: Starting OCR detection...")
            return self.ocr_detector.detect(image_path)
        
        # Execute in parallel using ThreadPoolExecutor
        with ThreadPoolExecutor(max_workers=2) as executor:
            # Submit both tasks
            yolo_future = executor.submit(run_yolo)
            ocr_future = executor.submit(run_ocr)
            
            # Wait for both to complete
            yolo_detections = yolo_future.result()
            ocr_detections = ocr_future.result()
        
        # üéØ FIX: Assign intelligent IDs BEFORE merging!
        yolo_detections, ocr_detections = self.assign_intelligent_ids(yolo_detections, ocr_detections)
        
        parallel_time = time.time() - parallel_start
        
        if self.enable_timing:
            debug_print(f"\n‚ö° Parallel detection completed in {parallel_time:.3f}s")
            debug_print(f"  YOLO found: {len(yolo_detections)} detections")
            debug_print(f"  OCR found: {len(ocr_detections)} detections")
        
        # Store individual results
        results['yolo_detections'] = yolo_detections
        results['ocr_detections'] = ocr_detections
        
        # Merge detections
        merge_start = time.time()
        merged_detections, merge_stats = self.merger.merge_detections(yolo_detections, ocr_detections)
        merge_time = time.time() - merge_start
        
        results['merged_detections'] = merged_detections
        results['merge_stats'] = merge_stats
        
        # Create visualizations if enabled
        viz_time = 0
        if self.create_visualizations:
            viz_start = time.time()
            if self.enable_timing:
                debug_print(f"\nüé® Creating beautiful visualizations...")
            
            visualization_paths = self.visualizer.create_all_visualizations(image_path, results)
            results['visualization_paths'] = visualization_paths
            viz_time = time.time() - viz_start
            
            if self.enable_timing:
                debug_print(f"  Visualization creation: {viz_time:.3f}s")
        
        # Compile timing information
        total_time = time.time() - total_start
        results['timing'] = {
            'total_time': total_time,
            'parallel_detection_time': parallel_time,
            'merge_time': merge_time,
            'visualization_time': viz_time,
            'yolo_count': len(yolo_detections),
            'ocr_count': len(ocr_detections),
            'merged_count': len(merged_detections)
        }
        
        # Save results to files
        self._save_results(results, output_dir, image_path)
        
        if self.enable_timing:
            debug_print(f"\nüéâ Pipeline completed successfully!")
            debug_print(f"  Total time: {total_time:.3f}s")
            debug_print(f"  Parallel detection: {parallel_time:.3f}s ({parallel_time/total_time*100:.1f}%)")
            debug_print(f"  Merging: {merge_time:.3f}s ({merge_time/total_time*100:.1f}%)")
            if viz_time > 0:
                debug_print(f"  Visualizations: {viz_time:.3f}s ({viz_time/total_time*100:.1f}%)")
            debug_print(f"  Final result: {len(merged_detections)} detections")
            debug_print("=" * 80)
        
        return results
    
    def _save_results(self, results: Dict[str, Any], output_dir: str, image_path: str):
        """Save all results to JSON files"""
        if self.enable_timing:
            debug_print(f"\nüíæ Saving results to {output_dir}...")

        if not self.save_intermediate_results:
            return
        
        # Extract base name for file naming
        base_name = os.path.splitext(os.path.basename(image_path))[0]
        
        # Save YOLO results
        yolo_file = os.path.join(output_dir, f"{base_name}_yolo_result.json")
        with open(yolo_file, 'w') as f:
            json.dump({
                'image_path': image_path,
                'detections': results['yolo_detections'],
                'count': len(results['yolo_detections']),
                'source': 'yolo'
            }, f, indent=2)
        
        # Save OCR results
        ocr_file = os.path.join(output_dir, f"{base_name}_ocr_det_result.json")
        with open(ocr_file, 'w') as f:
            json.dump({
                'image_path': image_path,
                'detections': results['ocr_detections'],
                'count': len(results['ocr_detections']),
                'source': 'ocr_det'
            }, f, indent=2)
        
        # Save merged results
        merged_file = os.path.join(output_dir, f"{base_name}_merged_result.json")
        with open(merged_file, 'w') as f:
            json.dump({
                'image_path': image_path,
                'detections': results['merged_detections'],
                'count': len(results['merged_detections']),
                'source': 'merged',
                'merge_stats': results['merge_stats'],
                'timing': results['timing']
            }, f, indent=2)
        
        # Save complete results
        complete_file = os.path.join(output_dir, f"{base_name}_complete_results.json")
        with open(complete_file, 'w') as f:
            json.dump(results, f, indent=2)
        
        if self.enable_timing:
            debug_print(f"  ‚úÖ YOLO results: {yolo_file}")
            debug_print(f"  ‚úÖ OCR results: {ocr_file}")
            debug_print(f"  ‚úÖ Merged results: {merged_file}")
            debug_print(f"  ‚úÖ Complete results: {complete_file}")

    def assign_intelligent_ids(self, yolo_detections, ocr_detections):
        """Assign simple, clean IDs for pipeline tracking"""
        debug_print("üîñ Assigning simple, clean IDs for pipeline tracking...")
        
        # Assign YOLO IDs
        for i, detection in enumerate(yolo_detections):
            detection['y_id'] = f"Y{i+1:03d}"
        
        # Assign OCR IDs  
        for i, detection in enumerate(ocr_detections):
            detection['o_id'] = f"O{i+1:03d}"
        
        debug_print(f"  ‚úÖ Assigned {len(yolo_detections)} YOLO IDs (Y001-Y{len(yolo_detections):03d})")
        debug_print(f"  ‚úÖ Assigned {len(ocr_detections)} OCR IDs (O001-O{len(ocr_detections):03d})")
        
        return yolo_detections, ocr_detections

==================================================

Path: utils\seraphine_pipeline\pipeline_exporter.py
File: pipeline_exporter.py
Code:
"""
Pipeline Export Utility
Handles JSON export and data structure creation for the enhanced pipeline
"""
import os
import json
from datetime import datetime
from .helpers import debug_print
from typing import Dict, List

def create_enhanced_seraphine_structure(seraphine_analysis: Dict, merged_detections: List[Dict]) -> Dict:
    """Create enhanced structure with proper ID mapping for fDOM compatibility"""
    
    bbox_processor = seraphine_analysis.get('bbox_processor')
    group_details = seraphine_analysis.get('analysis', {}).get('group_details', {})
    
    if not bbox_processor or not hasattr(bbox_processor, 'final_groups'):
        return {}
    
    seraphine_structure = {}
    
    for group_id, bboxes in bbox_processor.final_groups.items():
        # Get group-level information (including explore flag)
        group_info = group_details.get(group_id, {})
        group_explore = group_info.get('explore', True)  # Get explore from group level
        group_name = group_info.get('groups_name', 'Unknown')
        
        group_elements = {}
        
        for i, bbox in enumerate(bboxes):
            element_id = f"{group_id}_{i+1}"
            
            # Find matching detection for proper ID mapping
            matching_detection = None
            for detection in merged_detections:
                if detection.get('merged_id') == bbox.merged_id:
                    matching_detection = detection
                    break
            
            element_data = {
                'bbox': [bbox.x1, bbox.y1, bbox.x2, bbox.y2],
                'g_icon_name': getattr(bbox, 'g_icon_name', 'Unknown'),
                'g_brief': getattr(bbox, 'g_brief', 'No description'),
                'g_enabled': getattr(bbox, 'g_enabled', True),
                'g_interactive': getattr(bbox, 'g_interactive', True),
                'g_type': getattr(bbox, 'g_type', 'icon'),
                'explore': group_explore,  # NEW: Pass group explore down to element
                'm_id': matching_detection.get('merged_id') if matching_detection else None,
                'y_id': matching_detection.get('id') if matching_detection and matching_detection.get('source') == 'yolo' else None,
                'o_id': matching_detection.get('id') if matching_detection and matching_detection.get('source') == 'ocr_det' else None,
                'type': matching_detection.get('type', 'icon') if matching_detection else 'icon',
                'source': matching_detection.get('source', 'unknown') if matching_detection else 'unknown'
            }
            
            group_elements[element_id] = element_data
        
        if group_elements:  # Only add non-empty groups
            seraphine_structure[group_id] = group_elements
    
    return seraphine_structure

def save_enhanced_pipeline_json(image_path, detection_results, seraphine_analysis, gemini_results, config):
    """
    Save ENHANCED pipeline JSON with Gemini integration
    """
    if not config.get("save_json", False):
        debug_print("\n‚è≠Ô∏è  JSON saving disabled in config")
        return None
    
    debug_print("\nüíæ Saving Enhanced Pipeline JSON (with Gemini)")
    debug_print("=" * 70)
    
    # Create enhanced seraphine structure with PROPER ID TRACKING!
    enhanced_seraphine_groups = create_enhanced_seraphine_structure(
        seraphine_analysis, 
        detection_results['merged_detections']  # ‚úÖ PASS ORIGINAL MERGED DETECTIONS!
    )
    
    # Choose the right field name based on Gemini success
    seraphine_field_name = "seraphine_gemini_groups" if gemini_results else "seraphine_groups"
    
    # Rest of save_pipeline_json logic but with enhanced structure
    output_dir = config.get("output_dir", "outputs")
    current_time = datetime.now().strftime("%d-%m")
    filename_base = os.path.splitext(os.path.basename(image_path))[0]
    
    analysis = seraphine_analysis['analysis']
    
    pipeline_results = {
        'pipeline_version': 'v1.2_enhanced_with_gemini',
        'timestamp': datetime.now().isoformat(),
        'image_info': {
            'filename': os.path.basename(image_path),
            'path': image_path
        },
        'detection_summary': {
            'yolo_count': len(detection_results['yolo_detections']),
            'ocr_count': len(detection_results['ocr_detections']),
            'merged_count': len(detection_results['merged_detections']),
            'total_input': len(detection_results['yolo_detections']) + len(detection_results['ocr_detections']),
            'merge_efficiency': f"{len(detection_results['yolo_detections']) + len(detection_results['ocr_detections']) - len(detection_results['merged_detections'])} removed"
        },
        'seraphine_summary': {
            'total_groups': analysis['total_groups'],
            'horizontal_groups': analysis['horizontal_groups'],
            'vertical_groups': analysis['vertical_groups'],
            'long_box_groups': analysis['long_box_groups'],
            'grouping_efficiency': analysis['grouping_efficiency']
        },
        'gemini_summary': {
            'enabled': bool(gemini_results),
            'total_icons_analyzed': gemini_results.get('total_icons_found', 0) if gemini_results else 0,
            'successful_analyses': gemini_results.get('successful_analyses', 0) if gemini_results else 0,
            'analysis_time': gemini_results.get('analysis_duration_seconds', 0) if gemini_results else 0
        },
        'timing_breakdown': {
            **detection_results['timing'],
            'seraphine_time': seraphine_analysis.get('seraphine_timing', 0),
            'gemini_time': gemini_results.get('analysis_duration_seconds', 0) if gemini_results else 0
        },
        'detections': {
            'yolo_detections': detection_results['yolo_detections'],
            'ocr_detections': detection_results['ocr_detections'], 
            'merged_detections': detection_results['merged_detections']
        },
        seraphine_field_name: enhanced_seraphine_groups  # DYNAMIC FIELD NAME!
    }
    
    # Add Gemini analysis metadata only if successful (avoid duplication)
    if gemini_results:
        pipeline_results['gemini_analysis_metadata'] = {
            'total_images_analyzed': gemini_results.get('total_images_analyzed', 0),
            'analysis_mode': gemini_results.get('analysis_mode', 'unknown'),
            'timestamp': gemini_results.get('analysis_timestamp')
        }
    
    # Save JSON file
    json_filename = f"{filename_base}_enhanced_v1_{current_time}.json"
    json_path = os.path.join(output_dir, json_filename)
    
    os.makedirs(output_dir, exist_ok=True)
    
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(pipeline_results, f, indent=2, ensure_ascii=False)
    
    debug_print(f"‚úÖ Enhanced Pipeline JSON saved: {json_filename}")
    debug_print(f"   üìä Complete pipeline with Gemini integration")
    debug_print(f"   üîó Perfect ID mapping: Y/O ‚Üí M ‚Üí Seraphine Groups ‚Üí Gemini Analysis")
    debug_print(f"   üéØ Field name: '{seraphine_field_name}' (dynamic based on Gemini success)")
    
    return json_path


==================================================

Path: utils\seraphine_pipeline\seraphine_generator.py
File: seraphine_generator.py
Code:
import os
import time
import glob
from typing import List, Dict, Any
from PIL import Image
from .helpers import debug_print

class FinalGroupImageGenerator:
    """
    Wrapper class that provides the same interface as the old GroupImageGenerator
    but uses the BBoxProcessor internally for image generation
    """
    
    def __init__(self, output_dir: str = "outputs", enable_timing: bool = True, enable_debug: bool = False, save_mapping: bool = True):
        self.output_dir = output_dir
        self.enable_timing = enable_timing
        self.enable_debug = enable_debug
        self.save_mapping = save_mapping
        os.makedirs(self.output_dir, exist_ok=True)
    
    def create_grouped_images(self, image_path: str, seraphine_analysis: Dict[str, Any], 
                            filename_base: str, return_direct_images: bool = False) -> List[str] | Dict[str, Any]:
        """
        Generate group images using the BBoxProcessor, filtering to only explore=True groups
        
        Args:
            image_path: Path to original image
            seraphine_analysis: Result from FinalSeraphineProcessor.process_detections()
            filename_base: Base filename for outputs
            return_direct_images: If True, returns PIL images directly for Gemini
            
        Returns:
            If return_direct_images=False: List of generated image file paths (original behavior)
            If return_direct_images=True: Dict with 'file_paths' and 'direct_images'
        """
        start_time = time.time()
        
        if self.enable_debug:
            debug_print(f"üñºÔ∏è  [FINAL GROUP GENERATOR] Generating images (direct_images={return_direct_images})...")
        
        # Get the BBoxProcessor from seraphine result
        bbox_processor = seraphine_analysis.get('bbox_processor')
        if not bbox_processor:
            raise ValueError("No bbox_processor found in seraphine_analysis")
        
        # ‚úÖ FILTER GROUPS TO ONLY EXPLORE=TRUE GROUPS
        original_final_groups = bbox_processor.final_groups.copy()
        group_details = seraphine_analysis.get('analysis', {}).get('group_details', {})
        
        # Filter to only groups where explore=True
        filtered_groups = {}
        explore_count = 0
        total_count = len(original_final_groups)
        
        # ‚úÖ ALWAYS SHOW FILTERING RESULTS (NOT JUST IN DEBUG MODE)
        print(f"[GENERATOR] üîç Filtering {total_count} groups based on explore=True...")
        
        for group_id, group_bboxes in original_final_groups.items():
            group_info = group_details.get(group_id, {})
            explore = group_info.get('explore', False)
            
            if explore:
                filtered_groups[group_id] = group_bboxes
                explore_count += 1
                group_name = group_info.get('groups_name', 'unnamed')
                print(f"[GENERATOR] ‚úÖ Including {group_id} ('{group_name}') - explore=True")
            # Only show skipped groups if in debug mode to avoid spam
            elif self.enable_debug:
                group_name = group_info.get('groups_name', 'unnamed')
                print(f"[GENERATOR] ‚è≠Ô∏è  Skipping {group_id} ('{group_name}') - explore=False")
        
        print(f"[GENERATOR] üîç Final result: {total_count} total groups ‚Üí {explore_count} explore=True groups")
        
        # Temporarily replace final_groups with filtered version
        bbox_processor.final_groups = filtered_groups
        
        # Load original image into processor
        try:
            bbox_processor.original_image = Image.open(image_path)
            if self.enable_debug:
                debug_print(f"üì∑ Loaded original image: {bbox_processor.original_image.size}")
        except Exception as e:
            debug_print(f"‚ùå Error loading original image: {e}")
            bbox_processor.original_image = None
        
        # Generate images
        os.makedirs(self.output_dir, exist_ok=True)
        
        try:
            if return_direct_images:
                # Generate with direct image return
                result = bbox_processor.generate_images(self.output_dir, return_images=True)
                
                # Create file path list for compatibility
                generated_files = result['saved_paths']
                
                # Save mapping only if enabled
                if self.save_mapping:
                    bbox_processor.save_mapping(self.output_dir)
                
                elapsed = time.time() - start_time
                if self.enable_timing:
                    debug_print(f"‚è±Ô∏è  Image generation (with direct return, {explore_count} groups): {elapsed:.3f}s")
                
                return {
                    'file_paths': generated_files,
                    'direct_images': [(img, filename) for img, filename, _ in result['generated_images']],
                    'image_count': result['image_count'],
                    'filtered_group_count': explore_count,
                    'total_group_count': total_count
                }
            else:
                # Original behavior - just save files
                bbox_processor.generate_images(self.output_dir)
                if self.save_mapping:
                    bbox_processor.save_mapping(self.output_dir)
                
                # Return list of generated image paths (compatible with old interface)
                generated_files = []
                pattern = os.path.join(self.output_dir, "combined_groups_*.png")
                generated_files.extend(glob.glob(pattern))
                
                # Add annotated image if it exists
                annotated_path = os.path.join(self.output_dir, "annotated_original_image.png")
                if os.path.exists(annotated_path):
                    generated_files.append(annotated_path)
                
                elapsed = time.time() - start_time
                if self.enable_timing:
                    debug_print(f"‚è±Ô∏è  Image generation ({explore_count} groups): {elapsed:.3f}s")
                
                return generated_files
        
        finally:
            # ‚úÖ RESTORE ORIGINAL GROUPS (important for other parts of pipeline)
            bbox_processor.final_groups = original_final_groups


==================================================

Path: utils\seraphine_pipeline\seraphine_preprocessor.py
File: seraphine_preprocessor.py
Code:
"""
Seraphine Pre-Processor
Creates group visualization overlay on original screenshots
Integrates with seraphine_processor.py to visualize detected groups
Calls Gemini for supergroup analysis
"""

import os
import asyncio
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import cv2
import numpy as np
from PIL import Image
import argparse

# Gemini imports
try:
    from google import genai
    from google.genai.errors import ServerError
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("‚ö†Ô∏è  Warning: google-genai not installed. Gemini analysis will be skipped.")

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    print("‚ö†Ô∏è  Warning: python-dotenv not installed. Make sure GEMINI_API_KEY is set manually.")


def create_group_visualization(final_groups: Dict, original_image_path: str, 
                             output_dir: str = "outputs", app_name: str = "app") -> str:
    """
    Create group visualization overlay on original screenshot using EXACT labeling from postprocessor
    
    Args:
        final_groups: Dictionary of groups from seraphine_processor (e.g., {'H0': [bbox1, bbox2], 'V1': [bbox3]})
        original_image_path: Path to S001.png screenshot  
        output_dir: Output directory for saving result
        app_name: App name for filename
        
    Returns:
        Path to saved visualization image
    """    
    # Load original image using cv2 (same as postprocessor)
    try:
        image = cv2.imread(original_image_path)
        if image is None:
            raise ValueError(f"Could not load image: {original_image_path}")
        
        img_height, img_width = image.shape[:2]
        # print(f"[PREPROCESSOR] Loaded image: {img_width}x{img_height}")
    except Exception as e:
        print(f"[PREPROCESSOR ERROR] Failed to load image: {e}")
        return ""
    
    # ‚úÖ PRE-CALCULATE ALL GROUP BOUNDS to avoid label conflicts
    all_group_bounds = {}
    for group_id, bboxes in final_groups.items():
        if bboxes:
            all_group_bounds[group_id] = _calculate_group_bounds(bboxes)
    
    # ‚úÖ EXACT SAME COLOR PALETTE as postprocessor
    group_colors = [
        (255, 0, 0),      # Red
        (0, 255, 0),      # Green
        (0, 0, 255),      # Blue
        (255, 0, 255),    # Magenta
        (0, 255, 255),    # Cyan
        (255, 165, 0),    # Orange
        (128, 0, 128),    # Purple
        (255, 192, 203),  # Pink
        (0, 128, 0),      # Dark Green
        (128, 128, 0),    # Olive
        (0, 0, 128),      # Navy
        (128, 0, 0),      # Maroon
        (0, 128, 128),    # Teal
        (220, 220, 220),  # Silver 
        (255, 20, 147),   # Deep Pink
        (50, 205, 50),    # Lime Green
        (255, 140, 0),    # Dark Orange
        (138, 43, 226),   # Blue Violet
        (220, 20, 60),    # Crimson
        (55, 55, 0),      # Yellow
        (0, 0, 0),        # Black
        (139, 69, 19),    # Saddle Brown
        (255, 69, 0),     # Orange Red
        (75, 0, 130),     # Indigo
        (0, 100, 0),      # Forest Green
        (233, 150, 122),  # Dark Salmon
        (255, 215, 0),    # Gold
        (0, 191, 255),    # Deep Sky Blue
        (34, 139, 34),    # Forest Green (darker)
        (218, 112, 214),  # Orchid
        (255, 105, 180),  # Hot Pink
        (47, 79, 79),     # Dark Slate Gray
        (255, 99, 71),    # Tomato
        (72, 61, 139),    # Dark Slate Blue
        (154, 205, 50),   # Yellow Green
        (128, 0, 255),    # Violet
        (255, 0, 127),    # Rose
        (0, 255, 127),    # Spring Green
        (64, 224, 208),   # Turquoise
        (184, 134, 11),   # Dark Goldenrod
    ]
    
    # ‚úÖ EXACT SAME DRAWING PARAMETERS as postprocessor
    font = cv2.FONT_HERSHEY_DUPLEX
    text_scale = 0.4
    thickness = 2  # Thin 1px lines
    text_thickness = 1
    
    # Track label positions to avoid overlaps (same as postprocessor)
    existing_labels = []
    color_idx = 0
    processed_groups = 0
    
    # ‚úÖ PHASE 1: DRAW ALL RECTANGLES FIRST
    for group_id, bboxes in final_groups.items():
        if not bboxes:  # Skip empty groups
            continue
            
        # Get color (RGB to BGR conversion same as postprocessor)
        color_rgb = group_colors[color_idx % len(group_colors)]
        color_bgr = (color_rgb[2], color_rgb[1], color_rgb[0])  # RGB to BGR
        color_idx += 1
                
        # ‚úÖ EXACT SAME GROUP BOUNDS CALCULATION as postprocessor
        group_bbox = _calculate_group_bounds(bboxes)
        x1, y1, x2, y2 = group_bbox
        
        if x1 == x2 or y1 == y2:  # Invalid bbox
            continue
        
        # ‚úÖ DRAW RECTANGLE ONLY
        cv2.rectangle(image, (x1, y1), (x2, y2), color_bgr, thickness)
    
    # ‚úÖ PHASE 2: DRAW ALL LABELS ON TOP
    color_idx = 0  # Reset color index
    existing_labels = []  # Reset label tracking
    
    for group_id, bboxes in final_groups.items():
        if not bboxes:  # Skip empty groups
            continue
            
        # Get same color as rectangle
        color_rgb = group_colors[color_idx % len(group_colors)]
        color_bgr = (color_rgb[2], color_rgb[1], color_rgb[0])  # RGB to BGR
        color_idx += 1
                
        # ‚úÖ EXACT SAME GROUP BOUNDS CALCULATION as postprocessor
        group_bbox = _calculate_group_bounds(bboxes)
        x1, y1, x2, y2 = group_bbox
        
        if x1 == x2 or y1 == y2:  # Invalid bbox
            continue
        
        # ‚úÖ GET OTHER GROUP BOUNDS (exclude current group)
        other_group_bounds = [bounds for gid, bounds in all_group_bounds.items() if gid != group_id]
        
        # ‚úÖ FIND OPTIMAL LABEL POSITION
        label_x, label_y = _find_optimal_label_position(
            group_bbox, group_id, font, text_scale, 
            img_width, img_height, existing_labels, other_group_bounds
        )
        
        # ‚úÖ DRAW LABEL BACKGROUND AND TEXT
        (text_w, text_h), _ = cv2.getTextSize(group_id, font, text_scale, text_thickness)
        
        bg_padding = 3
        bg_x1 = label_x - bg_padding
        bg_y1 = label_y - text_h - bg_padding
        bg_x2 = label_x + text_w + bg_padding
        bg_y2 = label_y + bg_padding
        
        # Draw colored background
        cv2.rectangle(image, (bg_x1, bg_y1), (bg_x2, bg_y2), color_bgr, cv2.FILLED)
        # Draw white border
        # cv2.rectangle(image, (bg_x1, bg_y1), (bg_x2, bg_y2), (220, 220, 220), 1)
        
        # ‚úÖ DRAW TEXT ON TOP
        cv2.putText(image, group_id, (label_x, label_y), font, text_scale, 
                   (255, 255, 255), text_thickness, cv2.LINE_AA)
        
        # Track this label position
        label_rect = (bg_x1, bg_y1, bg_x2, bg_y2)
        existing_labels.append(label_rect)
        
        processed_groups += 1
    
    # Save the result
    os.makedirs(output_dir, exist_ok=True)
    output_filename = f"{app_name}_seraphine_groups.png"
    output_path = os.path.join(output_dir, output_filename)
    
    cv2.imwrite(output_path, image)
    # print(f"[PREPROCESSOR] Saved group visualization: {output_path} ({processed_groups} groups)")
    
    # Return path for later Gemini analysis by the main pipeline
    return output_path


def _load_preprocessor_prompt() -> str:
    """Load the supergroup analysis prompt from preprocessor_prompt.txt"""
    module_dir = os.path.dirname(os.path.abspath(__file__))
    prompt_path = os.path.join(module_dir, "preprocessor_prompt.txt")
    
    try:
        with open(prompt_path, "r", encoding="utf-8") as f:
            prompt_content = f.read().strip()
        # print(f"[PREPROCESSOR] ‚úÖ Loaded prompt ({len(prompt_content)} characters)")
        return prompt_content
    except FileNotFoundError:
        print(f"[PREPROCESSOR ERROR] Prompt file not found: {prompt_path}")
        return ""


# Add a separate async function for the pipeline to call
async def analyze_supergroups_with_gemini(image_path: str) -> Optional[str]:
    """Analyze the group visualization image with Gemini (to be called by async pipeline)"""
    
    if not GEMINI_AVAILABLE:
        print(f"[PREPROCESSOR] ‚ö†Ô∏è  Skipping Gemini analysis (not available)")
        return None
        
    # Load prompt
    prompt = _load_preprocessor_prompt()
    if not prompt:
        return None
    
    # Initialize Gemini client
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        print(f"[PREPROCESSOR ERROR] GEMINI_API_KEY not found in environment variables")
        return None
    
    client = genai.Client(api_key=api_key)
    
    try:
        # Load image with debugging
        image = Image.open(image_path)
        # ‚úÖ SCALE SMALL IMAGES FOR BETTER GEMINI ANALYSIS
        width, height = image.size
        if width < 200 and height < 200:
            # Scale maintaining aspect ratio - make larger dimension 400px
            scale_factor = 400 / max(width, height)
            new_width = int(width * scale_factor)
            new_height = int(height * scale_factor)
            
            # Resize using high-quality resampling
            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            print(f"[PREPROCESSOR DEBUG] ‚úÖ Scaled small image: {width}x{height} ‚Üí {new_width}x{new_height}")
        else:
            print(f"[PREPROCESSOR DEBUG] Image size OK: {width}x{height}, no scaling needed")
        
        # Call Gemini API
        response = await client.aio.models.generate_content(
            model="gemini-2.0-flash-exp",
            contents=[prompt, image],
        )
        
        # # Print raw results on console
        # print(f"\n{'='*80}")
        # print(f"ü§ñ GEMINI SUPERGROUP ANALYSIS RESULTS")
        # print(f"{'='*80}")
        # print(response.text)
        # print(f"{'='*80}\n")
        
        return response.text
        
    except ServerError as e:
        print(f"[PREPROCESSOR ERROR] Gemini server error: {e}")
        return None
    except Exception as e:
        print(f"[PREPROCESSOR ERROR] Gemini analysis error: {e}")
        return None


def _calculate_group_bounds(bboxes) -> Tuple[int, int, int, int]:
    """Calculate bounding box that encompasses all bboxes in a group (same as postprocessor)"""
    if not bboxes:
        return 0, 0, 0, 0
    
    # Collect all coordinates
    x1_coords, y1_coords, x2_coords, y2_coords = [], [], [], []
    
    for bbox in bboxes:
        x1, y1, x2, y2 = bbox.x1, bbox.y1, bbox.x2, bbox.y2
        x1_coords.append(x1)
        y1_coords.append(y1)
        x2_coords.append(x2)
        y2_coords.append(y2)
    
    if not x1_coords:
        return 0, 0, 0, 0
    
    # Calculate extreme coordinates
    min_x = min(x1_coords)
    min_y = min(y1_coords)
    max_x = max(x2_coords)
    max_y = max(y2_coords)
    
    return min_x, min_y, max_x, max_y


def _find_optimal_label_position(group_bbox: Tuple[int, int, int, int], 
                               label: str, font, text_scale: float,
                               img_width: int, img_height: int,
                               existing_labels: List[Tuple],
                               other_group_bounds: List[Tuple]) -> Tuple[int, int]:
    """Find optimal position for group label to avoid overlaps AND other group boundaries"""
    x1, y1, x2, y2 = group_bbox
    
    # Calculate text dimensions
    (text_w, text_h), _ = cv2.getTextSize(label, font, text_scale, 1)
    
    # ‚úÖ EXACT SAME CANDIDATE POSITIONS as postprocessor
    candidate_positions = [
        (x1, y1 - 0),                    # Above top-left
        (x1, y2 + text_h + 0),           # Below bottom-left
        (x2 - text_w, y1 - 0),           # Above top-right
        (x2 - text_w, y2 + text_h + 0),  # Below bottom-right
        (x1 + 0, y1 + text_h + 0),        # Inside top-left
        (x2 - text_w - 0, y1 + text_h + 0), # Inside top-right
    ]
    
    for text_x, text_y in candidate_positions:
        # Check bounds
        if (text_x >= 0 and text_y >= text_h and 
            text_x + text_w <= img_width and text_y <= img_height):
            
            # Check overlap with existing labels
            label_rect = (text_x, text_y - text_h, text_x + text_w, text_y)
            overlap = False
            
            for existing_rect in existing_labels:
                if _rectangles_overlap(label_rect, existing_rect):
                    overlap = True
                    break
            
            if not overlap:
                return text_x, text_y
    
    # Fallback: use first position even if it overlaps
    return candidate_positions[0]


def _rectangles_overlap(rect1: Tuple, rect2: Tuple) -> bool:
    """Check if two rectangles overlap (EXACT COPY from postprocessor)"""
    x1_1, y1_1, x2_1, y2_1 = rect1
    x1_2, y1_2, x2_2, y2_2 = rect2
    
    return not (x2_1 < x1_2 or x2_2 < x1_1 or y2_1 < y1_2 or y2_2 < y1_1)


def integrate_supergroup_analysis(seraphine_analysis: Dict, supergroup_analysis_text: str) -> Dict:
    """
    Integrate supergroup analysis results into the existing seraphine analysis structure
    Updates group_details with explore, navigation, state_change, file_loader, metadata, and groups_name fields
    Then processes merge suggestions as the final step
    
    Args:
        seraphine_analysis: Original seraphine analysis with 'analysis' section
        supergroup_analysis_text: Raw Gemini JSON response text
        
    Returns:
        Updated seraphine_analysis with integrated supergroup information and merges applied
    """
    print(f"[PREPROCESSOR] üîÑ Integrating enriched supergroup analysis into seraphine structure...")
    
    try:
        import json
        import re
        
        # Extract JSON from the response (handle ```json wrapper)
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', supergroup_analysis_text, re.DOTALL)
        if json_match:
            json_text = json_match.group(1)
        else:
            # Try to find JSON without wrapper
            json_text = supergroup_analysis_text.strip()
        
        supergroup_data = json.loads(json_text)
        print(f"[PREPROCESSOR] ‚úÖ Parsed supergroup JSON successfully")
        
        # ‚úÖ EXTRACT ALL CATEGORIES WITH GROUP NAMES
        groups_to_explore = {item.get('group_id'): item.get('group_name', 'explore') 
                           for item in supergroup_data.get('groups_to_explore', [])}
        
        groups_causing_navigation = {item.get('group_id'): item.get('group_name', 'navigation') 
                                   for item in supergroup_data.get('groups_causing_navigation', [])}
        
        groups_causing_state_change = {item.get('group_id'): item.get('group_name', 'state_change') 
                                     for item in supergroup_data.get('groups_causing_state_change', [])}
        
        file_loader_zones = {item.get('group_id'): item.get('group_name', 'file_loader') 
                           for item in supergroup_data.get('file_loader_zones', [])}
        
        file_metadata_zones = {item.get('group_id'): item.get('group_name', 'metadata') 
                             for item in supergroup_data.get('file_metadata_zones', [])}
        
        # Handle primary_interaction_zone (single object, not list)
        primary_interaction_zone = {}
        primary_zone = supergroup_data.get('primary_interaction_zone', {})
        if primary_zone and 'id' in primary_zone:
            primary_interaction_zone[primary_zone['id']] = "primary_interaction"
        
        # Handle groups_to_ignore (can have group_ids list or single group_id)
        groups_to_ignore_list = supergroup_data.get('groups_to_ignore', [])
        groups_to_ignore = set()
        for item in groups_to_ignore_list:
            if 'group_ids' in item:
                groups_to_ignore.update(item['group_ids'])
            elif 'group_id' in item:
                groups_to_ignore.add(item['group_id'])
        
        # ‚úÖ EXTRACT MERGE SUGGESTIONS (FIXED - look in correct location)
        merge_suggestions = []
        merge_suggestions_data = supergroup_data.get('merge_suggestions', [])
        for item in merge_suggestions_data:
            if 'merge_ids' in item:
                merge_suggestions.append({
                    'merge_ids': item['merge_ids'],
                    'group_name': item.get('group_name', 'merged_group'),
                    'reason': item.get('reason', 'Merge suggested by Gemini')
                })
        
        # ‚úÖ CREATE SETS FOR BOOLEAN LOGIC (FIXED - ensure variables are created)
        navigation_groups = set(groups_causing_navigation.keys()) if groups_causing_navigation else set()
        state_change_groups = set(groups_causing_state_change.keys()) if groups_causing_state_change else set()
        file_loader_groups = set(file_loader_zones.keys()) if file_loader_zones else set()
        metadata_groups = set(file_metadata_zones.keys()) if file_metadata_zones else set()
        primary_groups = set(primary_interaction_zone.keys()) if primary_interaction_zone else set()
        explore_groups = set(groups_to_explore.keys()) if groups_to_explore else set()
        
        # Action categories that make explore = true (unless overridden)
        action_groups = (explore_groups | navigation_groups | state_change_groups | 
                        file_loader_groups | primary_groups)
        
        # Override groups that NEVER get explore = true
        override_groups = groups_to_ignore | metadata_groups
        
        # Create a deep copy of seraphine_analysis to avoid modifying original
        updated_analysis = seraphine_analysis.copy()
        updated_analysis['analysis'] = seraphine_analysis['analysis'].copy()
        updated_analysis['analysis']['group_details'] = seraphine_analysis['analysis']['group_details'].copy()
        
        # ‚úÖ STEP 1: UPDATE EACH GROUP WITH BOOLEAN FIELDS
        groups_updated = 0
        explore_true_count = 0
        explore_false_count = 0
        
        for group_id, group_info in updated_analysis['analysis']['group_details'].items():
            # Create a copy of group_info to avoid modifying original
            updated_group_info = group_info.copy()
            
            # ‚úÖ EXPLORE LOGIC WITH OVERRIDE RULE
            if group_id in override_groups:
                # OVERRIDE: Never explore if in ignore or metadata zones
                updated_group_info['explore'] = False
                explore_false_count += 1
            elif group_id in action_groups:
                # Action categories get explore = true
                updated_group_info['explore'] = True
                explore_true_count += 1
            else:
                # Unclassified groups
                updated_group_info['explore'] = False
                explore_false_count += 1
            
            # ‚úÖ INDIVIDUAL BOOLEAN FIELDS
            updated_group_info['navigation'] = group_id in navigation_groups
            updated_group_info['state_change'] = group_id in state_change_groups
            updated_group_info['file_loader'] = group_id in file_loader_groups
            updated_group_info['metadata'] = group_id in metadata_groups
            
            # ‚úÖ GROUP NAME WITH PRIORITY LOGIC
            if group_id in groups_to_explore:
                updated_group_info['groups_name'] = groups_to_explore[group_id]
            elif group_id in groups_causing_navigation:
                updated_group_info['groups_name'] = groups_causing_navigation[group_id]
            elif group_id in groups_causing_state_change:
                updated_group_info['groups_name'] = groups_causing_state_change[group_id]
            elif group_id in file_loader_zones:
                updated_group_info['groups_name'] = file_loader_zones[group_id]
            elif group_id in file_metadata_zones:
                updated_group_info['groups_name'] = file_metadata_zones[group_id]
            elif group_id in primary_interaction_zone:
                updated_group_info['groups_name'] = primary_interaction_zone[group_id]
            elif group_id in groups_to_ignore:
                updated_group_info['groups_name'] = "ignore"
            else:
                updated_group_info['groups_name'] = "unclassified"
            
            # Update the group_details
            updated_analysis['analysis']['group_details'][group_id] = updated_group_info
            groups_updated += 1
        
        # ‚úÖ STEP 2: PROCESS MERGE SUGGESTIONS (FINAL STEP)
        merges_processed = 0
        groups_merged = 0
        
        # ‚úÖ GET BBOX_PROCESSOR REFERENCE FOR SYNCHRONIZATION
        bbox_processor = updated_analysis.get('bbox_processor')
        
        for merge_suggestion in merge_suggestions:
            merge_ids_str = merge_suggestion['merge_ids']
            suggested_name = merge_suggestion['group_name']
            
            # Parse merge_ids (e.g., "H45, V0" ‚Üí ["H45", "V0"])
            group_ids_to_merge = [gid.strip() for gid in merge_ids_str.split(',')]
            
            # Find groups that exist in our analysis
            groups_to_merge = {}
            for gid in group_ids_to_merge:
                if gid in updated_analysis['analysis']['group_details']:
                    groups_to_merge[gid] = updated_analysis['analysis']['group_details'][gid]
            
            if len(groups_to_merge) < 2:
                print(f"[PREPROCESSOR] ‚ö†Ô∏è  Merge {merge_ids_str}: Only {len(groups_to_merge)} groups found, skipping")
                continue
            
            # ‚úÖ FIND LARGEST GROUP (by bbox area)
            largest_group_id = None
            largest_area = 0
            
            for gid, group_info in groups_to_merge.items():
                bboxes = group_info.get('bboxes', [])
                if bboxes:
                    # Calculate total area of all bboxes in this group
                    total_area = 0
                    for bbox in bboxes:
                        bbox_coords = bbox.get('bbox', [0, 0, 0, 0])
                        if len(bbox_coords) >= 4:
                            width = bbox_coords[2] - bbox_coords[0]
                            height = bbox_coords[3] - bbox_coords[1]
                            total_area += width * height
                    
                    if total_area > largest_area:
                        largest_area = total_area
                        largest_group_id = gid
            
            if not largest_group_id:
                print(f"[PREPROCESSOR] ‚ö†Ô∏è  Merge {merge_ids_str}: No valid bboxes found, skipping")
                continue
            
            # ‚úÖ CREATE MERGED GROUP
            merged_group = groups_to_merge[largest_group_id].copy()
            
            # Collect all bboxes and calculate union bbox
            all_bboxes = []
            min_x1, min_y1 = float('inf'), float('inf')
            max_x2, max_y2 = float('-inf'), float('-inf')
            
            for gid, group_info in groups_to_merge.items():
                group_bboxes = group_info.get('bboxes', [])
                all_bboxes.extend(group_bboxes)
                
                for bbox in group_bboxes:
                    bbox_coords = bbox.get('bbox', [0, 0, 0, 0])
                    if len(bbox_coords) >= 4:
                        x1, y1, x2, y2 = bbox_coords
                        min_x1 = min(min_x1, x1)
                        min_y1 = min(min_y1, y1)
                        max_x2 = max(max_x2, x2)
                        max_y2 = max(max_y2, y2)
            
            # ‚úÖ OR ALL BOOLEAN FIELDS
            merged_explore = any(groups_to_merge[gid].get('explore', False) for gid in groups_to_merge)
            merged_navigation = any(groups_to_merge[gid].get('navigation', False) for gid in groups_to_merge)
            merged_state_change = any(groups_to_merge[gid].get('state_change', False) for gid in groups_to_merge)
            merged_file_loader = any(groups_to_merge[gid].get('file_loader', False) for gid in groups_to_merge)
            merged_metadata = any(groups_to_merge[gid].get('metadata', False) for gid in groups_to_merge)
            
            # ‚úÖ UPDATE MERGED GROUP
            merged_group.update({
                'group_id': largest_group_id,  # Keep largest group's ID
                'size': len(all_bboxes),
                'bboxes': all_bboxes,
                'groups_name': suggested_name,  # Use Gemini's suggestion
                'explore': merged_explore,
                'navigation': merged_navigation,
                'state_change': merged_state_change,
                'file_loader': merged_file_loader,
                'metadata': merged_metadata,
                'merged_from': list(groups_to_merge.keys()),  # Track original groups
                'merge_reason': merge_suggestion.get('reason', '')
            })
            
            # ‚úÖ UPDATE bbox_processor.final_groups TO MATCH
            if bbox_processor and hasattr(bbox_processor, 'final_groups'):
                # Collect all bboxes from groups to merge
                merged_bboxes = []
                for gid in groups_to_merge:
                    if gid in bbox_processor.final_groups:
                        merged_bboxes.extend(bbox_processor.final_groups[gid])
                
                # Update the largest group with merged bboxes
                if merged_bboxes:  # Only update if we have bboxes
                    bbox_processor.final_groups[largest_group_id] = merged_bboxes
                    print(f"[PREPROCESSOR] üîó Updated bbox_processor.final_groups[{largest_group_id}] with {len(merged_bboxes)} bboxes")
                else:
                    print(f"[PREPROCESSOR] ‚ö†Ô∏è  No bboxes found to merge for {largest_group_id}")
                
                # Delete the other groups from final_groups
                for gid in groups_to_merge:
                    if gid != largest_group_id and gid in bbox_processor.final_groups:
                        del bbox_processor.final_groups[gid]
                        print(f"[PREPROCESSOR] üóëÔ∏è  Deleted group {gid} from bbox_processor.final_groups")
            else:
                print(f"[PREPROCESSOR] ‚ö†Ô∏è  bbox_processor or final_groups not available for synchronization")
            
            for gid in groups_to_merge:
                if gid != largest_group_id:
                    del updated_analysis['analysis']['group_details'][gid]
                    groups_merged += 1
            
            merges_processed += 1
            print(f"[PREPROCESSOR] ‚úÖ Merged {merge_ids_str} ‚Üí {largest_group_id} ('{suggested_name}')")
        
        # ‚úÖ EXTRACT SPLASH SCREEN AND STARTUP INTERACTION DATA
        splash_screen_data = supergroup_data.get('splash_screen', {})
        startup_interaction_data = supergroup_data.get('startup_interaction', {})
        
        # ‚úÖ ADD SPLASH SCREEN DATA TO ANALYSIS
        updated_analysis['analysis']['splash_screen'] = splash_screen_data
        updated_analysis['analysis']['startup_interaction'] = startup_interaction_data
        
        print(f"[PREPROCESSOR] ‚úÖ Updated {groups_updated} groups with enriched supergroup analysis")
        print(f"[PREPROCESSOR]    üìä Groups to explore: {len(explore_groups)} ‚Üí Final explore=true: {explore_true_count}")
        print(f"[PREPROCESSOR]    üö´ Groups to ignore: {len(groups_to_ignore)} ‚Üí Final explore=false: {explore_false_count}")
        print(f"[PREPROCESSOR]    üéØ Primary interaction groups: {len(primary_groups)}")
        print(f"[PREPROCESSOR]    üñ±Ô∏è Splash screen present: {splash_screen_data.get('present', False)}")
        print(f"[PREPROCESSOR]    üîÑ Startup interaction required: {startup_interaction_data.get('required', False)}")
        print(f"[PREPROCESSOR]    üîó Merges processed: {merges_processed}, Groups merged: {groups_merged}")
        
        return updated_analysis
        
    except json.JSONDecodeError as e:
        print(f"[PREPROCESSOR ERROR] Failed to parse supergroup JSON: {e}")
        print(f"[PREPROCESSOR ERROR] Raw response: {supergroup_analysis_text[:200]}...")
        return seraphine_analysis
    except Exception as e:
        print(f"[PREPROCESSOR ERROR] Failed to integrate supergroup analysis: {e}")
        import traceback
        traceback.print_exc()
        return seraphine_analysis


def main():
    """Command-line interface for testing"""
    parser = argparse.ArgumentParser(description='Seraphine Group Visualizer')
    parser.add_argument('--app-name', required=True, help='App name (e.g., notepad)')
    args = parser.parse_args()
    
    app_name = args.app_name
    app_dir = Path("apps") / app_name
    fdom_path = app_dir / "fdom.json"
    screenshot_path = app_dir / "S001.png"
    
    print(f"[PREPROCESSOR] Testing with app: {app_name}")
    print(f"[PREPROCESSOR] fDOM path: {fdom_path}")
    print(f"[PREPROCESSOR] Screenshot path: {screenshot_path}")
    
    if not fdom_path.exists():
        print(f"[PREPROCESSOR ERROR] fDOM file not found: {fdom_path}")
        return
        
    if not screenshot_path.exists():
        print(f"[PREPROCESSOR ERROR] Screenshot not found: {screenshot_path}")
        return
    
    # For testing, we'd need to parse fDOM and create mock groups
    # This is just a placeholder for the command-line interface
    print(f"[PREPROCESSOR] Command-line testing not implemented yet")
    print(f"[PREPROCESSOR] This function will be called from seraphine_processor.py")


if __name__ == "__main__":
    main()


==================================================

Path: utils\seraphine_pipeline\seraphine_processor.py
File: seraphine_processor.py
Code:
import json
import logging
from typing import List, Dict, Tuple, Optional, Any
from dataclasses import dataclass
from PIL import Image, ImageDraw, ImageFont
import os
import random
import math
import time
import tempfile
from .helpers import debug_print
import numpy as np

@dataclass
class BBox:
    x1: int
    y1: int
    x2: int
    y2: int
    original_id: int
    merged_id: int
    bbox_type: str
    source: str
    confidence: float
    
    @property
    def width(self) -> int:
        return self.x2 - self.x1
    
    @property
    def height(self) -> int:
        return self.y2 - self.y1
    
    @property
    def center_x(self) -> float:
        return (self.x1 + self.x2) / 2
    
    @property
    def center_y(self) -> float:
        return (self.y1 + self.y2) / 2
    
    @property
    def right_edge_center(self) -> float:
        return (self.y1 + self.y2) / 2

class BBoxProcessor:
    def __init__(self, enable_logging: bool = True):
        self.enable_logging = enable_logging
        self.setup_logging()
        
        # Global variables
        self.all_bboxes: List[BBox] = []
        self.sort_x_list: List[BBox] = []
        self.sort_y_list: List[BBox] = []
        self.long_boxes: List[Tuple[BBox, str]] = []  # (bbox, 'H'/'V')
        self.horizontal_groups: Dict[int, List[BBox]] = {}
        self.vertical_groups: Dict[int, List[BBox]] = {}
        self.final_groups: Dict[str, List[BBox]] = {}
        self.bbox_to_group_mapping: Dict[int, str] = {}  # original_id -> group_id
        self.group_colors: Dict[str, Tuple[int, int, int]] = {}  # group_id -> RGB color
        self.original_image: Optional[Image.Image] = None
        self.long_box_ids: set = set()
        
        # Constants
        self.LONG_BOX_THRESHOLD = 600
        self.LONG_BOX_SCALE_MAX = 1100
        self.HORIZONTAL_TOLERANCE_PX = 20
        self.Y_VARIANCE_TOLERANCE = 8
        self.GROUP_GAP = 50
        self.BBOX_GAP = 25  # Base gap between bboxes
        self.MIN_DIMENSION = 40
        self.MAX_HEIGHT = 50
        self.PADDING = 20
        self.IMAGE_WIDTH = 1280
        self.IMAGE_HEIGHT = 1280
        self.BBOX_BORDER_WIDTH = 1
        
        # GLOBAL PARAMETERS FOR FIXES
        self.LABEL_FONT_SIZE = 18  # Doubled from 12
        self.LABEL_TOP_PADDING = 20  # Space above each image for labels
        self.BBOX_LABEL_GAP = 25  # Additional horizontal gap to accommodate wide labels
        self.LABEL_BACKGROUND = False  # Remove box around IDs
        self.EFFICIENT_PACKING_WIDTH = 1250  # If group width < this, try to pack next group on same row
        self.SAME_ROW_GAP = 40  # Gap between groups on same row
        self.INCLUDE_BBOX_COUNT_IN_FILENAME = True  # Whether to include bbox count in filenames
    
    def setup_logging(self):
        if self.enable_logging:
            logging.basicConfig(
                level=logging.INFO,
                format='%(asctime)s - %(levelname)s - %(message)s'
            )
            self.logger = logging.getLogger(__name__)
        else:
            self.logger = logging.getLogger(__name__)
            self.logger.disabled = True
    
    def log(self, message: str, level: str = 'info'):
        if self.enable_logging:
            getattr(self.logger, level)(message)
    
    def generate_group_colors(self):
        """Generate distinct colors for each group"""
        self.log("Generating colors for groups")
        
        # Predefined colors for better distinction
        predefined_colors = [
            (255, 0, 0),    # Red
            (0, 255, 0),    # Green
            (0, 0, 255),    # Blue
            (255, 255, 0),  # Yellow
            (255, 0, 255),  # Magenta
            (0, 255, 255),  # Cyan
            (255, 165, 0),  # Orange
            (128, 0, 128),  # Purple
            (255, 192, 203), # Pink
            (0, 128, 0),    # Dark Green
            (128, 128, 0),  # Olive
            (0, 0, 128),    # Navy
            (128, 0, 0),    # Maroon
            (0, 128, 128),  # Teal
            (192, 192, 192), # Silver
            (255, 20, 147), # Deep Pink
            (50, 205, 50),  # Lime Green
            (255, 140, 0),  # Dark Orange
            (138, 43, 226), # Blue Violet
            (220, 20, 60),  # Crimson
        ]
        
        color_index = 0
        for group_id in self.final_groups.keys():
            if color_index < len(predefined_colors):
                self.group_colors[group_id] = predefined_colors[color_index]
            else:
                # Generate random colors if we run out of predefined ones
                self.group_colors[group_id] = (
                    random.randint(50, 255),
                    random.randint(50, 255),
                    random.randint(50, 255)
                )
            color_index += 1
        
        self.log(f"Generated colors for {len(self.group_colors)} groups")
    
    def load_bboxes(self, json_file_path: str):
        """Step 1: Load all bboxes from JSON file"""
        self.log("Step 1: Loading bboxes from JSON file")
        
        with open(json_file_path, 'r') as f:
            data = json.load(f)
        
        for item in data:
            bbox = BBox(
                x1=item['bbox'][0],
                y1=item['bbox'][1],
                x2=item['bbox'][2],
                y2=item['bbox'][3],
                original_id=item['id'],
                merged_id=item['merged_id'],
                bbox_type=item['type'],
                source=item['source'],
                confidence=item['confidence']
            )
            self.all_bboxes.append(bbox)
        
        self.log(f"Loaded {len(self.all_bboxes)} bounding boxes")
    
    def sort_bboxes(self):
        """Step 2: Create two sorted lists"""
        self.log("Step 2: Sorting bboxes")
        
        # SORT_X: x-first, then y
        self.sort_x_list = sorted(self.all_bboxes, key=lambda b: (b.x1, b.y1))
        
        # SORT_Y: y-first, then x
        self.sort_y_list = sorted(self.all_bboxes, key=lambda b: (b.y1, b.x1))
        
        self.log(f"Created SORT_X list with {len(self.sort_x_list)} items")
        self.log(f"Created SORT_Y list with {len(self.sort_y_list)} items")
    
    def assign_sorted_ids(self):
        """Step 3: Assign IDs in sorted lists"""
        self.log("Step 3: Assigning sorted IDs")
        
        for i, bbox in enumerate(self.sort_x_list):
            bbox.sort_x_id = i
        
        for i, bbox in enumerate(self.sort_y_list):
            bbox.sort_y_id = i
        
        self.log("Assigned sorted IDs to all bboxes")
    
    def calculate_dimensions_and_identify_long_boxes(self):
        """Steps 4-5: Calculate dimensions and identify long boxes"""
        self.log("Steps 4-5: Calculating dimensions and identifying long boxes")
        
        remaining_bboxes = []
        
        for bbox in self.all_bboxes:
            width = bbox.width
            height = bbox.height
            
            if width > self.LONG_BOX_THRESHOLD or height > self.LONG_BOX_THRESHOLD:
                # Track this as a long box
                self.long_box_ids.add(bbox.merged_id)
                
                # Scale the long box
                if width > height:
                    # Horizontal long box
                    if width > self.LONG_BOX_SCALE_MAX:
                        scale_factor = self.LONG_BOX_SCALE_MAX / width
                        new_width = self.LONG_BOX_SCALE_MAX
                        new_height = int(height * scale_factor)
                        self.log(f"SCALING: Long box ID {bbox.merged_id} from {width}x{height} to {new_width}x{new_height} (scale: {scale_factor:.3f})")
                        bbox.x2 = bbox.x1 + new_width
                        bbox.y2 = bbox.y1 + new_height
                    self.long_boxes.append((bbox, 'H'))
                    self.log(f"Identified horizontal long box: ID {bbox.merged_id}, size {width}x{height}")
                else:
                    # Vertical long box
                    if height > self.LONG_BOX_SCALE_MAX:
                        scale_factor = self.LONG_BOX_SCALE_MAX / height
                        new_height = self.LONG_BOX_SCALE_MAX
                        new_width = int(width * scale_factor)
                        self.log(f"SCALING: Long box ID {bbox.merged_id} from {width}x{height} to {new_width}x{new_height} (scale: {scale_factor:.3f})")
                        bbox.x2 = bbox.x1 + new_width
                        bbox.y2 = bbox.y1 + new_height
                    self.long_boxes.append((bbox, 'V'))
                    self.log(f"Identified vertical long box: ID {bbox.merged_id}, size {width}x{height}")
            else:
                remaining_bboxes.append(bbox)
        
        # Update the main lists to exclude long boxes
        self.all_bboxes = remaining_bboxes
        self.sort_x_list = [b for b in self.sort_x_list if b in remaining_bboxes]
        self.sort_y_list = [b for b in self.sort_y_list if b in remaining_bboxes]
        
        self.log(f"Identified {len(self.long_boxes)} long boxes")
        self.log(f"Remaining {len(self.all_bboxes)} boxes for grouping")
    
    def calculate_overlap_aware_distance(self, bbox1: BBox, bbox2: BBox, direction: str) -> float:
        """
        Calculate overlap-aware distance between two bboxes
        Returns negative values for overlaps, positive for gaps
        """
        if direction == 'horizontal':
            # Check if boxes overlap horizontally
            if bbox1.x2 > bbox2.x1:  # Overlap
                overlap = bbox1.x2 - bbox2.x1
                return -overlap  # Negative distance = overlap
            else:  # Gap
                gap = bbox2.x1 - bbox1.x2
                return gap  # Positive distance = gap
        
        elif direction == 'vertical':
            # Check if boxes overlap vertically  
            if bbox1.y2 > bbox2.y1:  # Overlap
                overlap = bbox1.y2 - bbox2.y1
                return -overlap  # Negative distance = overlap
            else:  # Gap
                gap = bbox2.y1 - bbox1.y2
                return gap  # Positive distance = gap

    def horizontal_grouping(self):
        """FIXED: Horizontal grouping with overlap support"""
        self.log("Step 6: Performing horizontal grouping (overlap-aware)")
        
        used_boxes = set()
        group_id = 0
        
        for bbox in self.sort_x_list:
            if bbox.merged_id in used_boxes:
                continue
            
            current_group = [bbox]
            used_boxes.add(bbox.merged_id)
            current_bbox = bbox
            
            # Find horizontal neighbors
            for next_bbox in self.sort_x_list:
                if next_bbox.merged_id in used_boxes:
                    continue
                
                # Check if next box is horizontally aligned
                y_diff = abs(next_bbox.center_y - current_bbox.center_y)
                if y_diff <= self.Y_VARIANCE_TOLERANCE:
                    # FIXED: Use overlap-aware distance
                    distance = self.calculate_overlap_aware_distance(current_bbox, next_bbox, 'horizontal')
                    
                    # Allow small overlaps and reasonable gaps
                    max_overlap = min(current_bbox.width, next_bbox.width) * 0.3  # 30% overlap allowed
                    max_gap = min(self.HORIZONTAL_TOLERANCE_PX, current_bbox.width)
                    
                    if -max_overlap <= distance <= max_gap:  # Allows overlaps AND gaps
                        current_group.append(next_bbox)
                        used_boxes.add(next_bbox.merged_id)
                        current_bbox = next_bbox
                        
                        if distance < 0:
                            self.log(f"OVERLAP: Grouped overlapping boxes (overlap: {-distance:.1f}px)")
                        else:
                            self.log(f"GAP: Grouped boxes with gap (gap: {distance:.1f}px)")
            
            if len(current_group) > 0:
                self.horizontal_groups[group_id] = current_group
                self.log(f"Created horizontal group H{group_id} with {len(current_group)} boxes")
                group_id += 1
    
    def vertical_grouping(self):
        """FIXED: Vertical grouping with overlap support"""
        self.log("Step 7: Performing vertical grouping (overlap-aware)")
        
        used_boxes = set()
        group_id = 0
        
        for bbox in self.sort_y_list:
            if bbox.merged_id in used_boxes:
                continue
            
            current_group = [bbox]
            used_boxes.add(bbox.merged_id)
            current_bbox = bbox
            
            # Find vertical neighbors
            for next_bbox in self.sort_y_list:
                if next_bbox.merged_id in used_boxes:
                    continue
                
                # Check if next box is vertically aligned
                x_diff = abs(next_bbox.center_x - current_bbox.center_x)
                if x_diff <= self.HORIZONTAL_TOLERANCE_PX:
                    # FIXED: Use overlap-aware distance
                    distance = self.calculate_overlap_aware_distance(current_bbox, next_bbox, 'vertical')
                    
                    # Allow small overlaps and reasonable gaps
                    max_overlap = min(current_bbox.height, next_bbox.height) * 0.3  # 30% overlap allowed
                    max_gap = self.HORIZONTAL_TOLERANCE_PX
                    
                    if -max_overlap <= distance <= max_gap:  # Allows overlaps AND gaps
                        current_group.append(next_bbox)
                        used_boxes.add(next_bbox.merged_id)
                        current_bbox = next_bbox
                        
                        if distance < 0:
                            self.log(f"OVERLAP: Grouped overlapping boxes (overlap: {-distance:.1f}px)")
                        else:
                            self.log(f"GAP: Grouped boxes with gap (gap: {distance:.1f}px)")
            
            if len(current_group) > 0:
                self.vertical_groups[group_id] = current_group
                self.log(f"Created vertical group V{group_id} with {len(current_group)} boxes")
                group_id += 1
    
    def merge_groups(self):
        """Step 8: Merge groups and resolve conflicts"""
        self.log("Step 8: Merging groups and resolving conflicts")
        
        # Track which boxes appear in both H and V groups
        h_box_to_group = {}
        v_box_to_group = {}
        
        for group_id, boxes in self.horizontal_groups.items():
            for bbox in boxes:
                h_box_to_group[bbox.merged_id] = group_id
        
        for group_id, boxes in self.vertical_groups.items():
            for bbox in boxes:
                v_box_to_group[bbox.merged_id] = group_id
        
        # Find conflicts and resolve by group size
        conflicts = set()
        for box_id in h_box_to_group:
            if box_id in v_box_to_group:
                conflicts.add(box_id)
        
        # Resolve conflicts
        for box_id in conflicts:
            h_group_id = h_box_to_group[box_id]
            v_group_id = v_box_to_group[box_id]
            
            h_group_size = len(self.horizontal_groups[h_group_id])
            v_group_size = len(self.vertical_groups[v_group_id])
            
            if h_group_size >= v_group_size:
                # Keep in horizontal group
                self.vertical_groups[v_group_id] = [b for b in self.vertical_groups[v_group_id] 
                                                  if b.original_id != box_id]
            else:
                # Keep in vertical group
                self.horizontal_groups[h_group_id] = [b for b in self.horizontal_groups[h_group_id] 
                                                    if b.original_id != box_id]
        
        # Create final groups dictionary WITH SEQUENTIAL RENUMBERING
        h_count = 0
        v_count = 0
        
        # Add non-empty horizontal groups with sequential numbering
        for group_id, boxes in self.horizontal_groups.items():
            if boxes:  # Only add non-empty groups
                self.final_groups[f"H{h_count}"] = boxes  # Sequential: H0, H1, H2...
                self.log(f"Renumbered H{group_id} ‚Üí H{h_count} ({len(boxes)} boxes)")
                h_count += 1
        
        # Add non-empty vertical groups with sequential numbering  
        for group_id, boxes in self.vertical_groups.items():
            if boxes:  # Only add non-empty groups
                self.final_groups[f"V{v_count}"] = boxes  # Sequential: V0, V1, V2...
                self.log(f"Renumbered V{group_id} ‚Üí V{v_count} ({len(boxes)} boxes)")
                v_count += 1
        
        # Add long boxes as separate groups (sequential)
        for i, (bbox, orientation) in enumerate(self.long_boxes):
            self.final_groups[f"{orientation}L{i}"] = [bbox]
        
        # Generate colors for groups
        self.generate_group_colors()
        
        self.log(f"Created {len(self.final_groups)} final groups with sequential numbering")
        self.log(f"Final: {h_count} H groups (H0-H{h_count-1}), {v_count} V groups (V0-V{v_count-1})")
    
    def scale_bbox_for_display(self, bbox: BBox) -> Tuple[int, int]:
        """Scale bbox for display according to rules - NO UPSCALING, only determine target size"""
        original_width = bbox.width
        original_height = bbox.height
        width = original_width
        height = original_height
        
        is_long_box = bbox.merged_id in self.long_box_ids
        
        if is_long_box:
            self.log(f"SKIP MIN SCALING: BBox ID {bbox.merged_id} is a long box, skipping minimum dimension scaling")
        else:
            # Determine target dimensions (but don't scale up - we'll pad instead)
            if width < self.MIN_DIMENSION:
                target_width = self.MIN_DIMENSION
                target_height = int(height * (self.MIN_DIMENSION / width))
                self.log(f"PADDING TARGET: BBox ID {bbox.merged_id} width will be padded from {original_width} to {target_width}")
                width = target_width
                height = target_height
            
            if height < self.MIN_DIMENSION:
                target_height = self.MIN_DIMENSION  
                target_width = int(width * (self.MIN_DIMENSION / height))
                self.log(f"PADDING TARGET: BBox ID {bbox.merged_id} height will be padded from {original_height} to {target_height}")
                width = target_width
                height = target_height
        
        # Scale down if height too large (apply to all boxes including long boxes)
        if height > self.MAX_HEIGHT:
            scale_factor = self.MAX_HEIGHT / height
            height = self.MAX_HEIGHT
            width = int(width * scale_factor)
            self.log(f"RESIZE: BBox ID {bbox.merged_id} height scaled down from {original_height} to {height} (factor: {scale_factor:.3f})")
        
        if width != original_width or height != original_height:
            self.log(f"TARGET DIMENSIONS: BBox ID {bbox.merged_id}: {original_width}x{original_height} -> {width}x{height}")
        
        return width, height
    
    def pad_image_to_size(self, image: Image.Image, target_width: int, target_height: int, bbox_id: int) -> Image.Image:
        """Pad image to target size using border pixel replication"""
        current_width, current_height = image.size
        
        # If image is already the right size or larger, just resize normally (scale down)
        if current_width >= target_width and current_height >= target_height:
            resized = image.resize((target_width, target_height), Image.Resampling.LANCZOS)
            self.log(f"PAD: BBox ID {bbox_id} - scaled down normally from {current_width}x{current_height} to {target_width}x{target_height}")
            return resized
        
        # Need to pad - preserve original image quality
        self.log(f"PAD: BBox ID {bbox_id} - padding from {current_width}x{current_height} to {target_width}x{target_height}")
        
        # Calculate padding needed
        pad_left = (target_width - current_width) // 2
        pad_right = target_width - current_width - pad_left
        pad_top = (target_height - current_height) // 2  
        pad_bottom = target_height - current_height - pad_top
        
        # Create padded image by extending border pixels
        # Convert to numpy for easier manipulation
        img_array = np.array(image)
        
        # Pad the image array using edge mode (replicate border pixels)
        padded_array = np.pad(
            img_array,
            ((pad_top, pad_bottom), (pad_left, pad_right), (0, 0)) if len(img_array.shape) == 3 else ((pad_top, pad_bottom), (pad_left, pad_right)),
            mode='edge'  # Replicate edge pixels
        )
        
        # Convert back to PIL Image
        padded_image = Image.fromarray(padded_array)
        
        self.log(f"PAD: BBox ID {bbox_id} - successfully padded with border replication (pad: L{pad_left} R{pad_right} T{pad_top} B{pad_bottom})")
        return padded_image
    
    def crop_bbox_from_image(self, bbox: BBox) -> Image.Image:
        """Crop the actual image content from the original image"""
        if self.original_image is None:
            self.log("ERROR: No original image loaded for cropping", "error")
            # Return a placeholder image
            return Image.new('RGB', (bbox.width, bbox.height), 'white')
        
        try:
            # Ensure coordinates are within image bounds
            x1 = max(0, bbox.x1)
            y1 = max(0, bbox.y1)
            x2 = min(self.original_image.width, bbox.x2)
            y2 = min(self.original_image.height, bbox.y2)
            
            if x1 >= x2 or y1 >= y2:
                self.log(f"WARNING: Invalid crop coordinates for BBox ID {bbox.merged_id}: ({x1},{y1},{x2},{y2})", "warning")
                return Image.new('RGB', (bbox.width, bbox.height), 'white')
            
            cropped = self.original_image.crop((x1, y1, x2, y2))
            self.log(f"CROP: Extracted {cropped.size[0]}x{cropped.size[1]} region from BBox ID {bbox.merged_id}")
            return cropped
            
        except Exception as e:
            self.log(f"ERROR: Failed to crop BBox ID {bbox.merged_id}: {e}", "error")
            return Image.new('RGB', (bbox.width, bbox.height), 'white')
    
    def calculate_label_width(self, label: str, font) -> int:
        """Calculate the width of a label text"""
        try:
            # Create a temporary image to measure text
            temp_img = Image.new('RGB', (1, 1))
            temp_draw = ImageDraw.Draw(temp_img)
            bbox = temp_draw.textbbox((0, 0), label, font=font)
            return bbox[2] - bbox[0]  # width
        except:
            # Fallback estimation: roughly 12px per character for size 24 font
            return len(label) * 12

    def calculate_dynamic_gap(self, current_bbox_width: int, current_label_width: int, 
                            next_bbox_width: int, next_label_width: int) -> int:
        """Calculate dynamic gap between two bboxes based on their label widths"""
        
        # Calculate how much each label extends beyond its bbox
        current_label_overhang = max(0, (current_label_width - current_bbox_width) // 2)
        next_label_overhang = max(0, (next_label_width - next_bbox_width) // 2)
        
        # Total gap needed = base gap + label overhangs + additional buffer
        total_gap = self.BBOX_GAP + current_label_overhang + next_label_overhang + self.BBOX_LABEL_GAP
        
        self.log(f"GAP CALC: bbox widths ({current_bbox_width}, {next_bbox_width}), "
                f"label widths ({current_label_width}, {next_label_width}), "
                f"overhangs ({current_label_overhang}, {next_label_overhang}), "
                f"total gap: {total_gap}")
        
        return total_gap

    def _count_bboxes_in_image(self, groups_in_image: List[str]) -> int:
        """Count total bboxes in the groups that will be in this image"""
        total_count = 0
        for group_id in groups_in_image:
            if group_id in self.final_groups:
                total_count += len(self.final_groups[group_id])
        return total_count
    
    def _generate_filename(self, base_name: str, image_count: int, bbox_count: int) -> str:
        """Generate filename with optional bbox count"""
        if self.INCLUDE_BBOX_COUNT_IN_FILENAME:
            return f"{base_name}_{image_count}_{bbox_count}_bboxes.png"
        else:
            return f"{base_name}_{image_count}.png"
    
    def _generate_combined_group_images(self, groups: Dict[str, List[BBox]], base_name: str, 
                             output_dir: str, start_image_count: int) -> int:
        """Generate images combining both horizontal and vertical groups"""
        image_count = start_image_count
        current_y = self.PADDING + self.LABEL_TOP_PADDING
        current_image = Image.new('RGB', (self.IMAGE_WIDTH, self.IMAGE_HEIGHT), 'white')
        
        try:
            font = ImageFont.truetype("arial.ttf", self.LABEL_FONT_SIZE)
        except:
            font = ImageFont.load_default()
        
        # Track current row state for efficient packing
        current_row_x = self.PADDING
        current_row_max_height = 0
        current_row_groups = []
        
        # Track groups in current image for bbox counting
        groups_in_current_image = []
        
        # Process horizontal groups first, then vertical groups
        h_groups = {k: v for k, v in groups.items() if k.startswith('H')}
        v_groups = {k: v for k, v in groups.items() if k.startswith('V')}
        
        self.log(f"PROCESSING: {len(h_groups)} horizontal groups, then {len(v_groups)} vertical groups")
        
        # Combine groups in order: H groups first, then V groups
        ordered_groups = list(h_groups.items()) + list(v_groups.items())
        
        for group_id, boxes in ordered_groups:
            self.log(f"PROCESSING: Starting group {group_id} with {len(boxes)} boxes")
            
            # Prepare scaled boxes with cropped images and calculate label widths
            scaled_boxes = []
            max_height = 0
            
            for i, bbox in enumerate(boxes):
                # Get scaled dimensions
                width, height = self.scale_bbox_for_display(bbox)
                
                # Crop the actual image content
                cropped_image = self.crop_bbox_from_image(bbox)
                
                # Resize the cropped image to match scaled dimensions
                if cropped_image.size != (width, height):
                    original_size = cropped_image.size
                    original_width, original_height = original_size
                    
                    # Check if we need to scale up (pad) or scale down (resize)
                    if original_width < width or original_height < height:
                        # Use padding to preserve image quality for upscaling
                        cropped_image = self.pad_image_to_size(cropped_image, width, height, bbox.merged_id)
                        self.log(f"PAD: Cropped image for BBox ID {bbox.merged_id} padded from {original_size} to {width}x{height}")
                    else:
                        # Use normal resize for downscaling
                        cropped_image = cropped_image.resize((width, height), Image.Resampling.LANCZOS)
                        self.log(f"RESIZE: Cropped image for BBox ID {bbox.merged_id} resized from {original_size} to {width}x{height}")
                
                label = f"{group_id}_{i+1}"
                label_width = self.calculate_label_width(label, font)
                
                scaled_boxes.append((bbox, width, height, label, cropped_image, label_width))
                max_height = max(max_height, height)
            
                self.log(f"LABEL: {label} width={label_width}px, bbox width={width}px")
            
            # Calculate group width with dynamic gaps based on label widths
            group_width = 0
            for i, (_, width, _, _, _, label_width) in enumerate(scaled_boxes):
                group_width += width
                
                # Add gap to next bbox if not the last one
                if i < len(scaled_boxes) - 1:
                    next_bbox = scaled_boxes[i + 1]
                    next_width = next_bbox[1]
                    next_label_width = next_bbox[5]
                    
                    dynamic_gap = self.calculate_dynamic_gap(width, label_width, next_width, next_label_width)
                    group_width += dynamic_gap
            
            # Add height for labels (vertical spacing unchanged)
            total_group_height = max_height + self.LABEL_TOP_PADDING
            
            self.log(f"LAYOUT: Group {group_id} dimensions: {group_width}x{total_group_height} (with dynamic label gaps)")
            
            # Check if we can fit this group on the current row
            can_fit_on_current_row = (
                current_row_x + group_width + self.PADDING <= self.IMAGE_WIDTH and
                current_y + total_group_height <= self.IMAGE_HEIGHT
            )
            
            # Check if we should start a new row
            should_start_new_row = (
                len(current_row_groups) > 0 and  # There are groups in current row
                (not can_fit_on_current_row or  # Can't fit
                 current_row_x > self.EFFICIENT_PACKING_WIDTH)  # Current row is already long enough
            )
            
            if should_start_new_row:
                # Move to next row
                current_y += current_row_max_height + self.GROUP_GAP
                current_row_x = self.PADDING
                current_row_max_height = 0
                current_row_groups = []
                self.log(f"LAYOUT: Starting new row at Y={current_y} for group {group_id}")
                
                # Check if new row fits in current image
                if current_y + total_group_height > self.IMAGE_HEIGHT:
                    # Save current image and start new one
                    if current_y > self.PADDING + self.LABEL_TOP_PADDING:  # Only save if there's content
                        # Count bboxes in current image
                        bbox_count = self._count_bboxes_in_image(groups_in_current_image)
                        filename = self._generate_filename(base_name, image_count, bbox_count)
                        output_path = f"{output_dir}/{filename}"
                        current_image.save(output_path)
                        self.log(f"SAVE: Saved {output_path} (height used: {current_y}, {bbox_count} bboxes)")
                    image_count += 1
                    
                    current_y = self.PADDING + self.LABEL_TOP_PADDING
                    current_row_x = self.PADDING
                    current_row_max_height = 0
                    current_row_groups = []
                    groups_in_current_image = []  # Reset for new image
                    current_image = Image.new('RGB', (self.IMAGE_WIDTH, self.IMAGE_HEIGHT), 'white')
                    self.log(f"NEW IMAGE: Started new image {image_count} for group {group_id}")
            
            # Add this group to current image tracking
            groups_in_current_image.append(group_id)
            
            # Place boxes in the group with dynamic spacing
            group_start_x = current_row_x
            current_x = group_start_x
            
            for i, (bbox, width, height, label, cropped_image, label_width) in enumerate(scaled_boxes):
                # ‚úÖ FIX: Check if this individual icon will exceed image width
                if current_x + width > self.IMAGE_WIDTH - self.PADDING:
                    # Start new row for this icon
                    current_y += max_height + self.GROUP_GAP
                    current_x = self.PADDING
                    self.log(f"WRAP: Icon {label} wrapped to new row at Y={current_y}")
                    
                    # Check if new row fits in current image
                    if current_y + height > self.IMAGE_HEIGHT:
                        # Save current image and start new one
                        bbox_count = self._count_bboxes_in_image(groups_in_current_image)
                        filename = self._generate_filename(base_name, image_count, bbox_count)
                        output_path = f"{output_dir}/{filename}"
                        current_image.save(output_path)
                        self.log(f"SAVE: Saved {output_path} (height used: {current_y}, {bbox_count} bboxes)")
                    
                    image_count += 1
                    current_y = self.PADDING + self.LABEL_TOP_PADDING
                    current_x = self.PADDING
                    current_image = Image.new('RGB', (self.IMAGE_WIDTH, self.IMAGE_HEIGHT), 'white')
                    self.log(f"NEW IMAGE: Started new image {image_count} for icon {label}")
                
                # Calculate positions
                image_y = current_y
                label_y = current_y - self.LABEL_TOP_PADDING + 5
                
                # Paste the actual cropped image
                current_image.paste(cropped_image, (current_x, image_y))
                
                # Draw border around the image
                draw = ImageDraw.Draw(current_image)
                draw.rectangle([current_x, image_y, current_x + width, image_y + height], 
                             outline='lightgrey', width=self.BBOX_BORDER_WIDTH)
                
                # Draw label without background box
                text_x = current_x + width // 2
                
                if self.LABEL_BACKGROUND:
                    # Draw label background (if enabled)
                    text_bbox = draw.textbbox((text_x, label_y), label, font=font, anchor='mm')
                    draw.rectangle(
                        [text_bbox[0]-2, text_bbox[1]-1, text_bbox[2]+2, text_bbox[3]+1],
                        fill='white',
                        outline='black',
                        width=1
                    )
                
                # Draw label text
                draw.text((text_x, label_y), label, fill='black', font=font, anchor='mm')
                
                # Store mapping
                self.bbox_to_group_mapping[bbox.merged_id] = label
                
                self.log(f"PLACE: Placed {label} at ({current_x}, {image_y}) size {width}x{height}")
                
                # Move to next position with dynamic gap
                current_x += width
                
                # Add dynamic gap to next bbox if not the last one
                if i < len(scaled_boxes) - 1:
                    next_bbox = scaled_boxes[i + 1]
                    next_width = next_bbox[1]
                    next_label_width = next_bbox[5]
                    
                    dynamic_gap = self.calculate_dynamic_gap(width, label_width, next_width, next_label_width)
                    current_x += dynamic_gap
                    
                    self.log(f"SPACING: Added {dynamic_gap}px gap after {label} (label_width={label_width}px)")
            
            # Update row tracking
            current_row_x = current_x + self.SAME_ROW_GAP  # Add gap for next group
            current_row_max_height = max(current_row_max_height, total_group_height)
            current_row_groups.append(group_id)
            
            self.log(f"COMPLETE: Group {group_id} placed, next X position: {current_row_x}, row height: {current_row_max_height}")
        
        # Save final image if it has content
        if current_y > self.PADDING + self.LABEL_TOP_PADDING or len(current_row_groups) > 0:
            # Count bboxes in final image
            bbox_count = self._count_bboxes_in_image(groups_in_current_image)
            filename = self._generate_filename(base_name, image_count, bbox_count)
            output_path = f"{output_dir}/{filename}"
            current_image.save(output_path)
            self.log(f"SAVE: Saved final {output_path} (height used: {current_y + current_row_max_height}, {bbox_count} bboxes)")
            image_count += 1
        
        return image_count
    
    def draw_groups_on_original_image(self, original_image_path: str, output_dir: str = "output"):
        """Draw grouped bounding boxes on the original image with color coding"""
        self.log("Drawing groups on original image")
        
        # Load the original image
        try:
            original_image = Image.open(original_image_path)
            self.log(f"Loaded original image: {original_image.size}")
        except Exception as e:
            self.log(f"Error loading original image: {e}", "error")
            return
        
        # Create a copy for drawing
        annotated_image = original_image.copy()
        draw = ImageDraw.Draw(annotated_image)
        
        try:
            font = ImageFont.truetype("arial.ttf", 14)
            small_font = ImageFont.truetype("arial.ttf", 10)
        except:
            font = ImageFont.load_default()
            small_font = ImageFont.load_default()
        
        # Draw each group with its assigned color
        for group_id, boxes in self.final_groups.items():
            color = self.group_colors[group_id]
            self.log(f"Drawing group {group_id} with {len(boxes)} boxes in color {color}")
            
            for i, bbox in enumerate(boxes):
                # Draw the bounding box with group color
                draw.rectangle(
                    [bbox.x1, bbox.y1, bbox.x2, bbox.y2],
                    outline=color,
                    width=3
                )
                
                # Add a semi-transparent fill
                overlay = Image.new('RGBA', original_image.size, (0, 0, 0, 0))
                overlay_draw = ImageDraw.Draw(overlay)
                overlay_draw.rectangle(
                    [bbox.x1, bbox.y1, bbox.x2, bbox.y2],
                    fill=(*color, 50)  # Semi-transparent fill
                )
                annotated_image = Image.alpha_composite(
                    annotated_image.convert('RGBA'), overlay
                ).convert('RGB')
                
                # Draw group label
                label = f"{group_id}_{i+1}"
                
                # Calculate label position (top-left of bbox with some padding)
                label_x = bbox.x1 + 2
                label_y = bbox.y1 - 20 if bbox.y1 > 20 else bbox.y1 + 2
                
                # Draw label background
                text_bbox = draw.textbbox((label_x, label_y), label, font=small_font)
                draw.rectangle(
                    [text_bbox[0]-2, text_bbox[1]-1, text_bbox[2]+2, text_bbox[3]+1],
                    fill='white',
                    outline=color,
                    width=1
                )
                
                # Draw label text
                draw.text((label_x, label_y), label, fill=color, font=small_font)
                
                # Update the mapping
                self.bbox_to_group_mapping[bbox.merged_id] = label
        
        # Save the annotated image
        output_path = os.path.join(output_dir, "annotated_original_image.png")
        annotated_image.save(output_path)
        self.log(f"Saved annotated original image to {output_path}")
        
        # Also create a legend image
        self._create_legend_image(output_dir)
    
    def _create_legend_image(self, output_dir: str):
        """Create a legend showing group colors and IDs"""
        self.log("Creating legend image")
        
        legend_width = 400
        legend_height = max(300, len(self.final_groups) * 25 + 50)
        
        legend_image = Image.new('RGB', (legend_width, legend_height), 'white')
        draw = ImageDraw.Draw(legend_image)
        
        try:
            font = ImageFont.truetype("arial.ttf", 12)
            title_font = ImageFont.truetype("arial.ttf", 16)
        except:
            font = ImageFont.load_default()
            title_font = ImageFont.load_default()
        
        # Draw title
        draw.text((10, 10), "Group Legend", fill='black', font=title_font)
        
        # Draw legend entries
        y_pos = 40
        for group_id, color in self.group_colors.items():
            # Draw color box
            draw.rectangle([10, y_pos, 30, y_pos + 15], fill=color, outline='black')
            
            # Draw group info
            group_size = len(self.final_groups[group_id])
            text = f"{group_id}: {group_size} boxes"
            draw.text((40, y_pos), text, fill='black', font=font)
            
            y_pos += 25
        
        # Save legend
        legend_path = os.path.join(output_dir, "group_legend.png")
        legend_image.save(legend_path)
        self.log(f"Saved legend to {legend_path}")
    
    def save_mapping(self, output_dir: str = "outputs"):
        """Save the mapping of original IDs to group IDs"""
        mapping_file = f"{output_dir}/bbox_mapping.json"
        
        # Enhanced mapping with group colors and coordinates
        enhanced_mapping = {}
        for original_id, group_label in self.bbox_to_group_mapping.items():
            # Find the bbox and its group
            bbox = None
            group_id = None
            
            for gid, boxes in self.final_groups.items():
                for box in boxes:
                    if box.original_id == original_id:
                        bbox = box
                        group_id = gid
                        break
                if bbox:
                    break
            
            if bbox and group_id:
                enhanced_mapping[str(original_id)] = {
                    "group_label": group_label,
                    "group_id": group_id,
                    "group_color": self.group_colors[group_id],
                    "original_coordinates": [bbox.x1, bbox.y1, bbox.x2, bbox.y2],
                    "bbox_type": bbox.bbox_type,
                    "source": bbox.source
                }
        
        with open(mapping_file, 'w') as f:
            json.dump(enhanced_mapping, f, indent=2)
        
        self.log(f"Saved enhanced mapping to {mapping_file}")
    
    def process(self, json_file_path: str, original_image_path: str = None, output_dir: str = "outputs"):
        """Main processing pipeline"""
        self.log("Starting BBox processing pipeline")
        
        # Load original image first if provided
        if original_image_path:
            try:
                self.original_image = Image.open(original_image_path)
                self.log(f"Loaded original image for cropping: {self.original_image.size}")
            except Exception as e:
                self.log(f"Error loading original image: {e}", "error")
                self.original_image = None
        
        self.load_bboxes(json_file_path)
        self.sort_bboxes()
        self.assign_sorted_ids()
        self.calculate_dimensions_and_identify_long_boxes()
        self.horizontal_grouping()
        self.vertical_grouping()
        self.merge_groups()
        self.generate_images(output_dir)
        
        # Draw on original image if provided
        if original_image_path:
            self.draw_groups_on_original_image(original_image_path, output_dir)
        
        self.save_mapping(output_dir)
        
        self.log("BBox processing pipeline completed")

    def generate_images(self, output_dir: str = "outputs", return_images: bool = False):
        """Steps 10-11: Generate images with grouped bboxes - combining H and V groups"""
        self.log("Steps 10-11: Generating images with combined H and V groups")
        
        os.makedirs(output_dir, exist_ok=True)
        all_groups = self.final_groups
        self.log(f"Processing {len(all_groups)} total groups (H and V combined)")
        
        # Use unified function for both modes
        image_count, generated_images = self._generate_combined_group_images(
            all_groups, "combined_groups", output_dir, 0
        )
        
        if return_images:
            self.log(f"Generated {image_count} combined images with direct return")
            return {
                'image_count': image_count,
                'generated_images': generated_images,  # List of (PIL.Image, filename, bbox_count)
                'saved_paths': [f"{output_dir}/{filename}" for _, filename, _ in generated_images]
            }
        else:
            self.log(f"Generated {image_count} combined images")
            return None

    def _generate_combined_group_images(self, groups: Dict[str, List[BBox]], base_name: str, 
                                   output_dir: str, start_image_count: int) -> Tuple[int, List[Tuple]]:
        """Generate images and return them directly along with saving - UNIFIED VERSION"""
        image_count = start_image_count
        current_y = self.PADDING + self.LABEL_TOP_PADDING
        current_image = Image.new('RGB', (self.IMAGE_WIDTH, self.IMAGE_HEIGHT), 'white')
        generated_images = []  # List of (PIL.Image, filename, bbox_count)
        
        try:
            font = ImageFont.truetype("arial.ttf", self.LABEL_FONT_SIZE)
        except:
            font = ImageFont.load_default()
        
        # Track current row state for efficient packing
        current_row_x = self.PADDING
        current_row_max_height = 0
        current_row_groups = []
        
        # Track groups in current image for bbox counting
        groups_in_current_image = []
        
        # Process horizontal groups first, then vertical groups
        h_groups = {k: v for k, v in groups.items() if k.startswith('H')}
        v_groups = {k: v for k, v in groups.items() if k.startswith('V')}
        
        self.log(f"PROCESSING: {len(h_groups)} horizontal groups, then {len(v_groups)} vertical groups")
        
        # Combine groups in order: H groups first, then V groups
        ordered_groups = list(h_groups.items()) + list(v_groups.items())
        
        for group_id, boxes in ordered_groups:
            self.log(f"PROCESSING: Starting group {group_id} with {len(boxes)} boxes")
            
            # Prepare scaled boxes with cropped images and calculate label widths
            scaled_boxes = []
            max_height = 0
            
            for i, bbox in enumerate(boxes):
                width, height = self.scale_bbox_for_display(bbox)
                cropped_image = self.crop_bbox_from_image(bbox)
                
                if cropped_image.size != (width, height):
                    cropped_image = cropped_image.resize((width, height), Image.Resampling.LANCZOS)
                
                label = f"{group_id}_{i+1}"
                label_width = self.calculate_label_width(label, font)
                
                scaled_boxes.append((bbox, width, height, label, cropped_image, label_width))
                max_height = max(max_height, height)
            
            # Calculate group width with dynamic gaps
            group_width = 0
            for i, (_, width, _, _, _, label_width) in enumerate(scaled_boxes):
                group_width += width
                if i < len(scaled_boxes) - 1:
                    next_bbox = scaled_boxes[i + 1]
                    dynamic_gap = self.calculate_dynamic_gap(width, label_width, next_bbox[1], next_bbox[5])
                    group_width += dynamic_gap
            
            total_group_height = max_height + self.LABEL_TOP_PADDING
            
            self.log(f"LAYOUT: Group {group_id} dimensions: {group_width}x{total_group_height} (with dynamic label gaps)")
            
            # Check if we can fit this group on the current row
            can_fit_on_current_row = (
                current_row_x + group_width + self.PADDING <= self.IMAGE_WIDTH and
                current_y + total_group_height <= self.IMAGE_HEIGHT
            )
            
            # Check if we should start a new row
            should_start_new_row = (
                len(current_row_groups) > 0 and  # There are groups in current row
                (not can_fit_on_current_row or  # Can't fit
                 current_row_x > self.EFFICIENT_PACKING_WIDTH)  # Current row is already long enough
            )
            
            if should_start_new_row:
                # Move to next row
                current_y += current_row_max_height + self.GROUP_GAP
                current_row_x = self.PADDING
                current_row_max_height = 0
                current_row_groups = []
                self.log(f"LAYOUT: Starting new row at Y={current_y} for group {group_id}")
                
                # Check if new row fits in current image
                if current_y + total_group_height > self.IMAGE_HEIGHT:
                    # Save current image and start new one
                    if current_y > self.PADDING + self.LABEL_TOP_PADDING:  # Only save if there's content
                        bbox_count = self._count_bboxes_in_image(groups_in_current_image)
                        filename = self._generate_filename(base_name, image_count, bbox_count)
                        output_path = f"{output_dir}/{filename}"
                        
                        # Save to disk (original behavior)
                        current_image.save(output_path)
                        
                        # Add to return list (new behavior)
                        generated_images.append((current_image.copy(), filename, bbox_count))
                        
                        self.log(f"SAVE: Saved {output_path} and added to return list ({bbox_count} bboxes)")
                    
                    image_count += 1
                    current_y = self.PADDING + self.LABEL_TOP_PADDING
                    current_row_x = self.PADDING
                    current_row_max_height = 0
                    current_row_groups = []
                    groups_in_current_image = []  # Reset for new image
                    current_image = Image.new('RGB', (self.IMAGE_WIDTH, self.IMAGE_HEIGHT), 'white')
                    self.log(f"NEW IMAGE: Started new image {image_count} for group {group_id}")
            
            # Add this group to current image tracking
            groups_in_current_image.append(group_id)
            
            # Place boxes in the group with dynamic spacing
            group_start_x = current_row_x
            current_x = group_start_x
            
            for i, (bbox, width, height, label, cropped_image, label_width) in enumerate(scaled_boxes):
                # ‚úÖ FIX: Check if this individual icon will exceed image width
                if current_x + width > self.IMAGE_WIDTH - self.PADDING:
                    # Start new row for this icon
                    current_y += max_height + self.GROUP_GAP
                    current_x = self.PADDING
                    self.log(f"WRAP: Icon {label} wrapped to new row at Y={current_y}")
                    
                    # Check if new row fits in current image
                    if current_y + height > self.IMAGE_HEIGHT:
                        # Save current image and start new one
                        bbox_count = self._count_bboxes_in_image(groups_in_current_image)
                        filename = self._generate_filename(base_name, image_count, bbox_count)
                        output_path = f"{output_dir}/{filename}"
                        current_image.save(output_path)
                        generated_images.append((current_image.copy(), filename, bbox_count))
                        
                        # Start new image
                        image_count += 1
                        current_y = self.PADDING + self.LABEL_TOP_PADDING
                        current_x = self.PADDING
                        current_image = Image.new('RGB', (self.IMAGE_WIDTH, self.IMAGE_HEIGHT), 'white')
                        self.log(f"NEW IMAGE: Started new image {image_count} for icon {label}")
                
                # Calculate positions
                image_y = current_y
                label_y = current_y - self.LABEL_TOP_PADDING + 5
                
                # Paste the actual cropped image
                current_image.paste(cropped_image, (current_x, image_y))
                
                # Draw border around the image
                draw = ImageDraw.Draw(current_image)
                draw.rectangle([current_x, image_y, current_x + width, image_y + height], 
                             outline='lightgrey', width=self.BBOX_BORDER_WIDTH)
                
                # Draw label without background box
                text_x = current_x + width // 2
                
                if self.LABEL_BACKGROUND:
                    # Draw label background (if enabled)
                    text_bbox = draw.textbbox((text_x, label_y), label, font=font, anchor='mm')
                    draw.rectangle(
                        [text_bbox[0]-2, text_bbox[1]-1, text_bbox[2]+2, text_bbox[3]+1],
                        fill='white',
                        outline='black',
                        width=1
                    )
                
                # Draw label text
                draw.text((text_x, label_y), label, fill='black', font=font, anchor='mm')
                
                # Store mapping
                self.bbox_to_group_mapping[bbox.merged_id] = label
                
                self.log(f"PLACE: Placed {label} at ({current_x}, {image_y}) size {width}x{height}")
                
                # Move to next position with dynamic gap
                current_x += width
                
                # Add dynamic gap to next bbox if not the last one
                if i < len(scaled_boxes) - 1:
                    next_bbox = scaled_boxes[i + 1]
                    next_width = next_bbox[1]
                    next_label_width = next_bbox[5]
                    
                    dynamic_gap = self.calculate_dynamic_gap(width, label_width, next_width, next_label_width)
                    current_x += dynamic_gap
                    
                    self.log(f"SPACING: Added {dynamic_gap}px gap after {label} (label_width={label_width}px)")
            
            # Update row tracking
            current_row_x = current_x + self.SAME_ROW_GAP  # Add gap for next group
            current_row_max_height = max(current_row_max_height, total_group_height)
            current_row_groups.append(group_id)
            
            self.log(f"COMPLETE: Group {group_id} placed, next X position: {current_row_x}, row height: {current_row_max_height}")
        
        # Save final image if it has content
        if current_y > self.PADDING + self.LABEL_TOP_PADDING or len(current_row_groups) > 0:
            bbox_count = self._count_bboxes_in_image(groups_in_current_image)
            filename = self._generate_filename(base_name, image_count, bbox_count)
            output_path = f"{output_dir}/{filename}"
            
            # Save to disk
            current_image.save(output_path)
            
            # Add to return list
            generated_images.append((current_image.copy(), filename, bbox_count))
            
            self.log(f"SAVE: Saved final {output_path} and added to return list ({bbox_count} bboxes)")
            image_count += 1
        
        return image_count, generated_images


# INTEGRATION WRAPPER FUNCTIONS FOR MAIN.PY COMPATIBILITY
# These functions provide the same interface as the old seraphine_processor + group_image_generator

class FinalSeraphineProcessor:
    """
    Wrapper class that provides the same interface as the old SeraphineProcessor + GroupImageGenerator
    but uses the new BBoxProcessor internally for both grouping and image generation
    """
    
    def __init__(self, enable_timing: bool = True, enable_debug: bool = False):
        self.enable_timing = enable_timing
        self.enable_debug = enable_debug
        self.bbox_processor = BBoxProcessor(enable_logging=enable_debug)
    
    def process_detections(self, detections: List[Dict]) -> Dict[str, Any]:
        """
        Process detections using the new BBoxProcessor
        Maintains compatibility with old SeraphineProcessor interface
        
        Args:
            detections: List of detection dictionaries with 'bbox' key
            
        Returns:
            Dict containing grouping analysis and structured results (compatible with old format)
        """
        start_time = time.time()
        
        if self.enable_debug:
            debug_print(f"üß† [FINAL SERAPHINE] Processing {len(detections)} detections...")
        
        # Create temporary JSON file for BBoxProcessor
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as temp_file:
            json.dump(detections, temp_file, indent=2)
            temp_json_path = temp_file.name
        
        try:
            # Load detections into BBoxProcessor
            self.bbox_processor.load_bboxes(temp_json_path)
            self.bbox_processor.sort_bboxes()
            self.bbox_processor.assign_sorted_ids()
            self.bbox_processor.calculate_dimensions_and_identify_long_boxes()
            self.bbox_processor.horizontal_grouping()
            self.bbox_processor.vertical_grouping()
            self.bbox_processor.merge_groups()
            
            # Convert results to old format for compatibility
            analysis = self._create_compatible_analysis(detections)
            
            elapsed = time.time() - start_time
            if self.enable_timing:
                debug_print(f"‚è±Ô∏è  Final Seraphine processing: {elapsed:.3f}s")
            
            return {
                'horizontal_groups': self._convert_to_old_group_format('H'),
                'vertical_groups': self._convert_to_old_group_format('V'),
                'final_groups': self._convert_final_groups_to_old_format(),
                'group_dict': self._create_group_dict(),
                'analysis': analysis,
                'processing_time': elapsed,
                'bbox_processor': self.bbox_processor,  # Store reference for image generation
                'grouped_items': len(detections)
            }
            
        finally:
            # Clean up temporary file
            try:
                os.unlink(temp_json_path)
            except:
                pass
    
    def _bbox_to_dict(self, bbox: BBox) -> Dict:
        """Convert BBox object to dictionary format - SINGLE SOURCE OF TRUTH"""
        return {
            'bbox': [bbox.x1, bbox.y1, bbox.x2, bbox.y2],
            'id': bbox.original_id,
            'merged_id': bbox.merged_id,
            'type': bbox.bbox_type,
            'source': bbox.source,
            'confidence': bbox.confidence
        }

    def _convert_bbox_groups(self, groups_dict: Dict, output_format: str = 'list') -> Any:
        """Universal bbox group converter - eliminates all duplication"""
        if output_format == 'list':
            # For _convert_final_groups_to_old_format and _convert_to_old_group_format
            result = []
            for group_id, bbox_list in groups_dict.items():
                result.append([self._bbox_to_dict(bbox) for bbox in bbox_list])
            return result
        
        elif output_format == 'dict':
            # For _create_group_dict  
            result = {}
            for group_id, bbox_list in groups_dict.items():
                result[group_id] = [self._bbox_to_dict(bbox) for bbox in bbox_list]
            return result

    def _convert_to_old_group_format(self, group_type: str) -> List[List[Dict]]:
        """Convert new group format to old format"""
        if group_type == 'H':
            groups_dict = self.bbox_processor.horizontal_groups
        else:
            groups_dict = self.bbox_processor.vertical_groups
        return self._convert_bbox_groups(groups_dict, 'list')

    def _convert_final_groups_to_old_format(self) -> List[List[Dict]]:
        """Convert final groups to old format"""
        return self._convert_bbox_groups(self.bbox_processor.final_groups, 'list')

    def _create_group_dict(self) -> Dict[str, List[Dict]]:
        """Create group dictionary in old format"""
        return self._convert_bbox_groups(self.bbox_processor.final_groups, 'dict')

    def _create_compatible_analysis(self, detections: List[Dict]) -> Dict[str, Any]:
        """Create analysis compatible with old format"""
        total_detections = len(detections)
        total_groups = len(self.bbox_processor.final_groups)
        
        h_groups = len([g for g in self.bbox_processor.final_groups.keys() if g.startswith('H')])
        v_groups = len([g for g in self.bbox_processor.final_groups.keys() if g.startswith('V')])
        long_groups = len([g for g in self.bbox_processor.final_groups.keys() if 'L' in g])
        
        # Create group_details using helper function
        group_details = {}
        for group_id, bbox_list in self.bbox_processor.final_groups.items():
            group_details[group_id] = {
                'group_id': group_id,
                'size': len(bbox_list),
                'type': 'horizontal' if group_id.startswith('H') else 'vertical' if group_id.startswith('V') else 'long_box',
                'bboxes': [self._bbox_to_dict(bbox) for bbox in bbox_list]  # Use helper
            }
        
        return {
            'total_detections': total_detections,
            'total_groups': total_groups,
            'horizontal_groups': h_groups,
            'vertical_groups': v_groups,
            'long_box_groups': long_groups,
            'grouping_efficiency': total_groups / total_detections if total_detections > 0 else 0,
            'group_details': group_details,
            'ungrouped_detections': [],
            'grouped_items': total_detections,
            'ungrouped_items': 0
        }

==================================================

Path: utils\seraphine_pipeline\splashscreen_handler.py
File: splashscreen_handler.py
Code:
import os
import json
import time
import tempfile
import hashlib
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Use YOUR existing infrastructure
from gui_controller import SimpleWindowAPI
from fdom.screenshot_manager import ScreenshotManager  
from fdom.visual_differ import VisualDiffer

def handle_splash_screen_if_needed(seraphine_analysis: Dict, screenshot_path: str, fdom_path: str) -> Dict:
    """Handle splash screen and replace original screenshot"""
    try:
        # ‚úÖ LOOP PREVENTION: Check if we've already tried this recently
        if check_recent_splash_attempts(fdom_path):
            print("‚ö†Ô∏è Recent splash screen attempts detected - preventing infinite loop")
            return {"action": "loop_prevented", "success": True, "restart_required": False}
        
        # Extract splash screen data from seraphine_analysis
        splash_data, startup_data = extract_splash_data(seraphine_analysis)
        
        print(f"üîç Checking splash screen requirements...")
        print(f"   Splash present: {splash_data.get('present', False)}")
        print(f"   Startup required: {startup_data.get('required', False)}")
        
        if not splash_data.get('present', False) and not startup_data.get('required', False):
            print("‚úÖ No splash screen interaction needed")
            return {"action": "none", "success": True, "restart_required": False}

        # ‚úÖ SIMPLIFIED APPROACH - Use basic screenshot comparison instead of full visual_differ
        gui_api = SimpleWindowAPI()
        
        # ‚úÖ TAKE BEFORE SCREENSHOT using simple approach
        before_screenshot = take_simple_screenshot("splash_before")
        if not before_screenshot:
            return {"action": "failed", "success": False, "error": "Could not take before screenshot"}
        
        # Get click targets
        click_targets = get_click_targets(splash_data, startup_data)
        print(f"üéØ Attempting splash screen dismissal with {len(click_targets)} targets...")
        
        # Try each target with simplified verification
        for i, target in enumerate(click_targets, 1):
            group_id = target.get('group_id')
            coordinates = get_click_coordinates(group_id, seraphine_analysis)
            
            if coordinates:
                x, y = coordinates
                print(f"üñ±Ô∏è  Target {i}: Clicking {group_id} at coordinates ({x}, {y})")
                
                # ‚úÖ USE AUTO_CAPTIONER'S RELIABLE CLICK METHOD
                click_success = perform_enhanced_click(x, y, group_id)
                if not click_success:
                    print(f"‚ùå Enhanced click failed for {group_id}")
                    continue
                
                # ‚úÖ SIMPLIFIED VERIFICATION
                if verify_screen_changed_simple(before_screenshot, x, y):
                    print(f"‚úÖ VERIFIED screen change after clicking {group_id}")
                    
                    # Cleanup before screenshot
                    cleanup_screenshot(before_screenshot)
                    
                    record_splash_attempt(fdom_path, group_id, [x, y], True)
                    
                    # ‚úÖ TAKE NEW SCREENSHOT
                    print("üì∏ Taking new screenshot after splash screen dismissal...")
                    time.sleep(2.0)  # Give UI time to settle
                    new_screenshot_path = take_new_app_screenshot(screenshot_path)
                    
                    if new_screenshot_path:
                        print(f"‚úÖ New screenshot saved: {new_screenshot_path}")
                        
                        # ‚úÖ REPLACE ORIGINAL SCREENSHOT 
                        import shutil
                        import os
                        
                        # Backup original (optional)
                        backup_path = screenshot_path.replace('.png', '_with_splash.png')
                        shutil.copy2(screenshot_path, backup_path)
                        print(f"üìÅ Backed up original to: {os.path.basename(backup_path)}")
                        
                        # Replace original with clean screenshot
                        shutil.copy2(new_screenshot_path, screenshot_path)
                        print(f"üîÑ Replaced {os.path.basename(screenshot_path)} with splash-free version")
                        
                        # Clean up temp file
                        os.remove(new_screenshot_path)
                        
                        return {
                            "action": "replaced_screenshot",
                            "success": True,
                            "clicked_group": group_id,
                            "coordinates": [x, y],
                            "restart_required": True,  # ‚Üê Signal restart needed
                            "new_screenshot_path": screenshot_path,  # ‚Üê Same path, but new content
                            "message": "Splash screen dismissed, screenshot replaced, restart required"
                        }
                        
                    else:
                        print("‚ö†Ô∏è Could not take new screenshot, continuing without restart")
                    return {
                        "action": "clicked",
                        "success": True,
                        "clicked_group": group_id,
                        "coordinates": [x, y],
                            "restart_required": False,
                            "message": "Splash screen dismissed but screenshot replacement failed"
                    }
                else:
                    print(f"‚ùå No screen change detected after clicking {group_id}")
                    record_splash_attempt(fdom_path, group_id, [x, y], False)
                    continue
        
        # Cleanup before screenshot
        cleanup_screenshot(before_screenshot)
        
        return {"action": "tried", "success": False, "restart_required": False}
        
    except Exception as e:
        print(f"‚ùå Error during splash screen handling: {e}")
        return {"action": "failed", "success": False, "restart_required": False, "error": str(e)}

def take_simple_screenshot(name: str) -> Optional[str]:
    """Take a simple screenshot without requiring VisualDiffer"""
    try:
        import tempfile
        from PIL import ImageGrab
        
        # Take screenshot
        screenshot = ImageGrab.grab()
        
        # Save to temp file
        temp_dir = tempfile.gettempdir()
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        screenshot_path = os.path.join(temp_dir, f"{name}_{timestamp}.png")
        
        screenshot.save(screenshot_path)
        screenshot.close()
        
        print(f"üì∏ Screenshot saved: {screenshot_path}")
        return screenshot_path
        
    except Exception as e:
        print(f"‚ùå Screenshot failed: {e}")
        return None

def verify_screen_changed_simple(before_screenshot: str, click_x: int, click_y: int) -> bool:
    """Simplified screen change verification using basic image comparison"""
    try:
        print("üì∏ Taking after screenshot for comparison...")
        time.sleep(2.0)  # Give UI more time to respond
        
        # Take after screenshot
        after_screenshot = take_simple_screenshot("splash_after")
        if not after_screenshot:
            print("‚ùå Could not take after screenshot")
            return False
        
        # ‚úÖ BASIC IMAGE COMPARISON
        from PIL import Image
        import numpy as np
        
        # Load images
        img1 = Image.open(before_screenshot)
        img2 = Image.open(after_screenshot)
        
        # Convert to arrays
        arr1 = np.array(img1)
        arr2 = np.array(img2)
        
        # Calculate difference
        diff = np.abs(arr1.astype(float) - arr2.astype(float))
        total_diff = np.sum(diff)
        total_pixels = arr1.size
        
        # Calculate percentage difference
        diff_percentage = (total_diff / (total_pixels * 255)) * 100
        
        # Clean up
        img1.close()
        img2.close()
        cleanup_screenshot(after_screenshot)
        
        # Consider significant if more than 0.5% of pixels changed
        threshold = 0.5
        changed = diff_percentage > threshold
        
        print(f"üìä Image difference: {diff_percentage:.2f}% ({'CHANGED' if changed else 'NO CHANGE'})")
        
        return changed
        
    except Exception as e:
        print(f"‚ùå Simple verification failed: {e}")
        # Fall back to time-based assumption
        print("üì∏ Falling back to time-based verification")
        time.sleep(1)
        return True  # Assume success

def cleanup_screenshot(screenshot_path: str):
    """Clean up screenshot file"""
    if screenshot_path and os.path.exists(screenshot_path):
        try:
            os.remove(screenshot_path)
        except:
            pass

def perform_enhanced_click(abs_x: int, abs_y: int, element_name: str) -> bool:
    """Use auto_captioner's reliable SendInput click method"""
    try:
        import ctypes
        from ctypes import wintypes
        
        # Get current position for smooth movement
        gui_api = SimpleWindowAPI()
        current_pos = gui_api.get_cursor_position()
        start_x, start_y = current_pos if current_pos else (abs_x - 50, abs_y - 20)
        
        # ‚úÖ COPY AUTO_CAPTIONER'S WORKING SendInput METHOD
        class MOUSEINPUT(ctypes.Structure):
            _fields_ = [
                ("dx", ctypes.c_long),
                ("dy", ctypes.c_long),
                ("mouseData", wintypes.DWORD),
                ("dwFlags", wintypes.DWORD),
                ("time", wintypes.DWORD),
                ("dwExtraInfo", ctypes.POINTER(wintypes.ULONG))
            ]
        
        class INPUT(ctypes.Structure):
            class _INPUT(ctypes.Union):
                _fields_ = [("mi", MOUSEINPUT)]
            _anonymous_ = ("_input",)
            _fields_ = [
                ("type", wintypes.DWORD),
                ("_input", _INPUT)
            ]
        
        user32 = ctypes.windll.user32
        screen_width = user32.GetSystemMetrics(0)
        screen_height = user32.GetSystemMetrics(1)
        
        # Smooth movement to target (like auto_captioner)
        steps = 10
        for i in range(steps + 1):
            progress = i / steps
            eased_progress = 1 - (1 - progress) ** 2  # Ease-out
            
            current_x = int(start_x + (abs_x - start_x) * eased_progress)
            current_y = int(start_y + (abs_y - start_y) * eased_progress)
            
            # Convert to SendInput coordinates
            input_x = int((current_x * 65535) / screen_width)
            input_y = int((current_y * 65535) / screen_height)
            
            # Create input structure
            inp = INPUT()
            inp.type = 0  # INPUT_MOUSE
            inp.mi.dx = input_x
            inp.mi.dy = input_y
            inp.mi.mouseData = 0
            inp.mi.dwFlags = 0x8001  # MOUSEEVENTF_MOVE + MOUSEEVENTF_ABSOLUTE
            inp.mi.time = 0
            inp.mi.dwExtraInfo = None
            
            result = user32.SendInput(1, ctypes.byref(inp), ctypes.sizeof(INPUT))
            if result != 1:
                return False
        
            time.sleep(0.02)
        
        # Perform click at final position
        click_input = INPUT()
        click_input.type = 0
        click_input.mi.dx = int((abs_x * 65535) / screen_width)
        click_input.mi.dy = int((abs_y * 65535) / screen_height)
        click_input.mi.mouseData = 0
        click_input.mi.dwFlags = 0x8003  # MOUSEEVENTF_LEFTDOWN + MOUSEEVENTF_ABSOLUTE
        click_input.mi.time = 0
        click_input.mi.dwExtraInfo = None
        
        # Click down
        user32.SendInput(1, ctypes.byref(click_input), ctypes.sizeof(INPUT))
        time.sleep(0.05)
        
        # Click up
        click_input.mi.dwFlags = 0x8004  # MOUSEEVENTF_LEFTUP + MOUSEEVENTF_ABSOLUTE
        user32.SendInput(1, ctypes.byref(click_input), ctypes.sizeof(INPUT))
        
        time.sleep(2.0)  # Wait for splash screen to respond
        return True
        
    except Exception as e:
        print(f"‚ùå Enhanced click failed: {e}")
        return False

def get_click_coordinates(group_id: str, seraphine_analysis: Dict) -> Optional[Tuple[int, int]]:
    """Get click coordinates with PROPER bbox_processor lookup"""
    
    # Strategy 1: Check bbox_processor.final_groups first (like the original working version)
    bbox_processor = seraphine_analysis.get('bbox_processor')
    if bbox_processor and hasattr(bbox_processor, 'final_groups'):
        if group_id in bbox_processor.final_groups:
            bboxes = bbox_processor.final_groups[group_id]
            if bboxes:
                # Use first bbox for coordinates
                bbox = bboxes[0]
                app_relative_x = (bbox.x1 + bbox.x2) // 2
                app_relative_y = (bbox.y1 + bbox.y2) // 2
                
                # ‚úÖ CONVERT TO ABSOLUTE SCREEN COORDINATES
                absolute_x, absolute_y = convert_to_absolute_coordinates(app_relative_x, app_relative_y)
                
                print(f"‚úÖ Found coordinates for {group_id} in bbox_processor: app-relative ({app_relative_x}, {app_relative_y}) ‚Üí absolute ({absolute_x}, {absolute_y})")
                return (absolute_x, absolute_y)
    
    # Strategy 2: Fallback to group_details
    group_details = seraphine_analysis.get('analysis', {}).get('group_details', {})
    
    if group_id in group_details:
        bbox = group_details[group_id].get('bbox')
        if bbox and len(bbox) == 4:
            # Calculate centroid
            cx = (bbox[0] + bbox[2]) // 2
            cy = (bbox[1] + bbox[3]) // 2
            
            # Convert to absolute coordinates
            absolute_x, absolute_y = convert_to_absolute_coordinates(cx, cy)
            
            print(f"‚úÖ Found coordinates for {group_id} in group_details: ({cx}, {cy}) ‚Üí absolute ({absolute_x}, {absolute_y})")
            return (absolute_x, absolute_y)
    
    print(f"‚ùå Group {group_id} not found anywhere")
    
    # Debug info
    if bbox_processor and hasattr(bbox_processor, 'final_groups'):
        bbox_groups = list(bbox_processor.final_groups.keys())[:10]
        print(f"üîç bbox_processor groups: {bbox_groups}...")
    
    available_groups = list(group_details.keys())[:10]
    print(f"üîç group_details groups: {available_groups}...")
    
    return None

def convert_to_absolute_coordinates(app_x: int, app_y: int) -> Tuple[int, int]:
    """Convert app-relative coordinates to absolute screen coordinates"""
    try:
        # ‚úÖ DETECT APP DYNAMICALLY FROM CURRENT CONTEXT
        gui_api = SimpleWindowAPI()
        
        # Try to find current focused/active window
        possible_titles = ["PowerPoint", "Blender", "Word", "Excel", "Chrome", "Firefox"]
        
        app_window_id = None
        found_title = None
        for title in possible_titles:
            app_window_id = gui_api.find_window(title)
            if app_window_id:
                found_title = title
                break
        
        if app_window_id:
            print(f"‚úÖ Found active window: {found_title}")
            window_info = gui_api.get_window_info(app_window_id)
            if window_info and 'window_data' in window_info:
                pos = window_info['window_data']['position']
                window_x = pos.get('x', 0)
                window_y = pos.get('y', 0)
                
                # Convert to absolute coordinates
                absolute_x = window_x + app_x
                absolute_y = window_y + app_y
                
                print(f"üîß Coordinate conversion: window at ({window_x}, {window_y}) + app offset ({app_x}, {app_y}) = absolute ({absolute_x}, {absolute_y})")
                return (absolute_x, absolute_y)
            else:
                print("‚ùå No window_data in window_info")
        else:
            print("‚ùå Could not find any known application window")
        
        # Fallback: assume coordinates are already absolute
        print(f"‚ö†Ô∏è Could not get window position, using coordinates as-is")
        return (app_x, app_y)
        
    except Exception as e:
        print(f"‚ùå Coordinate conversion failed: {e}")
        return (app_x, app_y)

def get_click_coordinates_from_group(group_id: str, group_details: Dict, override_coords: Optional[Dict] = None) -> Optional[Tuple[int, int]]:
    """
    Get click coordinates from group details (app-relative coordinates)
    """
    
    # Priority 1: Use provided coordinates
    if override_coords and 'x' in override_coords and 'y' in override_coords:
        return (int(override_coords['x']), int(override_coords['y']))
    
    # Priority 2: Calculate centroid from group bbox
    group_info = group_details.get(group_id, {})
    
    print(f"üîç DEBUG: Group {group_id} structure:")
    print(f"   Keys: {list(group_info.keys()) if group_info else 'GROUP NOT FOUND'}")
    
    if not group_info:
        return None
        
    # Try different bbox formats
    bbox = None
    
    # Format: bboxes array - use first bbox
    if 'bboxes' in group_info and group_info['bboxes']:
        bboxes = group_info['bboxes']
        if bboxes:
            first_bbox = bboxes[0]
            if isinstance(first_bbox, dict) and 'bbox' in first_bbox:
                bbox = first_bbox['bbox']
            elif isinstance(first_bbox, list):
                bbox = first_bbox
    
    if bbox and len(bbox) >= 4:
        # bbox format: [x1, y1, x2, y2] - these are app-relative coordinates
        x1, y1, x2, y2 = bbox[:4]
        centroid_x = int((x1 + x2) / 2)
        centroid_y = int((y1 + y2) / 2)
        print(f"‚úÖ Found app-relative coordinates for {group_id}: ({centroid_x}, {centroid_y})")
        return (centroid_x, centroid_y)
    
    print(f"‚ùå Could not determine coordinates for group {group_id}")
    return None


def perform_click_and_check_change_existing_system(app_coords: Tuple[int, int], group_id: str, api) -> bool:
    """
    Perform click using existing system and check for screen change
    """
    try:
        app_x, app_y = app_coords
        print(f"üñ±Ô∏è  Clicking at app-relative coords ({app_x}, {app_y}) for group {group_id}")
        
        # ‚úÖ GET WINDOW POSITION FROM EXISTING SYSTEM
        # You'll need to get the app window coordinates to convert app-relative to screen coordinates
        # For now, I'll assume the coordinates are already correct or use a workaround
        
        # ‚úÖ USE YOUR EXISTING CLICK SYSTEM
        success = api.click(app_x, app_y, "left")
        
        if not success:
            print(f"‚ùå Failed to perform click at ({app_x}, {app_y})")
            return False
        
        # ‚úÖ WAIT AND ASSUME SUCCESS FOR NOW (you can add screen change detection later)
        time.sleep(2.0)  # Wait for splash screen to respond
        print(f"‚úÖ Click completed on {group_id} using existing GUI system")
        return True  # ‚úÖ ASSUME SUCCESS since we're using your tested click system
        
    except Exception as e:
        print(f"‚ùå Error during click: {str(e)}")
        return False


# Add missing helper functions
def extract_splash_data(seraphine_analysis: Dict) -> Tuple[Dict, Dict]:
    """Extract splash screen data from seraphine analysis"""
    splash_data = {}
    startup_data = {}
    
    # Location 1: Direct in seraphine_analysis
    splash_data = seraphine_analysis.get('splash_screen', {})
    startup_data = seraphine_analysis.get('startup_interaction', {})
    
    # Location 2: In analysis sub-dict
    if not splash_data and 'analysis' in seraphine_analysis:
        analysis = seraphine_analysis['analysis']
        splash_data = analysis.get('splash_screen', {})
        startup_data = analysis.get('startup_interaction', {})
    
    return splash_data, startup_data

def get_click_targets(splash_data: Dict, startup_data: Dict) -> List[Dict]:
    """Get click targets from splash and startup data"""
    click_targets = []
    
    if splash_data.get('present', False):
        safe_targets = splash_data.get('dismissal', {}).get('safe_click_targets', [])
        click_targets.extend(safe_targets)
        print(f"üîç Added {len(safe_targets)} splash screen targets: {[t.get('group_id') for t in safe_targets]}")
    
    if startup_data.get('required', False):
        strategies = startup_data.get('strategies', [])
        # Sort by changes_screen=true first
        strategies.sort(key=lambda x: not x.get('changes_screen', False))
        click_targets.extend(strategies)
        print(f"üîç Added {len(strategies)} startup strategies: {[s.get('group_id') for s in strategies]}")
        
        # ‚úÖ FIXED: Use separate formatting to avoid f-string backslash issue
        priority_list = []
        for s in strategies:
            group_id = s.get('group_id')
            priority = 'HIGH' if s.get('changes_screen') else 'LOW'
            priority_list.append(f"{group_id}({priority})")
        print(f"üîç Priority order: {priority_list}")
    
    print(f"üîç Total click targets: {len(click_targets)}")
    return click_targets

def check_recent_splash_attempts(fdom_path: str) -> bool:
    """Check if we've made recent splash screen attempts (prevent infinite loops)"""
    try:
        if not os.path.exists(fdom_path):
            return False
        
        with open(fdom_path, 'r', encoding='utf-8') as f:
            fdom_data = json.load(f)
        
        attempts = fdom_data.get('metadata', {}).get('splash_attempts', [])
        
        # Check last 3 attempts in last 60 seconds
        current_time = time.time()
        recent_attempts = [a for a in attempts if current_time - a.get('timestamp', 0) < 60]
        
        if len(recent_attempts) >= 3:
            print(f"üõë LOOP PREVENTION: {len(recent_attempts)} attempts in last 60 seconds")
            return True
        
        return False
        
    except Exception:
        return False

def record_splash_attempt(fdom_path: str, group_id: str, coordinates: List[int], success: bool):
    """Record splash screen attempt for loop prevention"""
    try:
        if not os.path.exists(fdom_path):
            return
        
        with open(fdom_path, 'r', encoding='utf-8') as f:
            fdom_data = json.load(f)
        
        if 'metadata' not in fdom_data:
            fdom_data['metadata'] = {}
        
        if 'splash_attempts' not in fdom_data['metadata']:
            fdom_data['metadata']['splash_attempts'] = []
        
        attempt = {
            'timestamp': time.time(),
            'group_id': group_id,
            'coordinates': coordinates,
            'success': success,
            'datetime': datetime.now().isoformat()
        }
        
        fdom_data['metadata']['splash_attempts'].append(attempt)
        
        # Keep only last 10 attempts
        fdom_data['metadata']['splash_attempts'] = fdom_data['metadata']['splash_attempts'][-10:]
        
        with open(fdom_path, 'w', encoding='utf-8') as f:
            json.dump(fdom_data, f, indent=2, ensure_ascii=False)
        
        print(f"üìù Recorded splash attempt: {group_id} ‚Üí {'SUCCESS' if success else 'FAILED'}")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Could not record attempt: {e}")

def take_new_app_screenshot(original_screenshot_path: str) -> Optional[str]:
    """Take a new screenshot using the SAME method that successfully took the original"""
    try:
        from PIL import Image
        import mss
        import os
        
        # Generate new screenshot path
        dir_path = os.path.dirname(original_screenshot_path)
        base_name = os.path.basename(original_screenshot_path)
        name, ext = os.path.splitext(base_name)
        new_screenshot_path = os.path.join(dir_path, f"{name}_post_splash{ext}")
        
        # ‚úÖ DETECT APP DYNAMICALLY FROM SCREENSHOT PATH
        # Extract app name from path: apps/powerpnt/screenshots/S001.png ‚Üí powerpnt
        path_parts = original_screenshot_path.replace('\\', '/').split('/')
        app_name = None
        for i, part in enumerate(path_parts):
            if part == 'apps' and i + 1 < len(path_parts):
                app_name = path_parts[i + 1]
                break
        
        if not app_name:
            print("‚ùå Could not extract app name from screenshot path")
            return None
        
        print(f"üîç Detected app: {app_name}")
        
        # ‚úÖ FIND THE ACTUAL APP WINDOW (NOT HARDCODED BLENDER)
        gui_api = SimpleWindowAPI()
        
        # Try different window title patterns for the app
        possible_titles = [
            app_name,
            app_name.capitalize(), 
            app_name.upper(),
            "PowerPoint" if app_name == "powerpnt" else app_name,
            "Blender" if app_name == "blender" else app_name
        ]
        
        app_window_id = None
        for title in possible_titles:
            app_window_id = gui_api.find_window(title)
            if app_window_id:
                print(f"‚úÖ Found window with title: {title}")
                break
        
        if app_window_id:
            window_info = gui_api.get_window_info(app_window_id)
            
            if window_info and 'window_data' in window_info:
                pos = window_info['window_data']['position']
                size = window_info['window_data']['size']
                
                # Create window bounding box (same as AppController)
                window_bbox = {
                    'left': pos['x'],
                    'top': pos['y'], 
                    'width': size['width'],
                    'height': size['height']
                }
                
                print(f"üîç DEBUG: Window bbox = {window_bbox}")
                
                # ‚úÖ EXACT SAME CAPTURE METHOD AS S001.png
                with mss.mss() as sct:
                    # Capture just the window area
                    window_screenshot = sct.grab(window_bbox)
                    
                    # Convert to PIL Image (same format)
                    img = Image.frombytes('RGB', window_screenshot.size, window_screenshot.bgra, 'raw', 'BGRX')
                    
                    # Save screenshot
                    img.save(new_screenshot_path)
                    
                    # Calculate file size
                    file_size = os.path.getsize(new_screenshot_path) / (1024 * 1024)
                    
                    print(f"üì∏ App-only screenshot saved: {os.path.basename(new_screenshot_path)} ({file_size:.1f} MB)")
                    print(f"üéØ Captured area: {window_bbox['width']}√ó{window_bbox['height']} pixels from app window")
                    
                    return new_screenshot_path
            else:
                print("‚ùå No window_data in window_info")
        else:
            print(f"‚ùå Could not find {app_name} window")
        
        return None
        
    except Exception as e:
        print(f"‚ùå New screenshot failed: {e}")
        import traceback
        traceback.print_exc()
        return None


==================================================

Path: utils\seraphine_pipeline\yolo_detector.py
File: yolo_detector.py
Code:
"""
Clean YOLO detection utility - extracted from yolo_onnx.py
No imports from original files allowed.
"""
import time
import math
import numpy as np
import cv2
import onnxruntime as ort
from PIL import Image
from dataclasses import dataclass
from typing import Tuple, List, Dict, Any
import argparse
import json
import os
import sys
from .helpers import debug_print

@dataclass
class YOLOConfig:
    """Configuration for YOLO inference pipeline"""
    conf_threshold: float = 0.1
    iou_threshold: float = 0.1
    max_resolution: Tuple[int, int] = (2560, 2560)
    enable_timing: bool = True
    enable_debug: bool = False
    model_path: str = "models/model_dynamic.onnx"
    # üöÄ Simple content filtering
    enable_content_filtering: bool = True
    min_content_pixels: int = 5  # Minimum content pixels to keep box

def filter_sparse_boxes_ultra_fast(image_np, detections, min_content_pixels=50):
    """
    Ultra-fast sparse content filtering using simple pixel counting
    
    Strategy: Count pixels that deviate significantly from local mean
    Args:
        image_np: numpy array image (BGR or RGB format)
        detections: list of detection dictionaries
        min_content_pixels: minimum content pixels to keep box
    """
    if len(detections) == 0:
        return detections, 0
    
    filtered_detections = []
    filtered_count = 0
    
    for detection in detections:
        x1, y1, x2, y2 = map(int, detection['bbox'])
        
        # Quick bounds check
        h, w = image_np.shape[:2]
        if x1 >= w or y1 >= h or x2 <= x1 or y2 <= y1:
            filtered_count += 1
            continue
            
        # Clamp coordinates
        x1, y1 = max(0, x1), max(0, y1)
        x2, y2 = min(w, x2), min(h, y2)
        
        # Extract box region
        box_crop = image_np[y1:y2, x1:x2]
        if box_crop.size == 0:
            filtered_count += 1
            continue
        
        # Convert to grayscale if needed
        if len(box_crop.shape) == 3:
            # Fast grayscale conversion
            gray = np.dot(box_crop[...,:3], [0.299, 0.587, 0.114]).astype(np.uint8)
        else:
            gray = box_crop
        
        # Ultra-fast content detection
        mean_val = np.mean(gray)
        
        # Count pixels that deviate from mean (content pixels)
        content_pixels = np.sum(np.abs(gray.astype(np.float32) - mean_val) > 15)
        
        # Keep box if it has enough content pixels
        if content_pixels >= min_content_pixels:
            filtered_detections.append(detection)
        else:
            filtered_count += 1
    
    return filtered_detections, filtered_count

class CPUModelCache:
    """Singleton cache for ONNX models with CPU optimization"""
    _instance = None
    _session = None
    _model_path = None
    _input_name = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def get_session(self, model_path):
        if self._session is None or self._model_path != model_path:
            if self._session is None:
                debug_print("  Loading CPU-optimized YOLO model...")
            else:
                debug_print("  Reloading YOLO model...")
            load_start = time.time()
            
            so = ort.SessionOptions()
            so.log_severity_level = 3
            so.enable_mem_pattern = True
            so.enable_mem_reuse = True
            so.enable_cpu_mem_arena = True
            so.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
            
            providers = [("CPUExecutionProvider", {
                "enable_cpu_mem_arena": True,
                "arena_extend_strategy": "kSameAsRequested",
                "initial_chunk_size_bytes": 1024 * 1024 * 32,
                "max_mem": 1024 * 1024 * 512
            })]
            
            self._session = ort.InferenceSession(model_path, sess_options=so, providers=providers)
            self._model_path = model_path
            self._input_name = self._session.get_inputs()[0].name
            
            load_time = time.time() - load_start
            debug_print(f"  YOLO model loading: {load_time:.3f}s")
        
        return self._session, self._input_name
    
    def reset(self):
        """Reset the model cache to force reload"""
        self._session = None
        self._model_path = None
        self._input_name = None
        debug_print("  üîÑ YOLO model cache cleared")

# Global instance
model_cache = CPUModelCache()

def round_to_multiple(x, base):
    return int(base * math.ceil(x / base))

def load_and_prepare_image_ultra_fast(img_path, max_resolution, enable_timing=True):
    """üöÄ ULTRA-FAST: Optimized preprocessing pipeline with minimal memory allocations"""
    start_time = time.time()
    if enable_timing:
        debug_print(f"üì∏ YOLO: Loading and preparing image: {img_path}")
    
    load_start = time.time()
    # Load directly as BGR (OpenCV native format)
    img_bgr = cv2.imread(img_path, cv2.IMREAD_COLOR)
    load_time = time.time() - load_start
    
    orig_h, orig_w = img_bgr.shape[:2]
    target_w = min(round_to_multiple(orig_w, 32), max_resolution[0])
    target_h = min(round_to_multiple(orig_h, 32), max_resolution[1])
    
    resize_start = time.time()
    # üöÄ OPTIMIZATION 1: Resize in BGR first (avoid extra conversion)
    # üöÄ OPTIMIZATION 2: Use INTER_AREA for downscaling (faster + better quality)
    if target_w < orig_w or target_h < orig_h:
        interpolation = cv2.INTER_AREA  # Faster for downscaling
    else:
        interpolation = cv2.INTER_LINEAR  # Better for upscaling
    
    img_resized_bgr = cv2.resize(img_bgr, (target_w, target_h), interpolation=interpolation)
    resize_time = time.time() - resize_start
    
    convert_start = time.time()
    # üöÄ OPTIMIZATION 3: Direct BGR->RGB conversion + normalization in one step
    img_rgb = cv2.cvtColor(img_resized_bgr, cv2.COLOR_BGR2RGB)
    
    # üöÄ OPTIMIZATION 4: In-place operations with copy=False + faster multiply
    img_np = img_rgb.astype(np.float32, copy=False) * np.float32(1.0/255.0)  # Faster than division
    
    # üöÄ OPTIMIZATION 5: Direct transpose (no intermediate variable)
    input_tensor = img_np.transpose(2, 0, 1)[None, ...]
    convert_time = time.time() - convert_start
    
    scaling_factors = (orig_w / target_w, orig_h / target_h)
    
    if enable_timing:
        total_time = time.time() - start_time
        debug_print(f"  YOLO image preparation: {total_time:.3f}s")
        debug_print(f"   - Loading: {load_time:.3f}s")
        debug_print(f"   - Resizing ({orig_w}x{orig_h} ‚Üí {target_w}x{target_h}): {resize_time:.3f}s")
        debug_print(f"   - Array conversion: {convert_time:.3f}s")
    
    # Return original BGR for content filtering (no extra conversion needed)
    return input_tensor, (target_w, target_h), (orig_w, orig_h), scaling_factors, img_bgr

def run_inference_optimized(model_path, input_tensor, enable_timing=True):
    start_time = time.time()
    if enable_timing:
        debug_print(f"üß† YOLO: Running CPU-optimized inference...")
    
    cache_start = time.time()
    session, input_name = model_cache.get_session(model_path)
    cache_time = time.time() - cache_start
    
    prep_start = time.time()
    input_dict = {input_name: input_tensor}
    prep_time = time.time() - prep_start
    
    inference_start = time.time()
    output = session.run(None, input_dict)
    inference_time = time.time() - inference_start
    
    if enable_timing:
        total_time = time.time() - start_time
        debug_print(f"  YOLO CPU timing breakdown:")
        debug_print(f"   - Cache/session access: {cache_time:.3f}s")
        debug_print(f"   - Data preparation: {prep_time:.3f}s")
        debug_print(f"   - CPU inference: {inference_time:.3f}s")
        debug_print(f"   - Total: {total_time:.3f}s")
    
    return output

def fast_nms_opencv(boxes, scores, iou_threshold):
    if len(boxes) == 0:
        return []
    
    boxes_cv = []
    for box in boxes:
        x1, y1, x2, y2 = box
        boxes_cv.append([float(x1), float(y1), float(x2 - x1), float(y2 - y1)])
    
    indices = cv2.dnn.NMSBoxes(
        boxes_cv, scores.tolist(), 
        score_threshold=0.0, nms_threshold=float(iou_threshold)
    )
    
    return indices.flatten() if len(indices) > 0 else []

def xywh2xyxy_vectorized(boxes, scaling_factors):
    xy = boxes[:, :2]
    wh = boxes[:, 2:]
    xy1 = xy - wh * 0.5
    xy2 = xy + wh * 0.5
    xyxy = np.concatenate([xy1, xy2], axis=1)
    xyxy[:, [0, 2]] *= scaling_factors[0]
    xyxy[:, [1, 3]] *= scaling_factors[1]
    return xyxy

def postprocess_optimized(output, input_size, orig_size, scaling_factors, 
                         conf_thres=0.1, iou_thres=0.1, enable_timing=True, enable_debug=False, 
                         batch_idx=0):
    """
    üöÄ OPTIMIZED: Removed memory pool, cleaner postprocessing
    """
    start_time = time.time()
    if enable_timing:
        debug_print(f"üîß YOLO: Postprocessing detections (VECTORIZED)...")
    
    # Handle batch output
    if len(output[0].shape) == 3:  # Batch output
        predictions = np.squeeze(output[0][batch_idx])
    else:  # Single image output
        predictions = np.squeeze(output[0])
        
    if predictions.shape[0] not in [5, 84]:
        debug_print(f"‚ö†Ô∏è  YOLO: Unexpected shape: {predictions.shape}")
        return []

    predictions = predictions.transpose()
    
    if enable_debug:
        debug_print(f"  YOLO Debug: Processing {len(predictions)} predictions")
    
    if predictions.shape[1] == 5:
        confs = predictions[:, 4]
        class_ids = np.zeros(len(confs), dtype=np.int32)
    else:
        obj_conf = predictions[:, 4]
        class_confs = predictions[:, 5:]
        class_ids = np.argmax(class_confs, axis=1)
        class_scores = class_confs[np.arange(len(class_confs)), class_ids]
        confs = obj_conf * class_scores

    keep_mask = confs > conf_thres
    if not np.any(keep_mask):
        if enable_timing:
            debug_print("‚ö†Ô∏è  YOLO: No detections above confidence threshold.")
        return []

    valid_predictions = predictions[keep_mask]
    valid_confs = confs[keep_mask]
    
    if enable_debug:
        debug_print(f"  YOLO Debug: {len(valid_predictions)} detections after confidence filtering")

    boxes = xywh2xyxy_vectorized(valid_predictions[:, :4], scaling_factors)
    keep_indices = fast_nms_opencv(boxes, valid_confs, iou_threshold=iou_thres)
    
    if len(keep_indices) == 0:
        if enable_timing:
            debug_print("‚ö†Ô∏è  YOLO: No detections after NMS.")
        return []
    
    final_boxes = boxes[keep_indices]
    
    if enable_timing:
        total_time = time.time() - start_time
        debug_print(f"  YOLO Postprocessing (VECTORIZED): {total_time:.3f}s")
        debug_print(f"  YOLO Found {len(final_boxes)} detections after filtering")
    
    return final_boxes.astype(int).tolist()

def load_and_prepare_image_from_pil(pil_image, max_resolution, enable_timing=True):
    """üöÄ Load and prepare from PIL Image (no file I/O)"""
    start_time = time.time()
    if enable_timing:
        debug_print(f"üì∏ YOLO: Preparing PIL image")
    
    # Convert PIL to BGR numpy array directly
    img_rgb = np.array(pil_image.convert('RGB'))
    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
    
    orig_h, orig_w = img_bgr.shape[:2]
    target_w = min(round_to_multiple(orig_w, 32), max_resolution[0])
    target_h = min(round_to_multiple(orig_h, 32), max_resolution[1])
    
    resize_start = time.time()
    # üöÄ OPTIMIZATION 1: Use cv2 resize instead of PIL (faster)
    img_resized_bgr = cv2.resize(img_bgr, (target_w, target_h), interpolation=cv2.INTER_AREA)
    resize_time = time.time() - resize_start
    
    convert_start = time.time()
    # üöÄ OPTIMIZATION 2: Direct normalization in one step
    norm_img = img_resized_bgr.astype(np.float32, copy=False) * np.float32(1.0/255.0)
    norm_img -= np.array([0.485, 0.456, 0.406], dtype=np.float32)
    norm_img /= np.array([0.229, 0.224, 0.225], dtype=np.float32)
    
    # üöÄ OPTIMIZATION 3: Direct transpose
    norm_img = norm_img.transpose(2, 0, 1)[np.newaxis, :]
    
    convert_time = time.time() - convert_start
    
    scaling_factors = (orig_w / target_w, orig_h / target_h)
    
    if enable_timing:
        total_time = time.time() - start_time
        debug_print(f"  YOLO image preparation: {total_time:.3f}s")
        debug_print(f"   - Loading: {resize_time:.3f}s")
        debug_print(f"   - Array conversion: {convert_time:.3f}s")
    
    return norm_img, (target_w, target_h), (orig_w, orig_h), scaling_factors, img_resized_bgr

class YOLODetector:
    """üöÄ OPTIMIZED YOLO detector class with ultra-fast content filtering"""
    
    def __init__(self, config: YOLOConfig = None):
        self.config = config or YOLOConfig()
    
    def detect(self, image_input) -> List[Dict[str, Any]]:
        """
        Run YOLO detection on image
        Args:
            image_input: str (file path) or PIL.Image
        """
        if isinstance(image_input, str):
            # File path - use existing fast loading
            input_tensor, input_size, orig_size, scaling_factors, content_image = load_and_prepare_image_ultra_fast(
                image_input, self.config.max_resolution, self.config.enable_timing
            )
        else:
            # PIL Image - use new PIL loading
            input_tensor, input_size, orig_size, scaling_factors, content_image = load_and_prepare_image_from_pil(
                image_input, self.config.max_resolution, self.config.enable_timing
            )
        
        total_start = time.time()
        
        if self.config.enable_timing:
            debug_print(f"\nüéØ Starting YOLO detection pipeline...")
            debug_print(f"ü§ñ Model: {self.config.model_path}")
            if self.config.enable_content_filtering:
                debug_print(f"üöÄ Content filtering: ENABLED (min pixels: {self.config.min_content_pixels})")
            debug_print("=" * 60)
        
        output = run_inference_optimized(self.config.model_path, input_tensor, self.config.enable_timing)
        
        boxes_raw = postprocess_optimized(
            output, input_size, orig_size, scaling_factors,
            self.config.conf_threshold, self.config.iou_threshold, 
            self.config.enable_timing, self.config.enable_debug
        )
        
        # Convert to standardized format
        detections = []
        for i, box in enumerate(boxes_raw):
            x1, y1, x2, y2 = box
            clipped_bbox = self.clip_bbox_to_image_bounds([x1, y1, x2, y2], orig_size[0], orig_size[1])
            if clipped_bbox:
                detections.append({
                    "bbox": clipped_bbox,
                    "type": "icon",
                    "source": "yolo",
                    "confidence": 1.0,
                    "id": i
                })
        
        # üöÄ Ultra-fast content filtering (using already loaded image)
        if self.config.enable_content_filtering and len(detections) > 0:
            filter_start = time.time()
            detections, filtered_count = filter_sparse_boxes_ultra_fast(
                content_image, detections, self.config.min_content_pixels
            )
            filter_time = time.time() - filter_start
            
            if self.config.enable_timing and filtered_count > 0:
                debug_print(f"  üöÄ Content filtering: {filter_time:.3f}s")
                debug_print(f"    Filtered out {filtered_count} sparse boxes ({len(detections)} kept)")
        
        if self.config.enable_timing:
            total_time = time.time() - total_start
            debug_print("=" * 60)
            debug_print(f"  üéØ YOLO Pipeline completed in {total_time:.3f}s")
            debug_print(f"  Final result: {len(detections)} quality YOLO detections")
        
        return detections
    
    def clip_bbox_to_image_bounds(self, bbox, image_width, image_height):
        """Clip bounding box coordinates to image boundaries"""
        x1, y1, x2, y2 = bbox
        
        # Clip to image bounds
        x1 = max(0, min(x1, image_width))
        y1 = max(0, min(y1, image_height))
        x2 = max(0, min(x2, image_width))
        y2 = max(0, min(y2, image_height))
        
        # Ensure valid box (x2 > x1, y2 > y1)
        if x2 <= x1 or y2 <= y1:
            return None  # Invalid box
        
        return [x1, y1, x2, y2]

def main():
    """CLI interface for YOLO detector"""
    parser = argparse.ArgumentParser(
        description="YOLO Object Detection with Content Filtering",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python yolo_detector.py image.jpg
  python yolo_detector.py image.jpg --model custom_model.onnx --conf 0.25
  python yolo_detector.py image.jpg --output results.json --format json
  python yolo_detector.py image.jpg --no-timing --no-content-filter
  python yolo_detector.py *.jpg --batch --output-dir results/
        """
    )
    
    # Input arguments
    parser.add_argument(
        "images", 
        nargs="+", 
        help="Input image path(s). Supports glob patterns for batch processing."
    )
    
    # Model configuration
    parser.add_argument(
        "--model", "-m",
        default="models/model_dynamic.onnx",
        help="Path to ONNX model file (default: models/model_dynamic.onnx)"
    )
    
    # Detection thresholds
    parser.add_argument(
        "--conf", "-c",
        type=float,
        default=0.1,
        help="Confidence threshold for detections (default: 0.1)"
    )
    
    parser.add_argument(
        "--iou", "-i",
        type=float,
        default=0.1,
        help="IoU threshold for Non-Maximum Suppression (default: 0.1)"
    )
    
    # Resolution settings
    parser.add_argument(
        "--max-width",
        type=int,
        default=2560,
        help="Maximum width for input images (default: 2560)"
    )
    
    parser.add_argument(
        "--max-height",
        type=int,
        default=2560,
        help="Maximum height for input images (default: 2560)"
    )
    
    # Content filtering
    parser.add_argument(
        "--no-content-filter",
        action="store_true",
        help="Disable content filtering for sparse boxes"
    )
    
    parser.add_argument(
        "--min-content-pixels",
        type=int,
        default=5,
        help="Minimum content pixels to keep a detection (default: 5)"
    )
    
    # Output options
    parser.add_argument(
        "--output", "-o",
        help="Output file path. If not specified, prints to stdout."
    )
    
    parser.add_argument(
        "--format", "-f",
        choices=["json", "csv", "txt", "simple"],
        default="simple",
        help="Output format (default: simple)"
    )
    
    parser.add_argument(
        "--output-dir",
        help="Output directory for batch processing. Creates files with same name + '_detections.json'"
    )
    
    # Display options
    parser.add_argument(
        "--no-timing",
        action="store_true",
        help="Disable timing information"
    )
    
    parser.add_argument(
        "--debug",
        action="store_true",
        help="Enable debug output"
    )
    
    parser.add_argument(
        "--quiet", "-q",
        action="store_true",
        help="Minimal output (only results)"
    )
    
    # Batch processing
    parser.add_argument(
        "--batch",
        action="store_true",
        help="Enable batch processing mode"
    )
    
    args = parser.parse_args()
    
    # Validate arguments
    if not os.path.exists(args.model):
        debug_print(f"‚ùå Error: Model file not found: {args.model}", file=sys.stderr)
        sys.exit(1)
    
    if args.output_dir and not args.batch:
        debug_print("‚ö†Ô∏è  Warning: --output-dir only used in batch mode", file=sys.stderr)
    
    # Create YOLO configuration
    config = YOLOConfig(
        conf_threshold=args.conf,
        iou_threshold=args.iou,
        max_resolution=(args.max_width, args.max_height),
        enable_timing=not args.no_timing and not args.quiet,
        enable_debug=args.debug,
        model_path=args.model,
        enable_content_filtering=not args.no_content_filter,
        min_content_pixels=args.min_content_pixels
    )
    
    # Initialize detector
    detector = YOLODetector(config)
    
    # Process images
    if args.batch or len(args.images) > 1:
        process_batch(detector, args)
    else:
        process_single(detector, args.images[0], args)

def process_single(detector, image_path, args):
    """Process a single image"""
    if not os.path.exists(image_path):
        debug_print(f"‚ùå Error: Image file not found: {image_path}", file=sys.stderr)
        sys.exit(1)
    
    try:
        detections = detector.detect(image_path)
        output_results(detections, image_path, args)
        
    except Exception as e:
        debug_print(f"‚ùå Error processing {image_path}: {e}", file=sys.stderr)
        if args.debug:
            import traceback
            traceback.print_exc()
        sys.exit(1)

def process_batch(detector, args):
    """Process multiple images in batch mode"""
    import glob
    
    # Expand glob patterns
    all_images = []
    for pattern in args.images:
        matches = glob.glob(pattern)
        if matches:
            all_images.extend(matches)
        else:
            if os.path.exists(pattern):
                all_images.append(pattern)
            else:
                debug_print(f"‚ö†Ô∏è  Warning: No matches for pattern: {pattern}", file=sys.stderr)
    
    if not all_images:
        debug_print("‚ùå Error: No valid images found", file=sys.stderr)
        sys.exit(1)
    
    # Create output directory if specified
    if args.output_dir:
        os.makedirs(args.output_dir, exist_ok=True)
    
    results = {}
    successful = 0
    failed = 0
    
    if not args.quiet:
        debug_print(f"üöÄ Processing {len(all_images)} images in batch mode...")
        debug_print("=" * 60)
    
    for i, image_path in enumerate(all_images, 1):
        if not args.quiet:
            debug_print(f"\n[{i}/{len(all_images)}] Processing: {image_path}")
        
        try:
            detections = detector.detect(image_path)
            results[image_path] = detections
            successful += 1
            
            # Save individual results if output directory specified
            if args.output_dir:
                base_name = os.path.splitext(os.path.basename(image_path))[0]
                output_file = os.path.join(args.output_dir, f"{base_name}_detections.json")
                with open(output_file, 'w') as f:
                    json.dump({
                        "image": image_path,
                        "detections": detections,
                        "count": len(detections)
                    }, f, indent=2)
                if not args.quiet:
                    debug_print(f"  üíæ Saved results to: {output_file}")
            
        except Exception as e:
            debug_print(f"‚ùå Error processing {image_path}: {e}", file=sys.stderr)
            results[image_path] = {"error": str(e)}
            failed += 1
    
    # Output batch summary
    if not args.quiet:
        debug_print("\n" + "=" * 60)
        debug_print(f"üìä Batch processing complete:")
        debug_print(f"  ‚úÖ Successful: {successful}")
        debug_print(f"  ‚ùå Failed: {failed}")
        debug_print(f"  üìÅ Total images: {len(all_images)}")
    
    # Output combined results
    if not args.output_dir:
        output_batch_results(results, args)

def output_results(detections, image_path, args):
    """Output detection results in specified format"""
    if args.format == "json":
        result = {
            "image": image_path,
            "detections": detections,
            "count": len(detections)
        }
        output_text = json.dumps(result, indent=2)
        
    elif args.format == "csv":
        lines = ["image,x1,y1,x2,y2,type,confidence,source"]
        for det in detections:
            bbox = det["bbox"]
            lines.append(f"{image_path},{bbox[0]},{bbox[1]},{bbox[2]},{bbox[3]},{det['type']},{det['confidence']},{det['source']}")
        output_text = "\n".join(lines)
        
    elif args.format == "txt":
        lines = [f"Image: {image_path}", f"Detections: {len(detections)}", ""]
        for i, det in enumerate(detections):
            bbox = det["bbox"]
            lines.append(f"Detection {i+1}: [{bbox[0]}, {bbox[1]}, {bbox[2]}, {bbox[3]}] ({det['type']}, conf: {det['confidence']:.3f})")
        output_text = "\n".join(lines)
        
    else:  # simple format
        if args.quiet:
            output_text = str(len(detections))
        else:
            lines = [f"üì∑ {image_path}: {len(detections)} detections"]
            for i, det in enumerate(detections):
                bbox = det["bbox"]
                w, h = bbox[2] - bbox[0], bbox[3] - bbox[1]
                lines.append(f"  {i+1:2d}. [{bbox[0]:4d},{bbox[1]:4d}] {w:3d}x{h:3d} ({det['confidence']:.3f})")
            output_text = "\n".join(lines)
    
    # Output to file or stdout
    if args.output:
        with open(args.output, 'w') as f:
            f.write(output_text)
        if not args.quiet:
            debug_print(f"üíæ Results saved to: {args.output}")
    else:
        debug_print(output_text)

def output_batch_results(results, args):
    """Output batch results in specified format"""
    if args.format == "json":
        output_text = json.dumps(results, indent=2)
    else:
        # Summary format for other types
        lines = []
        total_detections = 0
        for image_path, detections in results.items():
            if isinstance(detections, list):
                count = len(detections)
                total_detections += count
                lines.append(f"{image_path}: {count} detections")
            else:
                lines.append(f"{image_path}: ERROR - {detections.get('error', 'Unknown error')}")
        
        lines.append(f"\nTotal detections across all images: {total_detections}")
        output_text = "\n".join(lines)
    
    if args.output:
        with open(args.output, 'w') as f:
            f.write(output_text)
        if not args.quiet:
            debug_print(f"üíæ Batch results saved to: {args.output}")
    else:
        debug_print(output_text)

if __name__ == "__main__":
    main()





==================================================

Path: utils\windowManager\__init__.py
File: __init__.py
Code:


==================================================

Path: utils\windowManager\window_functions.py
File: window_functions.py
Code:
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from windowManager.window_manager import WindowManager
import json
from typing import Tuple, List, Optional


class WindowController:
    def __init__(self):
        self.wm = WindowManager()
        self.window_lookup = {}  # Maps last 8 digits to full window data
        self.previous_window_ids = {}  # Track ID changes: hwnd -> previous_id
    
    def refresh_windows(self):
        """Refresh window data and update lookup table"""
        data = self.wm.get_structured_windows()
        self.window_lookup = {}
        
        # Build lookup table with last 8 digits of window ID
        for monitor_data in data["monitors"].values():
            for app_data in monitor_data["applications"].values():
                for window_id, window_data in app_data["windows"].items():
                    last_8 = window_id[-8:]
                    self.window_lookup[last_8] = {
                        'window_data': window_data,
                        'app_name': app_data['process_name'],
                        'full_id': window_id
                    }
        
        return data
    
    def print_windows_summary(self):
        """Print a clean summary of all windows organized by screen"""
        # Use the WindowManager's built-in structured output instead of duplicating logic
        self.refresh_windows()
        self.wm.print_structured_output(show_minimized=True)
        
        # Add the window ID legend for our command system
        print("\nüí° TIP: Use the last 8 characters of any Window ID for commands")
        print("   Example: If ID is 'window_12345678_abcdefgh', use 'abcdefgh' for commands")
    
    def _parse_mouse_args(self, parts: List[str], start_idx: int = 1) -> Tuple[str, Optional[int], Optional[int]]:
        """Parse common mouse command arguments (button, x, y)"""
        button = "left"
        x, y = None, None
        
        current_idx = start_idx
        
        # Check if first argument is a button type
        if (current_idx < len(parts) and 
            parts[current_idx].lower() in ['left', 'right', 'middle']):
            button = parts[current_idx].lower()
            current_idx += 1
        
        # Check for coordinates
        if current_idx + 1 < len(parts):
            try:
                x, y = int(parts[current_idx]), int(parts[current_idx + 1])
            except ValueError:
                pass
        
        return button, x, y
    
    def _handle_introspection_command(self, hwnd: Optional[int] = None) -> Tuple[bool, str]:
        """Handle both global and window-specific introspection commands"""
        if hwnd:
            return self.wm.introspect_window(hwnd)
        else:
            return self.wm.get_element_under_cursor()
    
    def _execute_single_command(self, command_str: str) -> Tuple[bool, str]:
        """Execute a single command - internal method for chaining"""
        parts = command_str.strip().split()
        if not parts:
            return False, "Empty command"
        
        # Global introspection commands (don't need window ID)
        if parts[0].lower() in ['hover', 'detect', 'inspect']:
            return self._handle_introspection_command()
        
        # Cursor commands
        elif parts[0].lower() == 'cursor':
            if len(parts) == 1:
                success, message, pos = self.wm.get_cursor_position()
                return success, message
            elif len(parts) == 3:
                try:
                    x, y = int(parts[1]), int(parts[2])
                    return self.wm.set_cursor_position(x, y)
                except ValueError:
                    return False, "Invalid cursor coordinates"
            else:
                return False, "Invalid cursor command"
        
        # Mouse commands - using helper for parsing
        elif parts[0].lower() == 'click':
            button, x, y = self._parse_mouse_args(parts)
            return self.wm.send_mouse_click(button, x, y)
        
        elif parts[0].lower() == 'doubleclick':
            button, x, y = self._parse_mouse_args(parts)
            return self.wm.send_mouse_double_click(button, x, y)
        
        elif parts[0].lower() == 'longclick':
            button = "left"
            duration = 1.0
            x, y = None, None
            
            try:
                if len(parts) >= 2 and parts[1].lower() in ['left', 'right', 'middle']:
                    button = parts[1].lower()
                    if len(parts) >= 3:
                        duration = float(parts[2])
                    if len(parts) >= 5:
                        x, y = int(parts[3]), int(parts[4])
                elif len(parts) >= 2:
                    duration = float(parts[1])
                    if len(parts) >= 4:
                        x, y = int(parts[2]), int(parts[3])
                
                return self.wm.send_mouse_long_click(button, duration, x, y)
            except ValueError:
                return False, "Invalid longclick parameters"
        
        # Scroll commands
        elif parts[0].lower() == 'scroll':
            if len(parts) < 2:
                return False, "Missing scroll direction"
            
            direction = parts[1].lower()
            amount = 3
            x, y = None, None
            
            try:
                if len(parts) >= 3 and parts[2].isdigit():
                    amount = int(parts[2])
                if len(parts) >= 5:
                    x, y = int(parts[3]), int(parts[4])
                elif len(parts) >= 4 and not parts[2].isdigit():
                    x, y = int(parts[2]), int(parts[3])
                
                return self.wm.send_mouse_scroll(direction, amount, x, y)
            except ValueError:
                return False, "Invalid scroll parameters"
        
        # Drag commands
        elif parts[0].lower() == 'drag':
            if len(parts) < 5:
                return False, "Missing drag coordinates"
            
            try:
                x1, y1, x2, y2 = int(parts[1]), int(parts[2]), int(parts[3]), int(parts[4])
                button = "left"
                duration = 0.5
                
                if len(parts) >= 6 and parts[5].lower() in ['left', 'right', 'middle']:
                    button = parts[5].lower()
                if len(parts) >= 7:
                    duration = float(parts[6])
                elif len(parts) >= 6 and parts[5].replace('.', '').isdigit():
                    duration = float(parts[5])
                
                return self.wm.send_mouse_drag(x1, y1, x2, y2, button, duration)
            except ValueError:
                return False, "Invalid drag parameters"
        
        # Keyboard commands
        elif parts[0].lower() == 'send':
            if len(parts) < 2:
                return False, "Missing key combination"
            
            key_combo = ' '.join(parts[1:])
            return self.wm.send_key_combination(key_combo)
        
        elif parts[0].lower() == 'type':
            if len(parts) < 2:
                return False, "Missing text to type"
            
            text = ' '.join(parts[1:])
            return self.wm.send_text(text)
        
        # System commands
        elif parts[0].lower() == 'computer':
            return self.wm.get_computer_name()
        
        elif parts[0].lower() == 'user':
            return self.wm.get_user_name()
        
        elif parts[0].lower() == 'keys':
            return self.wm.get_virtual_key_codes()
        
        # Message box command
        elif parts[0].lower() == 'msgbox':
            if len(parts) < 3:
                return False, "Missing msgbox parameters"
            
            title = parts[1]
            if len(parts) >= 6 and parts[-2:][0].isdigit():
                try:
                    x, y = int(parts[-2]), int(parts[-1])
                    text = ' '.join(parts[2:-2])
                    return self.wm.show_message_box(title, text, x, y)
                except ValueError:
                    text = ' '.join(parts[2:])
                    return self.wm.show_message_box(title, text)
            else:
                text = ' '.join(parts[2:])
                return self.wm.show_message_box(title, text)
        
        # Application launcher command
        elif parts[0].lower() == 'launch':
            if len(parts) < 3:
                return False, "Missing launch parameters. Usage: launch APP_NAME SCREEN_ID [normal]"
            
            app_name = parts[1]
            try:
                screen_id = int(parts[2])
                fullscreen = True if len(parts) < 4 else parts[3].lower() != 'normal'
                return self.wm.launch_application(app_name, screen_id, fullscreen)
            except ValueError:
                return False, "Invalid screen ID"
        
        # Window commands (require window ID)
        elif len(parts) >= 2:
            window_id_suffix = parts[0]
            command = parts[1]
            
            # Find window
            if window_id_suffix not in self.window_lookup:
                return False, f"Window ID '{window_id_suffix}' not found"
            
            window_info = self.window_lookup[window_id_suffix]
            window_data = window_info['window_data']
            hwnd = window_data['hwnd']
            
            # Execute window command
            if command == 'm':
                return self.wm.minimize_window(hwnd)
            elif command == 'M':
                return self.wm.maximize_window(hwnd)
            elif command.lower() == 'c':
                return self.wm.close_window(hwnd)
            elif command.lower() == 'f':
                return self.wm.smart_foreground(hwnd)
            elif command.lower() == 's':
                current_state = self.wm.get_window_state(hwnd)
                return True, f"Size: {window_data['size']['width']}x{window_data['size']['height']} | State: {current_state.upper()}"
            elif command.lower() == 'l':
                current_state = self.wm.get_window_state(hwnd)
                if current_state == "minimized":
                    return True, f"Position: MINIMIZED (last: {window_data['position']['x']}, {window_data['position']['y']}) Screen {window_data['monitor']} | State: {current_state.upper()}"
                else:
                    return True, f"Position: ({window_data['position']['x']}, {window_data['position']['y']}) Screen {window_data['monitor']} | State: {current_state.upper()}"
            elif command.lower() == 'resize' and len(parts) == 4:
                try:
                    width, height = int(parts[2]), int(parts[3])
                    return self.wm.resize_window(hwnd, width, height)
                except ValueError:
                    return False, "Invalid resize dimensions"
            elif command.lower() == 'move' and len(parts) == 4:
                try:
                    x, y = int(parts[2]), int(parts[3])
                    return self.wm.move_window(hwnd, x, y)
                except ValueError:
                    return False, "Invalid move coordinates"
            elif command.lower() == 'screen' and len(parts) == 5:
                try:
                    screen_id, x, y = int(parts[2]), int(parts[3]), int(parts[4])
                    return self.wm.move_window_to_screen_position(hwnd, screen_id, x, y)
                except ValueError:
                    return False, "Invalid screen move parameters"
            elif command.lower() == 'monitor' and len(parts) == 3:
                try:
                    monitor_id = int(parts[2])
                    return self.wm.move_window_to_monitor(hwnd, monitor_id)
                except ValueError:
                    return False, "Invalid monitor ID"
            elif command in ['i', 'inspect']:
                return self._handle_introspection_command(hwnd)
            elif command.lower() == 'tree':
                return self.wm.get_window_hierarchy_tree(hwnd)
            else:
                return False, f"Unknown window command: {command}"
        
        return False, f"Unknown command: {parts[0]}"
    
    def process_command(self, user_input):
        """Process user command (supports chaining with ' : ')"""
        user_input = user_input.strip()
        
        if user_input.lower() == 'q':
            return False, "Goodbye!"
        
        if user_input.lower() == 'r':
            self.print_windows_summary()
            return True, "Window list refreshed"
        
        # Check if this is a command chain
        if ' : ' in user_input:
            commands = [cmd.strip() for cmd in user_input.split(' : ')]
            print(f"üîó Executing command chain ({len(commands)} steps)...")
            
            overall_success = True
            
            for i, cmd in enumerate(commands):
                if not cmd:
                    continue
                
                print(f"   Step {i+1}: {cmd}")
                success, message = self._execute_single_command(cmd)
                
                if success:
                    print(f"   ‚úÖ {message}")
                else:
                    print(f"   ‚ùå {message}")
                    overall_success = False
                    print(f"   ‚ö†Ô∏è  Chain stopped at step {i+1}")
                    break
                
                # Adaptive delay based on command type
                import time
                if 'click' in cmd.lower() or 'focus' in cmd.lower() or cmd.lower().endswith('f'):
                    time.sleep(0.3)  # Longer delay after focus/click operations
                elif 'send' in cmd.lower() or 'type' in cmd.lower():
                    time.sleep(0.2)  # Medium delay for keyboard operations
                else:
                    time.sleep(0.1)  # Short delay for other operations
            
            if overall_success:
                return True, f"‚úÖ Command chain completed successfully ({len(commands)} steps)"
            else:
                return True, f"‚ö†Ô∏è  Command chain stopped at step {i+1}"
        
        # Single command execution
        success, message = self._execute_single_command(user_input)
        
        # Check if ID changed after operation (for window commands)
        self.refresh_windows()
        
        status = "‚úÖ" if success else "‚ùå"
        return True, f"{status} {message}"
    
    @staticmethod
    def get_command_legend():
        """Get the command legend from external file"""
        try:
            legend_path = os.path.join(os.path.dirname(__file__), 'legend.txt')
            with open(legend_path, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            return "‚ùå Legend file not found. Please ensure legend.txt exists in the windowManager directory."
        except Exception as e:
            return f"‚ùå Error reading legend file: {e}"
    
    def print_legend(self):
        """Print command legend"""
        print(self.get_command_legend())
    
    def run_interactive_mode(self):
        """Run the interactive window controller"""
        print("üöÄ Starting Interactive Window Manager...")
        
        # Initial display
        self.print_windows_summary()
        self.print_legend()
        
        while True:
            try:
                user_input = input("\nüíª Enter command (or 'q' to quit): ").strip()
                
                if not user_input:
                    continue
                
                continue_running, message = self.process_command(user_input)
                print(f"   {message}")
                
                if not continue_running:
                    break
                    
            except KeyboardInterrupt:
                print("\n\nüëã Interrupted by user. Goodbye!")
                break
            except Exception as e:
                print(f"‚ùå Error: {e}")


def main():
    """Main function to run the window controller"""
    try:
        controller = WindowController()
        controller.run_interactive_mode()
    except ImportError as e:
        print(f"‚ùå Import error: {e}")
        print("Make sure window_manager.py is in the correct location")
    except Exception as e:
        print(f"‚ùå Unexpected error: {e}")


if __name__ == "__main__":
    main()


==================================================

Path: utils\windowManager\window_manager.py
File: window_manager.py
Code:
import win32gui
import win32process
import win32api
import win32con
import psutil
from typing import List, Dict, Optional, Tuple
import ctypes
from ctypes import wintypes, byref
import json
import time
import hashlib
import os
import getpass
import shutil

# Make UI Automation imports conditional
try:
    import comtypes
    from comtypes.client import CreateObject
    UI_AUTOMATION_AVAILABLE = True
except ImportError:
    UI_AUTOMATION_AVAILABLE = False
    comtypes = None

def _initialize_ui_automation():
    """Initialize UI Automation and generate the required interfaces"""
    global UI_AUTOMATION_AVAILABLE
    if not UI_AUTOMATION_AVAILABLE:
        return None, None
    
    try:
        # Create the UI Automation object first - this generates the interfaces
        uia = CreateObject("CUIAutomation")
        
        # Now import the generated interfaces
        import comtypes.gen.UIAutomationClient as UIA
        return uia, UIA
    except Exception as e:
        print(f"Warning: UI Automation not available: {e}")
        UI_AUTOMATION_AVAILABLE = False
        return None, None

class WindowManager:
    def __init__(self):
        # Get all monitors
        self.monitors = self._get_monitors()
        self._previous_windows = {}  # Track windows for change detection
    
    def _get_monitors(self) -> List[Dict]:
        """Get information about all monitors using proper Windows API"""
        monitors = []
        
        def monitor_enum_proc(hmonitor, hdc, rect, data):
            try:
                monitor_info = win32api.GetMonitorInfo(hmonitor)
                monitor_rect = monitor_info['Monitor']
                work_area = monitor_info['Work']
                is_primary = monitor_info['Flags'] == win32con.MONITORINFOF_PRIMARY
                device_name = monitor_info['Device']
                
                # Calculate actual monitor dimensions
                width = monitor_rect[2] - monitor_rect[0]
                height = monitor_rect[3] - monitor_rect[1]
                
                monitors.append({
                    'handle': hmonitor,
                    'rect': list(monitor_rect),  # [left, top, right, bottom]
                    'work_area': list(work_area),
                    'width': width,
                    'height': height,
                    'primary': is_primary,
                    'device': device_name,
                    'position': {
                        'left': monitor_rect[0],
                        'top': monitor_rect[1],
                        'right': monitor_rect[2],
                        'bottom': monitor_rect[3]
                    }
                })
                print(f"Monitor detected: {device_name} - {width}x{height} at ({monitor_rect[0]}, {monitor_rect[1]}) Primary: {is_primary}")
            except Exception as e:
                print(f"Error getting monitor info: {e}")
                # Fallback
                rect_list = [rect.left, rect.top, rect.right, rect.bottom] if hasattr(rect, 'left') else list(rect)
                width = rect_list[2] - rect_list[0]
                height = rect_list[3] - rect_list[1]
                monitors.append({
                    'handle': hmonitor,
                    'rect': rect_list,
                    'work_area': rect_list,
                    'width': width,
                    'height': height,
                    'primary': len(monitors) == 0,
                    'device': f'Monitor_{len(monitors) + 1}',
                    'position': {
                        'left': rect_list[0],
                        'top': rect_list[1],
                        'right': rect_list[2],
                        'bottom': rect_list[3]
                    }
                })
            return True
        
        try:
            # Use ctypes to properly call EnumDisplayMonitors
            user32 = ctypes.windll.user32
            
            # Define the callback function type
            MonitorEnumProc = ctypes.WINFUNCTYPE(ctypes.c_bool,
                                                 wintypes.HMONITOR,
                                                 wintypes.HDC,
                                                 ctypes.POINTER(wintypes.RECT),
                                                 wintypes.LPARAM)
            
            def enum_proc(hmonitor, hdc, rect_ptr, data):
                rect = rect_ptr.contents
                return monitor_enum_proc(hmonitor, hdc, rect, data)
            
            callback = MonitorEnumProc(enum_proc)
            user32.EnumDisplayMonitors(None, None, callback, 0)
            
            # Sort monitors: primary first, then by left position
            monitors.sort(key=lambda m: (not m['primary'], m['position']['left']))
            
        except Exception as e:
            print(f"Monitor enumeration failed: {e}")
            # Fallback to single monitor
            try:
                width = win32api.GetSystemMetrics(win32con.SM_CXSCREEN)
                height = win32api.GetSystemMetrics(win32con.SM_CYSCREEN)
                monitors.append({
                    'handle': 0,
                    'rect': [0, 0, width, height],
                    'work_area': [0, 0, width, height],
                    'width': width,
                    'height': height,
                    'primary': True,
                    'device': 'Primary Monitor',
                    'position': {'left': 0, 'top': 0, 'right': width, 'bottom': height}
                })
            except:
                # Ultimate fallback
                monitors.append({
                    'handle': 0,
                    'rect': [0, 0, 1920, 1080],
                    'work_area': [0, 0, 1920, 1080],
                    'width': 1920,
                    'height': 1080,
                    'primary': True,
                    'device': 'Default Monitor',
                    'position': {'left': 0, 'top': 0, 'right': 1920, 'bottom': 1080}
                })
        
        print(f"Total monitors detected: {len(monitors)}")
        for i, monitor in enumerate(monitors):
            print(f"  Monitor {i+1}: {monitor['width']}x{monitor['height']} at ({monitor['position']['left']}, {monitor['position']['top']}) - {monitor['device']} {'(Primary)' if monitor['primary'] else ''}")
        
        return monitors
    
    def _get_window_monitor(self, rect: Tuple[int, int, int, int]) -> int:
        """Determine which monitor a window is primarily on"""
        x1, y1, x2, y2 = rect
        window_center_x = (x1 + x2) // 2
        window_center_y = (y1 + y2) // 2
        
        for i, monitor in enumerate(self.monitors):
            pos = monitor['position']
            if pos['left'] <= window_center_x <= pos['right'] and pos['top'] <= window_center_y <= pos['bottom']:
                return i + 1  # 1-based indexing
        
        return 1  # Default to primary monitor
    
    def _is_window_minimized(self, hwnd: int) -> bool:
        """Check if a window is minimized"""
        return win32gui.IsIconic(hwnd)
    
    def _get_process_name(self, pid: int) -> str:
        """Get process name from PID"""
        try:
            process = psutil.Process(pid)
            return process.name()
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            return "Unknown"
    
    def _generate_window_id(self, hwnd: int, pid: int, title: str) -> str:
        """Generate a unique window identifier"""
        # Combine HWND, PID, and title hash for a more stable ID
        title_hash = hashlib.md5(title.encode('utf-8', errors='ignore')).hexdigest()[:8]
        return f"{hwnd}_{pid}_{title_hash}"
    
    def _is_valid_window(self, hwnd: int) -> bool:
        """Check if window is valid for our purposes"""
        try:
            if not win32gui.IsWindow(hwnd):
                return False
            if not win32gui.IsWindowVisible(hwnd):
                return False
            
            # Allow windows with empty titles (some valid windows have no title)
            title = win32gui.GetWindowText(hwnd)
            
            # Skip windows with no size
            rect = win32gui.GetWindowRect(hwnd)
            if rect[2] - rect[0] <= 0 or rect[3] - rect[1] <= 0:
                return False
                
            return True
        except Exception:
            return False

    # =============== WINDOW CONTROL METHODS ===============
    
    def get_window_state(self, hwnd: int) -> str:
        """Get current window state - FIXED to use proper Windows API"""
        try:
            # Don't validate visibility here, just check if window exists
            if not win32gui.IsWindow(hwnd):
                return "invalid"
            
            if win32gui.IsIconic(hwnd):
                return "minimized"
            
            # Use GetWindowPlacement to check if maximized
            try:
                # Get window placement structure
                placement = win32gui.GetWindowPlacement(hwnd)
                # placement[1] is the show state
                if placement[1] == win32con.SW_SHOWMAXIMIZED:
                    return "maximized"
                elif placement[1] == win32con.SW_SHOWMINIMIZED:
                    return "minimized"
                else:
                    return "normal"
            except:
                # Fallback: check if window covers entire screen
                try:
                    rect = win32gui.GetWindowRect(hwnd)
                    window_width = rect[2] - rect[0]
                    window_height = rect[3] - rect[1]
                    
                    # Find which monitor this window is on
                    monitor_id = self._get_window_monitor(rect)
                    if monitor_id <= len(self.monitors):
                        monitor = self.monitors[monitor_id - 1]
                        # If window size matches monitor size (or close), consider it maximized
                        if (abs(window_width - monitor['width']) <= 20 and 
                            abs(window_height - monitor['height']) <= 50):  # Allow for title bars
                            return "maximized"
                    
                    return "normal"
                except:
                    return "normal"
                    
        except Exception as e:
            return "error"
    
    def maximize_window(self, hwnd: int) -> Tuple[bool, str]:
        """Maximize a window"""
        try:
            # Add timing delay before action
            time.sleep(0.1)
            
            if not self.is_valid_window(hwnd):
                return False, "Window is no longer valid"
            
            current_state = self.get_window_state(hwnd)
            if current_state == "maximized":
                return True, "Window is already maximized"
            
            win32gui.ShowWindow(hwnd, win32con.SW_MAXIMIZE)
            return True, "Window maximized"
        except Exception as e:
            return False, f"Failed to maximize: {e}"
    
    def minimize_window(self, hwnd: int) -> Tuple[bool, str]:
        """Minimize a window"""
        try:
            # Add timing delay before action
            time.sleep(0.1)
            
            if not self.is_valid_window(hwnd):
                return False, "Window is no longer valid"
            
            current_state = self.get_window_state(hwnd)
            if current_state == "minimized":
                return True, "Window is already minimized"
            
            win32gui.ShowWindow(hwnd, win32con.SW_MINIMIZE)
            return True, "Window minimized"
        except Exception as e:
            return False, f"Failed to minimize: {e}"
    
    def close_window(self, hwnd: int) -> Tuple[bool, str]:
        """Close a window"""
        try:
            # Add timing delay before action
            time.sleep(0.1)
            
            if not self.is_valid_window(hwnd):
                return False, "Window is no longer valid"
            
            win32gui.PostMessage(hwnd, win32con.WM_CLOSE, 0, 0)
            return True, "Window close signal sent"
        except Exception as e:
            return False, f"Failed to close: {e}"
    
    def smart_foreground(self, hwnd: int) -> Tuple[bool, str]:
        """Bring window to foreground using smart minimize/maximize technique with intermediate sizing"""
        try:
            # Add timing delay before action
            time.sleep(0.1)
            
            if not self.is_valid_window(hwnd):
                return False, "Window is no longer valid"
            
            # Store original state and position
            current_state = self.get_window_state(hwnd)
            rect = win32gui.GetWindowRect(hwnd)
            original_x, original_y = rect[0], rect[1]
            original_width = rect[2] - rect[0]
            original_height = rect[3] - rect[1]
            
            # Check if window is currently in foreground
            try:
                foreground_hwnd = win32gui.GetForegroundWindow()
                is_foreground = (foreground_hwnd == hwnd)
            except:
                is_foreground = False
            
            messages = []
            
            # If window is not in foreground, minimize it first
            if not is_foreground and current_state != "minimized":
                win32gui.ShowWindow(hwnd, win32con.SW_MINIMIZE)
                messages.append("minimized")
                time.sleep(1.5)  # Brief pause
            
            # Step 1: Restore and set to intermediate size (80% of screen)
            # Get monitor info for intermediate sizing
            monitor_info = win32api.GetMonitorInfo(win32api.MonitorFromWindow(hwnd, win32con.MONITOR_DEFAULTTONEAREST))
            work_area = monitor_info['Work']
            screen_width = work_area[2] - work_area[0]
            screen_height = work_area[3] - work_area[1]
            
            # Calculate intermediate size (80% of screen, centered)
            intermediate_width = int(screen_width * 0.8)
            intermediate_height = int(screen_height * 0.8)
            intermediate_x = work_area[0] + (screen_width - intermediate_width) // 2
            intermediate_y = work_area[1] + (screen_height - intermediate_height) // 2
            
            # Restore to normal first
            win32gui.ShowWindow(hwnd, win32con.SW_RESTORE)
            time.sleep(0.3)
            
            # Set intermediate size
            win32gui.SetWindowPos(
                hwnd,
                0,
                intermediate_x, intermediate_y, intermediate_width, intermediate_height,
                win32con.SWP_NOZORDER | win32con.SWP_NOACTIVATE
            )
            messages.append(f"resized to intermediate ({intermediate_width}x{intermediate_height})")
            time.sleep(1.0)  # Pause for intermediate state to settle
            
            # Step 2: FORCE RESTORE first, then maximize (this is key!)
            win32gui.ShowWindow(hwnd, win32con.SW_RESTORE)
            time.sleep(0.5)  # Let restore complete
            
            # Now maximize - this should work better after explicit restore
            win32gui.ShowWindow(hwnd, win32con.SW_MAXIMIZE)
            messages.append("maximized to full screen")
            time.sleep(1.0)  # Pause for maximize animation
            
            # Step 3: Double-check maximize worked, force it if needed
            current_state_after = self.get_window_state(hwnd)
            if current_state_after != "maximized":
                # Try alternative maximize approach
                win32gui.ShowWindow(hwnd, win32con.SW_SHOWMAXIMIZED)
                time.sleep(0.5)
                messages.append("force maximized (fallback)")
                
                # Final check
                final_state = self.get_window_state(hwnd)
                if final_state != "maximized":
                    messages.append(f"maximize attempted (final state: {final_state})")
            
            # Finally, bring to foreground
            try:
                win32gui.SetForegroundWindow(hwnd)
                messages.append("brought to foreground")
            except:
                # Use fallback method
                try:
                    current_thread = win32process.GetCurrentThreadId()
                    window_thread, _ = win32process.GetWindowThreadProcessId(hwnd)
                    
                    if current_thread != window_thread:
                        win32process.AttachThreadInput(current_thread, window_thread, True)
                        try:
                            win32gui.SetForegroundWindow(hwnd)
                            messages.append("brought to foreground (method 2)")
                        finally:
                            win32process.AttachThreadInput(current_thread, window_thread, False)
                except:
                    messages.append("attempted foreground (may be restricted)")
            
            return True, f"Enhanced smart foreground: {' ‚Üí '.join(messages)}"
                        
        except Exception as e:
            return False, f"Failed enhanced smart foreground: {e}"
    
    def resize_window(self, hwnd: int, width: int, height: int) -> Tuple[bool, str]:
        """Resize a window to specific dimensions"""
        try:
            # Add timing delay before action
            time.sleep(0.1)
            
            if not self.is_valid_window(hwnd):
                return False, "Window is no longer valid"
            
            # Get current position
            rect = win32gui.GetWindowRect(hwnd)
            current_x, current_y = rect[0], rect[1]
            
            # Restore window if minimized/maximized first
            if win32gui.IsIconic(hwnd) or self.get_window_state(hwnd) == "maximized":
                win32gui.ShowWindow(hwnd, win32con.SW_RESTORE)
            
            # Resize window keeping current position
            win32gui.SetWindowPos(
                hwnd, 
                0,  # Insert after (ignored with SWP_NOZORDER)
                current_x, current_y, width, height,
                win32con.SWP_NOZORDER | win32con.SWP_NOACTIVATE
            )
            
            # Verify the resize worked by checking new dimensions
            time.sleep(0.1)  # Small delay to let Windows process the change
            new_rect = win32gui.GetWindowRect(hwnd)
            new_width = new_rect[2] - new_rect[0]
            new_height = new_rect[3] - new_rect[1]
            
            # Consider it successful if we're close to target size (within 20 pixels)
            if abs(new_width - width) <= 20 and abs(new_height - height) <= 20:
                return True, f"Window resized to {new_width}x{new_height}"
            else:
                return True, f"Window resize attempted (target: {width}x{height}, actual: {new_width}x{new_height})"
                
        except Exception as e:
            return False, f"Failed to resize: {e}"
    
    def move_window(self, hwnd: int, x: int, y: int) -> Tuple[bool, str]:
        """Move window to specific absolute coordinates"""
        try:
            # Add timing delay before action
            time.sleep(0.1)
            
            if not self.is_valid_window(hwnd):
                return False, "Window is no longer valid"
            
            # Get current size
            rect = win32gui.GetWindowRect(hwnd)
            current_width = rect[2] - rect[0]
            current_height = rect[3] - rect[1]
            
            # Restore window if minimized/maximized first
            if win32gui.IsIconic(hwnd) or self.get_window_state(hwnd) == "maximized":
                win32gui.ShowWindow(hwnd, win32con.SW_RESTORE)
            
            # Move window keeping current size
            win32gui.SetWindowPos(
                hwnd,
                0,  # Insert after (ignored with SWP_NOZORDER)
                x, y, current_width, current_height,
                win32con.SWP_NOZORDER | win32con.SWP_NOACTIVATE
            )
            
            # Verify the move worked by checking new position
            time.sleep(2)  # Small delay to let Windows process the change
            new_rect = win32gui.GetWindowRect(hwnd)
            new_x, new_y = new_rect[0], new_rect[1]
            
            # Consider it successful if we're close to target position (within 10 pixels)
            if abs(new_x - x) <= 10 and abs(new_y - y) <= 10:
                return True, f"Window moved to ({new_x}, {new_y})"
            else:
                return True, f"Window move attempted (target: ({x}, {y}), actual: ({new_x}, {new_y}))"
                
        except Exception as e:
            return False, f"Failed to move: {e}"
    
    def move_window_to_monitor(self, hwnd: int, target_monitor: int) -> Tuple[bool, str]:
        """Move a window to a specific monitor (centered)"""
        try:
            if not self.is_valid_window(hwnd):
                return False, "Window is no longer valid"
            
            if target_monitor < 1 or target_monitor > len(self.monitors):
                return False, f"Invalid monitor ID. Available monitors: 1-{len(self.monitors)}"
            
            target_monitor_data = self.monitors[target_monitor - 1]
            
            # Get current window size
            current_rect = win32gui.GetWindowRect(hwnd)
            window_width = current_rect[2] - current_rect[0]
            window_height = current_rect[3] - current_rect[1]
            
            # Calculate position to center window on target monitor
            monitor_pos = target_monitor_data['position']
            target_x = monitor_pos['left'] + (target_monitor_data['width'] - window_width) // 2
            target_y = monitor_pos['top'] + (target_monitor_data['height'] - window_height) // 2
            
            # Ensure window doesn't go off-screen
            target_x = max(monitor_pos['left'], min(target_x, monitor_pos['right'] - window_width))
            target_y = max(monitor_pos['top'], min(target_y, monitor_pos['bottom'] - window_height))
            
            success, message = self.move_window(hwnd, target_x, target_y)
            if success:
                return True, f"Window moved to monitor {target_monitor} at ({target_x}, {target_y})"
            else:
                return False, message
                
        except Exception as e:
            return False, f"Failed to move to monitor: {e}"
    
    def move_window_to_screen_position(self, hwnd: int, screen_id: int, x: int, y: int) -> Tuple[bool, str]:
        """Move window to specific coordinates on a specific screen"""
        try:
            if not self.is_valid_window(hwnd):
                return False, "Window is no longer valid"
            
            if screen_id < 1 or screen_id > len(self.monitors):
                return False, f"Invalid screen ID. Available screens: 1-{len(self.monitors)}"
            
            screen_data = self.monitors[screen_id - 1]
            screen_pos = screen_data['position']
            
            # Convert relative screen coordinates to absolute coordinates
            absolute_x = screen_pos['left'] + x
            absolute_y = screen_pos['top'] + y
            
            # Validate coordinates are within screen bounds
            if x < 0 or y < 0:
                return False, f"Coordinates must be positive. Got ({x}, {y})"
            
            if x >= screen_data['width'] or y >= screen_data['height']:
                return False, f"Coordinates ({x}, {y}) are outside screen {screen_id} bounds ({screen_data['width']}x{screen_data['height']})"
            
            success, message = self.move_window(hwnd, absolute_x, absolute_y)
            if success:
                return True, f"Window moved to screen {screen_id} position ({x}, {y}) [absolute: ({absolute_x}, {absolute_y})]"
            else:
                return False, message
                
        except Exception as e:
            return False, f"Failed to move to screen position: {e}"

    # =============== EXISTING METHODS ===============
    
    def get_structured_windows(self) -> Dict:
        """Get all windows organized by monitor and application"""
        result = {
            "timestamp": time.time(),
            "monitors": {},
            "summary": {
                "total_monitors": len(self.monitors),
                "total_windows": 0,
                "total_apps": 0
            }
        }
        
        # Initialize monitor structure with correct dimensions
        for i, monitor in enumerate(self.monitors):
            monitor_id = i + 1
            result["monitors"][f"monitor_{monitor_id}"] = {
                "id": monitor_id,
                "rect": monitor['rect'],
                "work_area": monitor['work_area'],
                "width": monitor['width'],
                "height": monitor['height'],
                "primary": monitor['primary'],
                "device": monitor['device'],
                "applications": {},
                "window_count": 0
            }
        
        # Get all windows
        def enum_windows_proc(hwnd, data):
            if self._is_valid_window(hwnd):
                try:
                    # Get window info
                    title = win32gui.GetWindowText(hwnd)
                    _, pid = win32process.GetWindowThreadProcessId(hwnd)
                    proc_name = self._get_process_name(pid)
                    rect = win32gui.GetWindowRect(hwnd)
                    screen = self._get_window_monitor(rect)
                    minimized = self._is_window_minimized(hwnd)
                    window_id = self._generate_window_id(hwnd, pid, title)
                    
                    # Calculate window dimensions
                    width = rect[2] - rect[0]
                    height = rect[3] - rect[1]
                    
                    monitor_key = f"monitor_{screen}"
                    if monitor_key not in result["monitors"]:
                        return True  # Skip if monitor not found
                    
                    # Initialize app entry if not exists
                    if proc_name not in result["monitors"][monitor_key]["applications"]:
                        result["monitors"][monitor_key]["applications"][proc_name] = {
                            "process_name": proc_name,
                            "windows": {},
                            "window_count": 0,
                            "minimized_count": 0,
                            "visible_count": 0
                        }
                    
                    app_data = result["monitors"][monitor_key]["applications"][proc_name]
                    
                    # Add window details
                    window_data = {
                        "window_id": window_id,
                        "hwnd": hwnd,
                        "pid": pid,
                        "title": title,
                        "position": {
                            "x": rect[0],
                            "y": rect[1]
                        },
                        "size": {
                            "width": width,
                            "height": height
                        },
                        "rect": list(rect),
                        "minimized": minimized,
                        "visible": not minimized,
                        "monitor": screen
                    }
                    
                    app_data["windows"][window_id] = window_data
                    app_data["window_count"] += 1
                    
                    if minimized:
                        app_data["minimized_count"] += 1
                    else:
                        app_data["visible_count"] += 1
                    
                    result["monitors"][monitor_key]["window_count"] += 1
                    result["summary"]["total_windows"] += 1
                    
                except Exception as e:
                    # Skip windows that cause errors
                    pass
            return True
        
        win32gui.EnumWindows(enum_windows_proc, None)
        
        # Count unique applications
        all_apps = set()
        for monitor_data in result["monitors"].values():
            all_apps.update(monitor_data["applications"].keys())
        result["summary"]["total_apps"] = len(all_apps)
        
        return result
    
    def find_window_by_app(self, app_name: str) -> List[Dict]:
        """Find windows by application name - returns list format for backwards compatibility"""
        structured = self.get_structured_windows()
        matching_windows = []
        
        app_name_lower = app_name.lower()
        if not app_name_lower.endswith('.exe'):
            app_name_lower += '.exe'
        
        for monitor_data in structured["monitors"].values():
            for proc_name, app_data in monitor_data["applications"].items():
                if proc_name.lower() == app_name_lower:
                    for window_data in app_data["windows"].values():
                        # Convert back to old format for compatibility
                        matching_windows.append({
                            "hwnd": window_data["hwnd"],
                            "title": window_data["title"],
                            "pid": window_data["pid"],
                            "proc": proc_name,
                            "rect": window_data["rect"],
                            "screen": window_data["monitor"],
                            "minimized": window_data["minimized"]
                        })
        
        return matching_windows

    def print_structured_output(self, show_minimized: bool = True):
        """Print a clean, structured view of all windows"""
        data = self.get_structured_windows()
        
        print("=" * 80)
        print(f"WINDOW MANAGER - {data['summary']['total_windows']} windows across {data['summary']['total_monitors']} monitors")
        print("=" * 80)
        
        for monitor_key, monitor_data in data["monitors"].items():
            print(f"\nüì∫ MONITOR {monitor_data['id']} {'(PRIMARY)' if monitor_data['primary'] else ''}")
            print(f"   Resolution: {monitor_data['width']}x{monitor_data['height']}")
            print(f"   Position: {monitor_data['rect']}")
            print(f"   Windows: {monitor_data['window_count']}")
            print("-" * 60)
            
            if not monitor_data["applications"]:
                print("   No applications on this monitor")
                continue
            
            for app_name, app_data in monitor_data["applications"].items():
                visible_windows = [w for w in app_data["windows"].values() if not w["minimized"]]
                minimized_windows = [w for w in app_data["windows"].values() if w["minimized"]]
                
                print(f"\n   üñ•Ô∏è  {app_name}")
                print(f"      Total: {app_data['window_count']} | Visible: {len(visible_windows)} | Minimized: {len(minimized_windows)}")
                
                # Show visible windows
                for window in visible_windows:
                    title = window["title"][:50] + "..." if len(window["title"]) > 50 else window["title"]
                    print(f"      ‚îú‚îÄ üëÅÔ∏è  {title}")
                    print(f"      ‚îÇ   ID: {window['window_id']}")
                    print(f"      ‚îÇ   Position: ({window['position']['x']}, {window['position']['y']})")
                    print(f"      ‚îÇ   Size: {window['size']['width']}x{window['size']['height']}")
                
                # Show minimized windows if requested
                if show_minimized and minimized_windows:
                    print(f"      ‚îÇ")
                    for window in minimized_windows:
                        title = window["title"][:50] + "..." if len(window["title"]) > 50 else window["title"]
                        print(f"      ‚îú‚îÄ üì¶ {title} (minimized)")
                        print(f"      ‚îÇ   ID: {window['window_id']}")
        
        print("\n" + "=" * 80)

    # =============== NEW SYSTEM UTILITIES ===============
    
    def get_cursor_position(self) -> Tuple[bool, str, Optional[Tuple[int, int]]]:
        """Get current cursor position"""
        try:
            cursor_pos = win32gui.GetCursorPos()
            monitor_id = self._get_cursor_monitor(cursor_pos)
            return True, f"Cursor at ({cursor_pos[0]}, {cursor_pos[1]}) on Monitor {monitor_id}", cursor_pos
        except Exception as e:
            return False, f"Failed to get cursor position: {e}", None
    
    def set_cursor_position(self, x: int, y: int) -> Tuple[bool, str]:
        """Set cursor position to absolute coordinates"""
        try:
            # Add timing delay before action (shorter for cursor movements)
            time.sleep(0.05)
            
            win32api.SetCursorPos((x, y))
            
            # Verify the position was set correctly
            actual_pos = win32gui.GetCursorPos()
            if actual_pos == (x, y):
                monitor_id = self._get_cursor_monitor((x, y))
                return True, f"Cursor moved to ({x}, {y}) on Monitor {monitor_id}"
            else:
                monitor_id = self._get_cursor_monitor(actual_pos)
                return True, f"Cursor moved to ({actual_pos[0]}, {actual_pos[1]}) on Monitor {monitor_id} (close to target)"
        except Exception as e:
            return False, f"Failed to set cursor position: {e}"
    
    def _get_cursor_monitor(self, cursor_pos: Tuple[int, int]) -> int:
        """Determine which monitor the cursor is on"""
        x, y = cursor_pos
        for i, monitor in enumerate(self.monitors):
            pos = monitor['position']
            if pos['left'] <= x <= pos['right'] and pos['top'] <= y <= pos['bottom']:
                return i + 1
        return 1
    
    def show_message_box(self, title: str, message: str, x: int = None, y: int = None, 
                        width: int = 300, height: int = 150) -> Tuple[bool, str]:
        """Display a message box at specified location"""
        try:
            # If no position specified, use cursor position
            if x is None or y is None:
                cursor_pos = win32gui.GetCursorPos()
                x = cursor_pos[0] if x is None else x
                y = cursor_pos[1] if y is None else y
            
            # Create a simple message box using Windows API
            # Note: Standard MessageBox doesn't support custom positioning directly
            # We'll use a workaround by creating it normally then moving it
            
            # Use threading to show message box and return immediately
            import threading
            
            def show_box():
                try:
                    # Show message box (this will be at default position initially)
                    result = win32api.MessageBox(0, message, title, win32con.MB_OK | win32con.MB_TOPMOST)
                except:
                    pass
            
            # Start in background
            thread = threading.Thread(target=show_box)
            thread.daemon = True
            thread.start()
            
            # Brief delay to let it appear
            time.sleep(0.1)
            
            # Try to find and move the message box window
            try:
                def find_message_box(hwnd, param):
                    if win32gui.GetWindowText(hwnd) == title:
                        # Found our message box, move it
                        win32gui.SetWindowPos(hwnd, win32con.HWND_TOPMOST, 
                                            x, y, width, height, 
                                            win32con.SWP_SHOWWINDOW)
                        return False  # Stop enumeration
                    return True
                
                win32gui.EnumWindows(find_message_box, None)
            except:
                pass  # If we can't move it, that's okay
            
            return True, f"Message box '{title}' shown at ({x}, {y})"
            
        except Exception as e:
            return False, f"Failed to show message box: {e}"
    
    def get_computer_name(self) -> Tuple[bool, str]:
        """Get computer name"""
        try:
            computer_name = os.environ.get('COMPUTERNAME', 'Unknown')
            return True, f"Computer name: {computer_name}"
        except Exception as e:
            return False, f"Failed to get computer name: {e}"
    
    def get_user_name(self) -> Tuple[bool, str]:
        """Get current user name"""
        try:
            user_name = getpass.getuser()
            domain = os.environ.get('USERDOMAIN', '')
            if domain:
                full_name = f"{domain}\\{user_name}"
            else:
                full_name = user_name
            return True, f"User: {full_name}"
        except Exception as e:
            return False, f"Failed to get user name: {e}"
    
    # =============== VIRTUAL KEYBOARD OPERATIONS ===============
    
    def get_virtual_key_codes(self) -> Tuple[bool, str]:
        """Get all available virtual key codes - COMPREHENSIVE LIST"""
        try:
            key_categories = {
                "Modifier Keys": {
                    'CTRL': 0x11, 'LCTRL': 0xA2, 'RCTRL': 0xA3,
                    'ALT': 0x12, 'LALT': 0xA4, 'RALT': 0xA5,
                    'SHIFT': 0x10, 'LSHIFT': 0xA0, 'RSHIFT': 0xA1,
                    'WIN': 0x5B, 'LWIN': 0x5B, 'RWIN': 0x5C,
                },
                "Basic Keys": {
                    'ESC': 0x1B, 'TAB': 0x09, 'ENTER': 0x0D, 'SPACE': 0x20,
                    'BACKSPACE': 0x08, 'DELETE': 0x2E, 'INSERT': 0x2D,
                },
                "Navigation": {
                    'HOME': 0x24, 'END': 0x23, 'PAGEUP': 0x21, 'PAGEDOWN': 0x22,
                    'UP': 0x26, 'DOWN': 0x28, 'LEFT': 0x25, 'RIGHT': 0x27,
                },
                "Function Keys": {
                    'F1': 0x70, 'F2': 0x71, 'F3': 0x72, 'F4': 0x73, 'F5': 0x74, 'F6': 0x75,
                    'F7': 0x76, 'F8': 0x77, 'F9': 0x78, 'F10': 0x79, 'F11': 0x7A, 'F12': 0x7B,
                    'F13': 0x7C, 'F14': 0x7D, 'F15': 0x7E, 'F16': 0x7F, 'F17': 0x80, 'F18': 0x81,
                    'F19': 0x82, 'F20': 0x83, 'F21': 0x84, 'F22': 0x85, 'F23': 0x86, 'F24': 0x87,
                },
                "Numpad": {
                    'NUMPAD0': 0x60, 'NUMPAD1': 0x61, 'NUMPAD2': 0x62, 'NUMPAD3': 0x63,
                    'NUMPAD4': 0x64, 'NUMPAD5': 0x65, 'NUMPAD6': 0x66, 'NUMPAD7': 0x67,
                    'NUMPAD8': 0x68, 'NUMPAD9': 0x69, 'NUMPADADD': 0x6B, 'NUMPADSUBTRACT': 0x6D,
                    'NUMPADMULTIPLY': 0x6A, 'NUMPADDIVIDE': 0x6F, 'NUMPADDECIMAL': 0x6E,
                },
                "Special Characters": {
                    'SEMICOLON': 0xBA, 'EQUALS': 0xBB, 'COMMA': 0xBC, 'MINUS': 0xBD,
                    'PERIOD': 0xBE, 'SLASH': 0xBF, 'GRAVE': 0xC0, 'LBRACKET': 0xDB,
                    'BACKSLASH': 0xDC, 'RBRACKET': 0xDD, 'QUOTE': 0xDE,
                },
                "Lock Keys": {
                    'CAPSLOCK': 0x14, 'NUMLOCK': 0x90, 'SCROLLLOCK': 0x91,
                },
                "Media Keys": {
                    'VOLUME_MUTE': 0xAD, 'VOLUME_DOWN': 0xAE, 'VOLUME_UP': 0xAF,
                    'MEDIA_NEXT_TRACK': 0xB0, 'MEDIA_PREV_TRACK': 0xB1,
                    'MEDIA_STOP': 0xB2, 'MEDIA_PLAY_PAUSE': 0xB3,
                },
            }
            
            # Add letters and numbers
            key_categories["Letters"] = {}
            for i in range(26):
                key_categories["Letters"][chr(ord('A') + i)] = 0x41 + i
            
            key_categories["Numbers"] = {}
            for i in range(10):
                key_categories["Numbers"][str(i)] = 0x30 + i
            
            result = []
            for category, keys in key_categories.items():
                result.append(f"\nüìÅ {category}:")
                for key, code in sorted(keys.items()):
                    result.append(f"   {key:<20} = {hex(code)}")
            
            return True, "\n".join(result)
            
        except Exception as e:
            return False, f"Failed to get virtual key codes: {e}"
    
    def send_key_combination(self, keys: str) -> Tuple[bool, str]:
        """Send virtual keyboard combination (e.g., 'ctrl+c', 'alt+tab') - COMPREHENSIVE"""
        try:
            # Add timing delay before action
            time.sleep(0.1)
            
            # Parse key combination
            key_parts = [k.strip().upper() for k in keys.split('+')]
            
            # COMPREHENSIVE Map key names to virtual key codes
            key_map = {
                # Modifier keys
                'CTRL': 0x11, 'CONTROL': 0x11, 'LCTRL': 0xA2, 'RCTRL': 0xA3,
                'ALT': 0x12, 'LALT': 0xA4, 'RALT': 0xA5,
                'SHIFT': 0x10, 'LSHIFT': 0xA0, 'RSHIFT': 0xA1,
                'WIN': 0x5B, 'WINDOWS': 0x5B, 'LWIN': 0x5B, 'RWIN': 0x5C,
                
                # Basic keys
                'ESC': 0x1B, 'ESCAPE': 0x1B,
                'TAB': 0x09, 'ENTER': 0x0D, 'RETURN': 0x0D, 'SPACE': 0x20,
                'BACKSPACE': 0x08, 'DELETE': 0x2E, 'INSERT': 0x2D,
                
                # Home cluster
                'HOME': 0x24, 'END': 0x23, 'PAGEUP': 0x21, 'PAGEDOWN': 0x22,
                'PGUP': 0x21, 'PGDN': 0x22,
                
                # Arrow keys
                'UP': 0x26, 'DOWN': 0x28, 'LEFT': 0x25, 'RIGHT': 0x27,
                'UPARROW': 0x26, 'DOWNARROW': 0x28, 'LEFTARROW': 0x25, 'RIGHTARROW': 0x27,
                
                # Function keys (F1-F24)
                'F1': 0x70, 'F2': 0x71, 'F3': 0x72, 'F4': 0x73, 'F5': 0x74, 'F6': 0x75,
                'F7': 0x76, 'F8': 0x77, 'F9': 0x78, 'F10': 0x79, 'F11': 0x7A, 'F12': 0x7B,
                'F13': 0x7C, 'F14': 0x7D, 'F15': 0x7E, 'F16': 0x7F, 'F17': 0x80, 'F18': 0x81,
                'F19': 0x82, 'F20': 0x83, 'F21': 0x84, 'F22': 0x85, 'F23': 0x86, 'F24': 0x87,
                
                # Numpad digits
                'NUMPAD0': 0x60, 'NUMPAD1': 0x61, 'NUMPAD2': 0x62, 'NUMPAD3': 0x63,
                'NUMPAD4': 0x64, 'NUMPAD5': 0x65, 'NUMPAD6': 0x66, 'NUMPAD7': 0x67,
                'NUMPAD8': 0x68, 'NUMPAD9': 0x69,
                
                # Numpad operators
                'NUMPADADD': 0x6B, 'NUMPADSUBTRACT': 0x6D, 'NUMPADMULTIPLY': 0x6A,
                'NUMPADDIVIDE': 0x6F, 'NUMPADDECIMAL': 0x6E, 'NUMPADENTER': 0x0D,
                'NUMPADPLUS': 0x6B, 'NUMPADMINUS': 0x6D, 'NUMPADSTAR': 0x6A,
                'NUMPADSLASH': 0x6F, 'NUMPADDOT': 0x6E,
                
                # Lock keys
                'CAPSLOCK': 0x14, 'CAPS': 0x14, 'NUMLOCK': 0x90, 'SCROLLLOCK': 0x91,
                'SCROLL': 0x91,
                
                # Special characters (main keyboard)
                'SEMICOLON': 0xBA, ';': 0xBA,           # ; :
                'EQUALS': 0xBB, '=': 0xBB,             # = +
                'COMMA': 0xBC, ',': 0xBC,              # , <
                'MINUS': 0xBD, '-': 0xBD,              # - _
                'PERIOD': 0xBE, '.': 0xBE,             # . >
                'SLASH': 0xBF, '/': 0xBF,              # / ?
                'GRAVE': 0xC0, '`': 0xC0,              # ` ~
                'LBRACKET': 0xDB, '[': 0xDB,           # [ {
                'BACKSLASH': 0xDC, '\\': 0xDC,         # \ |
                'RBRACKET': 0xDD, ']': 0xDD,           # ] }
                'QUOTE': 0xDE, "'": 0xDE,              # ' "
                
                # Media keys
                'VOLUME_MUTE': 0xAD, 'MUTE': 0xAD,
                'VOLUME_DOWN': 0xAE, 'VOLDOWN': 0xAE,
                'VOLUME_UP': 0xAF, 'VOLUP': 0xAF,
                'MEDIA_NEXT_TRACK': 0xB0, 'NEXTTRACK': 0xB0,
                'MEDIA_PREV_TRACK': 0xB1, 'PREVTRACK': 0xB1,
                'MEDIA_STOP': 0xB2, 'MEDIASTOP': 0xB2,
                'MEDIA_PLAY_PAUSE': 0xB3, 'PLAYPAUSE': 0xB3,
                
                # Browser keys
                'BROWSER_BACK': 0xA6, 'BROWSERBACK': 0xA6,
                'BROWSER_FORWARD': 0xA7, 'BROWSERFORWARD': 0xA7,
                'BROWSER_REFRESH': 0xA8, 'BROWSERREFRESH': 0xA8,
                'BROWSER_STOP': 0xA9, 'BROWSERSTOP': 0xA9,
                'BROWSER_SEARCH': 0xAA, 'BROWSERSEARCH': 0xAA,
                'BROWSER_FAVORITES': 0xAB, 'BROWSERFAVORITES': 0xAB,
                'BROWSER_HOME': 0xAC, 'BROWSERHOME': 0xAC,
                
                # Application keys
                'APPS': 0x5D, 'MENU': 0x5D,           # Context menu key
                'SLEEP': 0x5F,
                'PRINT': 0x2A, 'PRINTSCREEN': 0x2C,
                'PAUSE': 0x13, 'BREAK': 0x03,
                
                # Additional special keys
                'SELECT': 0x29, 'EXECUTE': 0x2B, 'HELP': 0x2F,
                'CLEAR': 0x0C, 'SEPARATOR': 0x6C,
            }
            
            # Add letter keys (A-Z)
            for i in range(26):
                key_map[chr(ord('A') + i)] = 0x41 + i
            
            # Add number keys (0-9) - main keyboard
            for i in range(10):
                key_map[str(i)] = 0x30 + i
            
            # Convert key names to codes
            key_codes = []
            for key in key_parts:
                if key in key_map:
                    key_codes.append(key_map[key])
                else:
                    return False, f"Unknown key: {key}. Use 'keys' command to see all available keys."
            
            if not key_codes:
                return False, "No valid keys specified"
            
            # Try multiple methods for better compatibility
            # Method 1: Try SendInput API
            try:
                success = self._send_keys_via_sendinput(key_codes)
                if success:
                    return True, f"Sent key combination: {keys} (SendInput)"
            except Exception as e:
                print(f"SendInput failed: {e}")
            
            # Method 2: Try keybd_event API (fallback)
            try:
                success = self._send_keys_via_keybd_event(key_codes)
                if success:
                    return True, f"Sent key combination: {keys} (keybd_event)"
            except Exception as e:
                print(f"keybd_event failed: {e}")
            
            # Method 3: Try PostMessage to foreground window
            try:
                success = self._send_keys_via_postmessage(key_codes)
                if success:
                    return True, f"Sent key combination: {keys} (PostMessage)"
            except Exception as e:
                print(f"PostMessage failed: {e}")
            
            return False, f"All keyboard input methods failed for: {keys}"
                
        except Exception as e:
            return False, f"Failed to send key combination: {e}"
    
    def _send_keys_via_sendinput(self, key_codes: List[int]) -> bool:
        """Send keys using SendInput API"""
        import ctypes
        from ctypes import wintypes
        
        # Define input structures
        class KEYBDINPUT(ctypes.Structure):
            _fields_ = [
                ("wVk", wintypes.WORD),
                ("wScan", wintypes.WORD),
                ("dwFlags", wintypes.DWORD),
                ("time", wintypes.DWORD),
                ("dwExtraInfo", ctypes.POINTER(wintypes.ULONG))
            ]
        
        class INPUT(ctypes.Structure):
            class _INPUT(ctypes.Union):
                _fields_ = [("ki", KEYBDINPUT)]
            _anonymous_ = ("_input",)
            _fields_ = [
                ("type", wintypes.DWORD),
                ("_input", _INPUT)
            ]
        
        # Create input events
        inputs = []
        
        # Press all keys down
        for vk_code in key_codes:
            inp = INPUT()
            inp.type = 1  # INPUT_KEYBOARD
            inp.ki.wVk = vk_code
            inp.ki.wScan = 0
            inp.ki.dwFlags = 0  # KEYEVENTF_KEYDOWN
            inp.ki.time = 0
            inp.ki.dwExtraInfo = None
            inputs.append(inp)
        
        # Small delay between press and release
        time.sleep(0.05)
        
        # Release all keys (in reverse order)
        for vk_code in reversed(key_codes):
            inp = INPUT()
            inp.type = 1  # INPUT_KEYBOARD
            inp.ki.wVk = vk_code
            inp.ki.wScan = 0
            inp.ki.dwFlags = 2  # KEYEVENTF_KEYUP
            inp.ki.time = 0
            inp.ki.dwExtraInfo = None
            inputs.append(inp)
        
        # Send the inputs
        user32 = ctypes.windll.user32
        num_sent = user32.SendInput(len(inputs), (INPUT * len(inputs))(*inputs), ctypes.sizeof(INPUT))
        
        return num_sent == len(inputs)
    
    def _send_keys_via_keybd_event(self, key_codes: List[int]) -> bool:
        """Send keys using keybd_event API (older method)"""
        import ctypes
        
        user32 = ctypes.windll.user32
        
        try:
            # Press all keys down
            for vk_code in key_codes:
                user32.keybd_event(vk_code, 0, 0, 0)  # Key down
                time.sleep(0.01)
            
            time.sleep(0.05)  # Hold
            
            # Release all keys (in reverse order)
            for vk_code in reversed(key_codes):
                user32.keybd_event(vk_code, 0, 2, 0)  # Key up (KEYEVENTF_KEYUP = 2)
                time.sleep(0.01)
            
            return True
        except:
            return False
    
    def _send_keys_via_postmessage(self, key_codes: List[int]) -> bool:
        """Send keys using PostMessage to foreground window"""
        try:
            # Get foreground window
            hwnd = win32gui.GetForegroundWindow()
            if not hwnd:
                return False
            
            # For simple combinations like Ctrl+V, we can send WM_KEYDOWN/WM_KEYUP
            WM_KEYDOWN = 0x0100
            WM_KEYUP = 0x0101
            
            # Press keys down
            for vk_code in key_codes:
                win32gui.PostMessage(hwnd, WM_KEYDOWN, vk_code, 0)
                time.sleep(0.01)
            
            time.sleep(0.05)
            
            # Release keys
            for vk_code in reversed(key_codes):
                win32gui.PostMessage(hwnd, WM_KEYUP, vk_code, 0)
                time.sleep(0.01)
            
            return True
        except:
            return False
    
    def send_text(self, text: str) -> Tuple[bool, str]:
        """Send text as if typed on keyboard"""
        try:
            import ctypes
            from ctypes import wintypes
            
            # Define input structures (same as above)
            class KEYBDINPUT(ctypes.Structure):
                _fields_ = [
                    ("wVk", wintypes.WORD),
                    ("wScan", wintypes.WORD),
                    ("dwFlags", wintypes.DWORD),
                    ("time", wintypes.DWORD),
                    ("dwExtraInfo", ctypes.POINTER(wintypes.ULONG))
                ]
            
            class INPUT(ctypes.Structure):
                class _INPUT(ctypes.Union):
                    _fields_ = [("ki", KEYBDINPUT)]
                _anonymous_ = ("_input",)
                _fields_ = [
                    ("type", wintypes.DWORD),
                    ("_input", _INPUT)
                ]
            
            inputs = []
            for char in text:
                # Key down
                inp = INPUT()
                inp.type = 1  # INPUT_KEYBOARD
                inp.ki.wVk = 0
                inp.ki.wScan = ord(char)
                inp.ki.dwFlags = 4  # KEYEVENTF_UNICODE
                inp.ki.time = 0
                inp.ki.dwExtraInfo = None
                inputs.append(inp)
                
                # Key up
                inp = INPUT()
                inp.type = 1  # INPUT_KEYBOARD
                inp.ki.wVk = 0
                inp.ki.wScan = ord(char)
                inp.ki.dwFlags = 4 | 2  # KEYEVENTF_UNICODE | KEYEVENTF_KEYUP
                inp.ki.time = 0
                inp.ki.dwExtraInfo = None
                inputs.append(inp)
            
            # Send the inputs
            user32 = ctypes.windll.user32
            num_sent = user32.SendInput(len(inputs), (INPUT * len(inputs))(*inputs), ctypes.sizeof(INPUT))
            
            if num_sent == len(inputs):
                return True, f"Sent text: '{text}' ({len(text)} characters)"
            else:
                return False, f"Only sent {num_sent}/{len(inputs)} key events"
                
        except Exception as e:
            return False, f"Failed to send text: {e}"

    # =============== MOUSE OPERATIONS ===============
    
    def send_mouse_click(self, button: str = "left", x: int = None, y: int = None) -> Tuple[bool, str]:
        """Send mouse click at specified position or current cursor position"""
        try:
            import ctypes
            from ctypes import wintypes
            
            # Add timing delay before action
            time.sleep(0.1)
            
            # Define mouse input structure
            class MOUSEINPUT(ctypes.Structure):
                _fields_ = [
                    ("dx", ctypes.c_long),
                    ("dy", ctypes.c_long),
                    ("mouseData", wintypes.DWORD),
                    ("dwFlags", wintypes.DWORD),
                    ("time", wintypes.DWORD),
                    ("dwExtraInfo", ctypes.POINTER(wintypes.ULONG))
                ]
            
            class INPUT(ctypes.Structure):
                class _INPUT(ctypes.Union):
                    _fields_ = [("mi", MOUSEINPUT)]
                _anonymous_ = ("_input",)
                _fields_ = [
                    ("type", wintypes.DWORD),
                    ("_input", _INPUT)
                ]
            
            # ALWAYS move cursor to position if specified (this is the key change)
            if x is not None and y is not None:
                success, msg = self.set_cursor_position(x, y)
                if not success:
                    return False, f"Failed to move cursor: {msg}"
                # Add small delay after cursor movement
                time.sleep(0.05)
            else:
                # Get current cursor position
                cursor_pos = win32gui.GetCursorPos()
                x, y = cursor_pos
            
            # Map button to flags
            button_map = {
                "left": (0x0002, 0x0004),    # MOUSEEVENTF_LEFTDOWN, MOUSEEVENTF_LEFTUP
                "right": (0x0008, 0x0010),   # MOUSEEVENTF_RIGHTDOWN, MOUSEEVENTF_RIGHTUP
                "middle": (0x0020, 0x0040)   # MOUSEEVENTF_MIDDLEDOWN, MOUSEEVENTF_MIDDLEUP
            }
            
            if button.lower() not in button_map:
                return False, f"Invalid button: {button}. Use left, right, or middle"
            
            down_flag, up_flag = button_map[button.lower()]
            
            # Create input events
            inputs = []
            
            # Mouse down
            inp = INPUT()
            inp.type = 0  # INPUT_MOUSE
            inp.mi.dx = 0
            inp.mi.dy = 0
            inp.mi.mouseData = 0
            inp.mi.dwFlags = down_flag
            inp.mi.time = 0
            inp.mi.dwExtraInfo = None
            inputs.append(inp)
            
            # Mouse up
            inp = INPUT()
            inp.type = 0  # INPUT_MOUSE
            inp.mi.dx = 0
            inp.mi.dy = 0
            inp.mi.mouseData = 0
            inp.mi.dwFlags = up_flag
            inp.mi.time = 0
            inp.mi.dwExtraInfo = None
            inputs.append(inp)
            
            # Send the inputs
            user32 = ctypes.windll.user32
            num_sent = user32.SendInput(len(inputs), (INPUT * len(inputs))(*inputs), ctypes.sizeof(INPUT))
            
            if num_sent == len(inputs):
                monitor_id = self._get_cursor_monitor((x, y))
                return True, f"{button.capitalize()} click at ({x}, {y}) on Monitor {monitor_id}"
            else:
                return False, f"Only sent {num_sent}/{len(inputs)} mouse events"
                
        except Exception as e:
            return False, f"Failed to send mouse click: {e}"
    
    def send_mouse_double_click(self, button: str = "left", x: int = None, y: int = None) -> Tuple[bool, str]:
        """Send mouse double click"""
        try:
            # Add timing delay before action
            time.sleep(0.1)
            
            # ALWAYS move cursor to position first if specified
            if x is not None and y is not None:
                success, msg = self.set_cursor_position(x, y)
                if not success:
                    return False, f"Failed to move cursor: {msg}"
                # Add small delay after cursor movement
                time.sleep(0.05)
            
            # Send first click (don't move cursor again since we already moved it)
            success1, msg1 = self.send_mouse_click(button, None, None)  # Use current position
            if not success1:
                return False, f"First click failed: {msg1}"
            
            # Brief delay between clicks
            time.sleep(0.05)
            
            # Send second click
            success2, msg2 = self.send_mouse_click(button, None, None)  # Use current position
            if not success2:
                return False, f"Second click failed: {msg2}"
            
            if x is None or y is None:
                cursor_pos = win32gui.GetCursorPos()
                x, y = cursor_pos
            
            monitor_id = self._get_cursor_monitor((x, y))
            return True, f"{button.capitalize()} double-click at ({x}, {y}) on Monitor {monitor_id}"
            
        except Exception as e:
            return False, f"Failed to send double click: {e}"
    
    def send_mouse_long_click(self, button: str = "left", duration: float = 1.0, 
                             x: int = None, y: int = None) -> Tuple[bool, str]:
        """Send mouse long click (press and hold)"""
        try:
            import ctypes
            from ctypes import wintypes
            
            # Add timing delay before action
            time.sleep(0.1)
            
            # ALWAYS move cursor to position if specified
            if x is not None and y is not None:
                success, msg = self.set_cursor_position(x, y)
                if not success:
                    return False, f"Failed to move cursor: {msg}"
            else:
                cursor_pos = win32gui.GetCursorPos()
                x, y = cursor_pos
            
            # Map button to flags
            button_map = {
                "left": (0x0002, 0x0004),
                "right": (0x0008, 0x0010),
                "middle": (0x0020, 0x0040)
            }
            
            if button.lower() not in button_map:
                return False, f"Invalid button: {button}. Use left, right, or middle"
            
            down_flag, up_flag = button_map[button.lower()]
            
            # Mouse down
            inp = INPUT()
            inp.type = 0  # INPUT_MOUSE
            inp.mi.dx = 0
            inp.mi.dy = 0
            inp.mi.mouseData = 0
            inp.mi.dwFlags = down_flag
            inp.mi.time = 0
            inp.mi.dwExtraInfo = None
            
            user32 = ctypes.windll.user32
            user32.SendInput(1, ctypes.byref(inp), ctypes.sizeof(INPUT))
            
            # Hold for specified duration
            time.sleep(duration)
            
            # Mouse up
            inp.mi.dwFlags = up_flag
            user32.SendInput(1, ctypes.byref(inp), ctypes.sizeof(INPUT))
            
            monitor_id = self._get_cursor_monitor((x, y))
            return True, f"{button.capitalize()} long-click ({duration}s) at ({x}, {y}) on Monitor {monitor_id}"
            
        except Exception as e:
            return False, f"Failed to send long click: {e}"
    
    def send_mouse_scroll(self, direction: str, amount: int = 3, x: int = None, y: int = None) -> Tuple[bool, str]:
        """Send mouse scroll (up, down, left, right)"""
        try:
            import ctypes
            from ctypes import wintypes
            
            # Define mouse input structure
            class MOUSEINPUT(ctypes.Structure):
                _fields_ = [
                    ("dx", ctypes.c_long),
                    ("dy", ctypes.c_long),
                    ("mouseData", wintypes.DWORD),
                    ("dwFlags", wintypes.DWORD),
                    ("time", wintypes.DWORD),
                    ("dwExtraInfo", ctypes.POINTER(wintypes.ULONG))
                ]
            
            class INPUT(ctypes.Structure):
                class _INPUT(ctypes.Union):
                    _fields_ = [("mi", MOUSEINPUT)]
                _anonymous_ = ("_input",)
                _fields_ = [
                    ("type", wintypes.DWORD),
                    ("_input", _INPUT)
                ]
            
            # Move cursor to position if specified
            if x is not None and y is not None:
                success, msg = self.set_cursor_position(x, y)
                if not success:
                    return False, f"Failed to move cursor: {msg}"
            else:
                cursor_pos = win32gui.GetCursorPos()
                x, y = cursor_pos
            
            # Map direction to flags and data
            WHEEL_DELTA = 120  # Standard wheel delta
            
            direction_map = {
                "up": (0x0800, amount * WHEEL_DELTA),      # MOUSEEVENTF_WHEEL, positive
                "down": (0x0800, -amount * WHEEL_DELTA),   # MOUSEEVENTF_WHEEL, negative
                "left": (0x1000, -amount * WHEEL_DELTA),   # MOUSEEVENTF_HWHEEL, negative
                "right": (0x1000, amount * WHEEL_DELTA)    # MOUSEEVENTF_HWHEEL, positive
            }
            
            if direction.lower() not in direction_map:
                return False, f"Invalid direction: {direction}. Use up, down, left, or right"
            
            flag, wheel_data = direction_map[direction.lower()]
            
            # Create scroll input
            inp = INPUT()
            inp.type = 0  # INPUT_MOUSE
            inp.mi.dx = 0
            inp.mi.dy = 0
            inp.mi.mouseData = wheel_data
            inp.mi.dwFlags = flag
            inp.mi.time = 0
            inp.mi.dwExtraInfo = None
            
            # Send the input
            user32 = ctypes.windll.user32
            num_sent = user32.SendInput(1, ctypes.byref(inp), ctypes.sizeof(INPUT))
            
            if num_sent == 1:
                monitor_id = self._get_cursor_monitor((x, y))
                return True, f"Scroll {direction} (amount: {amount}) at ({x}, {y}) on Monitor {monitor_id}"
            else:
                return False, "Failed to send scroll event"
                
        except Exception as e:
            return False, f"Failed to send scroll: {e}"
    
    def send_mouse_drag(self, start_x: int, start_y: int, end_x: int, end_y: int, 
                       button: str = "left", duration: float = 0.5) -> Tuple[bool, str]:
        """Send mouse drag from start to end position"""
        try:
            import ctypes
            from ctypes import wintypes
            
            # Define mouse input structure
            class MOUSEINPUT(ctypes.Structure):
                _fields_ = [
                    ("dx", ctypes.c_long),
                    ("dy", ctypes.c_long),
                    ("mouseData", wintypes.DWORD),
                    ("dwFlags", wintypes.DWORD),
                    ("time", wintypes.DWORD),
                    ("dwExtraInfo", ctypes.POINTER(wintypes.ULONG))
                ]
            
            class INPUT(ctypes.Structure):
                class _INPUT(ctypes.Union):
                    _fields_ = [("mi", MOUSEINPUT)]
                _anonymous_ = ("_input",)
                _fields_ = [
                    ("type", wintypes.DWORD),
                    ("_input", _INPUT)
                ]
            
            # Map button to flags
            button_map = {
                "left": (0x0002, 0x0004),
                "right": (0x0008, 0x0010),
                "middle": (0x0020, 0x0040)
            }
            
            if button.lower() not in button_map:
                return False, f"Invalid button: {button}. Use left, right, or middle"
            
            down_flag, up_flag = button_map[button.lower()]
            
            # Move to start position
            self.set_cursor_position(start_x, start_y)
            time.sleep(0.1)
            
            # Mouse down at start
            inp = INPUT()
            inp.type = 0  # INPUT_MOUSE
            inp.mi.dx = 0
            inp.mi.dy = 0
            inp.mi.mouseData = 0
            inp.mi.dwFlags = down_flag
            inp.mi.time = 0
            inp.mi.dwExtraInfo = None
            
            user32 = ctypes.windll.user32
            user32.SendInput(1, ctypes.byref(inp), ctypes.sizeof(INPUT))
            
            # Calculate intermediate positions for smooth drag
            steps = max(10, int(duration * 20))  # 20 steps per second
            for i in range(steps + 1):
                progress = i / steps
                current_x = int(start_x + (end_x - start_x) * progress)
                current_y = int(start_y + (end_y - start_y) * progress)
                
                self.set_cursor_position(current_x, current_y)
                time.sleep(duration / steps)
            
            # Mouse up at end
            inp.mi.dwFlags = up_flag
            user32.SendInput(1, ctypes.byref(inp), ctypes.sizeof(INPUT))
            
            start_monitor = self._get_cursor_monitor((start_x, start_y))
            end_monitor = self._get_cursor_monitor((end_x, end_y))
            
            return True, f"{button.capitalize()} drag from ({start_x}, {start_y}) to ({end_x}, {end_y}) in {duration}s (Monitor {start_monitor}‚Üí{end_monitor})"
            
        except Exception as e:
            return False, f"Failed to send drag: {e}"

    def _execute_single_command(self, command_str: str) -> Tuple[bool, str]:
        """Execute a single command - used internally by command chain"""
        # This will be called from the test file's process_command method
        # We'll need to refactor the test file to support this
        pass

    def is_valid_window(self, hwnd: int) -> bool:
        """Check if window handle is still valid - SIMPLIFIED VERSION"""
        try:
            return win32gui.IsWindow(hwnd)
        except:
            return False
    


    def introspect_window(self, hwnd: int) -> Tuple[bool, str]:
        """Deep introspection of a window - like ShareX detection"""
        try:
            # Add timing delay
            time.sleep(0.1)
            
            if not self.is_valid_window(hwnd):
                return False, "Window is no longer valid"
            
            # Collect comprehensive window information
            introspection_data = {
                "basic_info": self._get_basic_window_info(hwnd),
                "hierarchy": self._get_window_hierarchy(hwnd),
                "ui_automation": self._get_ui_automation_info(hwnd),
                "regions": self._get_window_regions(hwnd),
                "class_info": self._get_window_class_info(hwnd),
                "process_info": self._get_window_process_info(hwnd)
            }
            
            # Format the output nicely
            output = self._format_introspection_output(introspection_data)
            return True, output
            
        except Exception as e:
            return False, f"Failed to introspect window: {e}"

    def _get_basic_window_info(self, hwnd: int) -> Dict:
        """Get basic window information"""
        try:
            rect = win32gui.GetWindowRect(hwnd)
            client_rect = win32gui.GetClientRect(hwnd)
            
            return {
                "hwnd": hwnd,
                "title": win32gui.GetWindowText(hwnd),
                "class_name": win32gui.GetClassName(hwnd),
                "window_rect": {"x": rect[0], "y": rect[1], "width": rect[2]-rect[0], "height": rect[3]-rect[1]},
                "client_rect": {"width": client_rect[2], "height": client_rect[3]},
                "visible": win32gui.IsWindowVisible(hwnd),
                "enabled": win32gui.IsWindowEnabled(hwnd),
                "state": self.get_window_state(hwnd),
                "z_order": self._get_window_z_order(hwnd),
                "has_menu": win32gui.GetMenu(hwnd) != 0,
                "is_unicode": win32gui.IsWindowUnicode(hwnd)
            }
        except Exception as e:
            return {"error": str(e)}

    def _get_window_hierarchy(self, hwnd: int) -> Dict:
        """Get window hierarchy information"""
        try:
            # Get parent window
            parent = win32gui.GetParent(hwnd)
            owner = win32gui.GetWindow(hwnd, win32con.GW_OWNER) if parent == 0 else None
            
            # Get child windows
            children = []
            def enum_child_proc(child_hwnd, lparam):
                try:
                    child_info = {
                        "hwnd": child_hwnd,
                        "title": win32gui.GetWindowText(child_hwnd),
                        "class_name": win32gui.GetClassName(child_hwnd),
                        "rect": win32gui.GetWindowRect(child_hwnd),
                        "visible": win32gui.IsWindowVisible(child_hwnd),
                        "control_id": win32gui.GetDlgCtrlID(child_hwnd)
                    }
                    children.append(child_info)
                except:
                    pass
                return True
            
            win32gui.EnumChildWindows(hwnd, enum_child_proc, 0)
            
            return {
                "parent": parent if parent != 0 else None,
                "owner": owner,
                "children_count": len(children),
                "children": children[:10],  # Limit to first 10 for readability
                "has_more_children": len(children) > 10
            }
        except Exception as e:
            return {"error": str(e)}

    def _get_ui_automation_info(self, hwnd: int) -> Dict:
        """Get UI Automation information (like ShareX detection)"""
        try:
            # Initialize UI Automation safely
            uia_obj, UIA = _initialize_ui_automation()
            if not uia_obj or not UIA:
                return {"error": "UI Automation not available"}
            
            element = uia_obj.ElementFromHandle(hwnd)
            
            if not element:
                return {"error": "Could not get UI Automation element"}
            
            # Get element properties
            automation_info = {
                "name": element.CurrentName or "",
                "automation_id": element.CurrentAutomationId or "",
                "control_type": self._get_control_type_name(element.CurrentControlType),
                "class_name": element.CurrentClassName or "",
                "framework_id": element.CurrentFrameworkId or "",
                "is_enabled": element.CurrentIsEnabled,
                "is_keyboard_focusable": element.CurrentIsKeyboardFocusable,
                "is_content_element": element.CurrentIsContentElement,
                "is_control_element": element.CurrentIsControlElement,
                "bounding_rectangle": self._get_automation_rect(element.CurrentBoundingRectangle),
                "help_text": element.CurrentHelpText or "",
                "accelerator_key": element.CurrentAcceleratorKey or "",
                "access_key": element.CurrentAccessKey or ""
            }
            
            # Get child elements for structure analysis
            child_elements = []
            try:
                children = element.FindAll(UIA.TreeScope_Children, uia_obj.CreateTrueCondition())
                for i in range(min(children.Length, 10)):  # Limit to 10 children
                    child = children.GetElement(i)
                    child_info = {
                        "name": child.CurrentName or "",
                        "control_type": self._get_control_type_name(child.CurrentControlType),
                        "class_name": child.CurrentClassName or "",
                        "rect": self._get_automation_rect(child.CurrentBoundingRectangle)
                    }
                    child_elements.append(child_info)
            except:
                pass
            
            automation_info["ui_children"] = child_elements
            automation_info["ui_children_count"] = len(child_elements)
            
            return automation_info
            
        except Exception as e:
            return {"error": f"UI Automation failed: {e}"}

    def _get_window_regions(self, hwnd: int) -> Dict:
        """Detect different regions within the window"""
        try:
            window_rect = win32gui.GetWindowRect(hwnd)
            client_rect = win32gui.GetClientRect(hwnd)
            
            # Calculate border sizes
            border_x = (window_rect[2] - window_rect[0] - client_rect[2]) // 2
            border_y = (window_rect[3] - window_rect[1] - client_rect[3]) - border_x
            
            regions = {
                "title_bar": {
                    "x": window_rect[0],
                    "y": window_rect[1], 
                    "width": window_rect[2] - window_rect[0],
                    "height": border_y
                },
                "client_area": {
                    "x": window_rect[0] + border_x,
                    "y": window_rect[1] + border_y,
                    "width": client_rect[2],
                    "height": client_rect[3]
                },
                "borders": {
                    "left": border_x,
                    "right": border_x, 
                    "top": border_y,
                    "bottom": border_x
                }
            }
            
            # Try to detect specific regions using point testing
            test_points = self._get_region_test_points(window_rect, client_rect)
            region_detection = {}
            
            for region_name, point in test_points.items():
                try:
                    child_hwnd = win32gui.ChildWindowFromPoint(hwnd, (point[0] - window_rect[0], point[1] - window_rect[1]))
                    if child_hwnd and child_hwnd != hwnd:
                        region_detection[region_name] = {
                            "detected": True,
                            "child_hwnd": child_hwnd,
                            "class_name": win32gui.GetClassName(child_hwnd),
                            "title": win32gui.GetWindowText(child_hwnd)
                        }
                    else:
                        region_detection[region_name] = {"detected": False}
                except:
                    region_detection[region_name] = {"detected": False, "error": "Detection failed"}
            
            return {
                "calculated_regions": regions,
                "detected_controls": region_detection
            }
            
        except Exception as e:
            return {"error": str(e)}

    def _get_window_class_info(self, hwnd: int) -> Dict:
        """Get detailed window class information"""
        try:
            class_name = win32gui.GetClassName(hwnd)
            
            # Get window style and extended style
            style = win32gui.GetWindowLong(hwnd, win32con.GWL_STYLE)
            ex_style = win32gui.GetWindowLong(hwnd, win32con.GWL_EXSTYLE)
            
            # Decode common window styles
            style_flags = self._decode_window_styles(style)
            ex_style_flags = self._decode_extended_styles(ex_style)
            
            return {
                "class_name": class_name,
                "window_style": hex(style),
                "extended_style": hex(ex_style),
                "style_flags": style_flags,
                "extended_style_flags": ex_style_flags,
                "class_type": self._classify_window_type(class_name, style)
            }
        except Exception as e:
            return {"error": str(e)}

    def _get_window_process_info(self, hwnd: int) -> Dict:
        """Get detailed process information"""
        try:
            _, pid = win32process.GetWindowThreadProcessId(hwnd)
            
            try:
                process = psutil.Process(pid)
                return {
                    "pid": pid,
                    "name": process.name(),
                    "exe": process.exe(),
                    "cmdline": " ".join(process.cmdline()),
                    "memory_usage": process.memory_info().rss,
                    "cpu_percent": process.cpu_percent(),
                    "create_time": process.create_time(),
                    "num_threads": process.num_threads()
                }
            except psutil.NoSuchProcess:
                return {"pid": pid, "error": "Process no longer exists"}
        except Exception as e:
            return {"error": str(e)}

    def _get_control_type_name(self, control_type: int) -> str:
        """Convert UI Automation control type to readable name"""
        control_types = {
            50000: "Button", 50001: "Calendar", 50002: "CheckBox", 50003: "ComboBox",
            50004: "Edit", 50005: "Hyperlink", 50006: "Image", 50007: "ListItem",
            50008: "List", 50009: "Menu", 50010: "MenuBar", 50011: "MenuItem",
            50012: "ProgressBar", 50013: "RadioButton", 50014: "ScrollBar",
            50015: "Slider", 50016: "Spinner", 50017: "StatusBar", 50018: "Tab",
            50019: "TabItem", 50020: "Text", 50021: "ToolBar", 50022: "ToolTip",
            50023: "Tree", 50024: "TreeItem", 50025: "Custom", 50026: "Group",
            50027: "Thumb", 50028: "DataGrid", 50029: "DataItem", 50030: "Document",
            50031: "SplitButton", 50032: "Window", 50033: "Pane", 50034: "Header",
            50035: "HeaderItem", 50036: "Table", 50037: "TitleBar", 50038: "Separator"
        }
        return control_types.get(control_type, f"Unknown({control_type})")

    def _get_automation_rect(self, rect) -> Dict:
        """Convert UI Automation rectangle to dict"""
        try:
            return {
                "x": int(rect.left),
                "y": int(rect.top), 
                "width": int(rect.right - rect.left),
                "height": int(rect.bottom - rect.top)
            }
        except:
            return {"x": 0, "y": 0, "width": 0, "height": 0}

    def _get_window_z_order(self, hwnd: int) -> int:
        """Get window Z-order position"""
        try:
            z_order = 0
            current = win32gui.GetWindow(hwnd, win32con.GW_HWNDFIRST)
            while current:
                if current == hwnd:
                    return z_order
                z_order += 1
                current = win32gui.GetWindow(current, win32con.GW_HWNDNEXT)
            return -1
        except:
            return -1

    def _get_region_test_points(self, window_rect: tuple, client_rect: tuple) -> Dict:
        """Generate test points for different window regions"""
        wx, wy, wr, wb = window_rect
        cw, ch = client_rect[2], client_rect[3]
        
        return {
            "title_bar_center": (wx + (wr-wx)//2, wy + 10),
            "client_top_left": (wx + 10, wy + 30),
            "client_center": (wx + (wr-wx)//2, wy + (wb-wy)//2),
            "client_bottom_right": (wr - 10, wb - 10)
        }

    def _decode_window_styles(self, style: int) -> List[str]:
        """Decode window style flags"""
        styles = []
        style_map = {
            0x10000000: "WS_VISIBLE",
            0x00C00000: "WS_CAPTION", 
            0x00080000: "WS_SYSMENU",
            0x00040000: "WS_THICKFRAME",
            0x00020000: "WS_MINIMIZEBOX",
            0x00010000: "WS_MAXIMIZEBOX",
            0x20000000: "WS_MINIMIZE",
            0x01000000: "WS_MAXIMIZE"
        }
        
        for flag, name in style_map.items():
            if style & flag:
                styles.append(name)
        return styles

    def _decode_extended_styles(self, ex_style: int) -> List[str]:
        """Decode extended window style flags"""
        styles = []
        ex_style_map = {
            0x00000080: "WS_EX_TOOLWINDOW",
            0x00000008: "WS_EX_TOPMOST", 
            0x00000200: "WS_EX_ACCEPTFILES",
            0x00080000: "WS_EX_LAYERED",
            0x08000000: "WS_EX_NOACTIVATE"
        }
        
        for flag, name in ex_style_map.items():
            if ex_style & flag:
                styles.append(name)
        return styles

    def _classify_window_type(self, class_name: str, style: int) -> str:
        """Classify window type based on class name and style"""
        if "Chrome" in class_name:
            return "Browser"
        elif class_name in ["Notepad", "Edit", "WordPadClass"]:
            return "Text Editor"
        elif class_name == "CabinetWClass":
            return "File Explorer"
        elif style & 0x00C00000:  # WS_CAPTION
            return "Application Window"
        elif style & 0x00000080:  # WS_EX_TOOLWINDOW
            return "Tool Window"
        else:
            return "Unknown"

    def _format_introspection_output(self, data: Dict) -> str:
        """Format introspection data for readable output"""
        output = []
        
        # Basic Info
        basic = data.get("basic_info", {})
        output.append("üîç WINDOW INTROSPECTION")
        output.append("=" * 50)
        output.append(f"üì± Title: {basic.get('title', 'N/A')}")
        output.append(f"üÜî HWND: {basic.get('hwnd', 'N/A')}")
        output.append(f"üìè Size: {basic.get('window_rect', {}).get('width', 0)}x{basic.get('window_rect', {}).get('height', 0)}")
        output.append(f"üìç Position: ({basic.get('window_rect', {}).get('x', 0)}, {basic.get('window_rect', {}).get('y', 0)})")
        output.append(f"üéØ State: {basic.get('state', 'unknown')}")
        output.append(f"üëÅÔ∏è  Visible: {basic.get('visible', False)}")
        output.append(f"üìä Z-Order: {basic.get('z_order', -1)}")
        
        # Class Info
        class_info = data.get("class_info", {})
        output.append(f"\nüè∑Ô∏è  CLASS INFORMATION")
        output.append(f"üìã Class Name: {class_info.get('class_name', 'N/A')}")
        output.append(f"üé® Window Type: {class_info.get('class_type', 'Unknown')}")
        output.append(f"‚öôÔ∏è  Style Flags: {', '.join(class_info.get('style_flags', []))}")
        
        # Process Info
        process = data.get("process_info", {})
        if "error" not in process:
            output.append(f"\n‚ö° PROCESS INFORMATION")
            output.append(f"üî¢ PID: {process.get('pid', 'N/A')}")
            output.append(f"üìÇ Process: {process.get('name', 'N/A')}")
            output.append(f"üíæ Memory: {process.get('memory_usage', 0) // (1024*1024)} MB")
        
        # UI Automation
        ui_auto = data.get("ui_automation", {})
        if "error" not in ui_auto:
            output.append(f"\nü§ñ UI AUTOMATION ANALYSIS")
            output.append(f"üè∑Ô∏è  Control Type: {ui_auto.get('control_type', 'N/A')}")
            output.append(f"üÜî Automation ID: {ui_auto.get('automation_id', 'N/A')}")
            output.append(f"üñºÔ∏è  Framework: {ui_auto.get('framework_id', 'N/A')}")
        
        return "\n".join(output)

    # Add this method to the WindowManager class (around line 1800):

    def get_element_under_cursor(self) -> Tuple[bool, str]:
        """Get detailed info about UI element under mouse cursor (like ShareX)"""
        try:
            cursor_pos = win32gui.GetCursorPos()
            x, y = cursor_pos
            
            # Get window under cursor
            hwnd = win32gui.WindowFromPoint(cursor_pos)
            if not hwnd:
                return False, "No window found under cursor"
            
            # Get window hierarchy
            root_hwnd = hwnd
            while True:
                parent = win32gui.GetParent(root_hwnd)
                if parent == 0:
                    break
                root_hwnd = parent
            
            # Get basic info
            window_title = win32gui.GetWindowText(hwnd)
            window_class = win32gui.GetClassName(hwnd)
            window_rect = win32gui.GetWindowRect(hwnd)
            
            # ENHANCED: Classify the UI region type
            region_type = self._classify_ui_region(window_class, window_rect, root_hwnd)
            
            output = []
            output.append(f"üéØ ELEMENT UNDER CURSOR ({x}, {y})")
            output.append("=" * 50)
            output.append(f"üé® UI Region Type: {region_type}")
            output.append(f"ü™ü Window: {window_title or 'Untitled'}")
            output.append(f"üè∑Ô∏è  Class: {window_class}")
            output.append(f"üÜî HWND: {hwnd}")
            output.append(f"üìè Size: {window_rect[2]-window_rect[0]}√ó{window_rect[3]-window_rect[1]}")
            output.append(f"üìç Position: ({window_rect[0]}, {window_rect[1]})")
            
            # Show relative position within parent
            if root_hwnd != hwnd:
                root_title = win32gui.GetWindowText(root_hwnd)
                root_class = win32gui.GetClassName(root_hwnd)
                root_rect = win32gui.GetWindowRect(root_hwnd)
                
                rel_x = window_rect[0] - root_rect[0]
                rel_y = window_rect[1] - root_rect[1]
                
                output.append(f"\nüè† Parent Application: {root_title or 'Untitled'}")
                output.append(f"üè∑Ô∏è  Parent Class: {root_class}")
                output.append(f"üìç Relative Position: ({rel_x}, {rel_y}) within parent")
                
                # Detect what area of the application this is
                app_region = self._detect_application_region(window_rect, root_rect, window_class)
                output.append(f"üéØ Application Region: {app_region}")
            
            # Get child windows/controls in this area
            children = self._get_nearby_controls(hwnd, cursor_pos)
            if children:
                output.append(f"\nüîç Nearby Controls:")
                for child in children[:3]:  # Show first 3
                    output.append(f"   ‚Ä¢ {child['class']} - {child['title'][:30]}")
            
            return True, "\n".join(output)
            
        except Exception as e:
            return False, f"Failed to get element under cursor: {e}"

    def _classify_ui_region(self, class_name: str, rect: tuple, root_hwnd: int) -> str:
        """Classify what type of UI region this is"""
        width = rect[2] - rect[0]
        height = rect[3] - rect[1]
        
        # Office applications
        if "NetUIHWND" in class_name:
            return "üéÄ RIBBON/TOOLBAR"
        elif "_WwG" in class_name or "OpusApp" in class_name:
            return "üìÑ DOCUMENT/CONTENT AREA"
        elif "StatusBar" in class_name:
            return "üìä STATUS BAR"
        
        # Browser
        elif "Chrome" in class_name:
            if height < 100:
                return "üåê BROWSER TOOLBAR"
            else:
                return "üåê WEB CONTENT"
        
        # Common patterns
        elif height < 50:
            return "üîß TOOLBAR/MENU"
        elif width > height * 3:
            return "üìè HORIZONTAL PANEL"
        elif height > width * 2:
            return "üìê VERTICAL PANEL"
        else:
            return "üñºÔ∏è CONTENT AREA"

    def _detect_application_region(self, window_rect: tuple, parent_rect: tuple, class_name: str) -> str:
        """Detect which part of the application window this control is in"""
        wx, wy = window_rect[0], window_rect[1]
        px, py, pr, pb = parent_rect
        
        # Relative position within parent
        rel_x = (wx - px) / (pr - px) if pr != px else 0
        rel_y = (wy - py) / (pb - py) if pb != py else 0
        
        if rel_y < 0.2:
            return "üîù TOP (Likely ribbon/menu area)"
        elif rel_y > 0.9:
            return "üîΩ BOTTOM (Likely status bar)"
        elif rel_x < 0.1:
            return "‚óÄÔ∏è LEFT SIDE (Likely sidebar/navigation)"
        elif rel_x > 0.9:
            return "‚ñ∂Ô∏è RIGHT SIDE (Likely properties/tools)"
        else:
            return "üéØ CENTER (Likely main content)"

    def _get_nearby_controls(self, hwnd: int, cursor_pos: tuple) -> List[Dict]:
        """Get controls near the cursor position"""
        controls = []
        x, y = cursor_pos
        
        # Check for sibling windows (same parent)
        try:
            parent = win32gui.GetParent(hwnd)
            if parent:
                def enum_siblings(sibling_hwnd, lparam):
                    if sibling_hwnd != hwnd and win32gui.IsWindowVisible(sibling_hwnd):
                        rect = win32gui.GetWindowRect(sibling_hwnd)
                        # Check if it's near our cursor (within 200 pixels)
                        if (abs(rect[0] - x) < 200 or abs(rect[2] - x) < 200) and \
                           (abs(rect[1] - y) < 200 or abs(rect[3] - y) < 200):
                            controls.append({
                                'hwnd': sibling_hwnd,
                                'title': win32gui.GetWindowText(sibling_hwnd),
                                'class': win32gui.GetClassName(sibling_hwnd),
                                'rect': rect
                            })
                    return True
                
                win32gui.EnumChildWindows(parent, enum_siblings, 0)
        except:
            pass
        
        return controls

    def get_window_hierarchy_tree(self, hwnd: int) -> Tuple[bool, str]:
        """Get complete hierarchical tree of all UI regions in a window"""
        try:
            time.sleep(0.1)
            
            if not self.is_valid_window(hwnd):
                return False, "Window is no longer valid"
            
            # Build the complete tree structure
            tree = self._build_window_tree(hwnd, 0)
            
            # Format as readable tree
            output = self._format_hierarchy_tree(tree)
            
            return True, output
            
        except Exception as e:
            return False, f"Failed to get window hierarchy: {e}"

    def _build_window_tree(self, hwnd: int, depth: int) -> Dict:
        """Recursively build window hierarchy tree"""
        try:
            # Get basic window info
            rect = win32gui.GetWindowRect(hwnd)
            title = win32gui.GetWindowText(hwnd)
            class_name = win32gui.GetClassName(hwnd)
            visible = win32gui.IsWindowVisible(hwnd)
            
            node = {
                'hwnd': hwnd,
                'title': title,
                'class': class_name,
                'rect': rect,
                'size': (rect[2] - rect[0], rect[3] - rect[1]),
                'visible': visible,
                'depth': depth,
                'children': []
            }
            
            # Get all child windows
            def enum_child_proc(child_hwnd, lparam):
                try:
                    # Only include visible children with reasonable size
                    if win32gui.IsWindowVisible(child_hwnd):
                        child_rect = win32gui.GetWindowRect(child_hwnd)
                        width = child_rect[2] - child_rect[0]
                        height = child_rect[3] - child_rect[1]
                        
                        # Skip tiny elements (< 5px) - usually artifacts
                        if width >= 5 and height >= 5:
                            child_tree = self._build_window_tree(child_hwnd, depth + 1)
                            node['children'].append(child_tree)
                except:
                    pass
                return True
            
            win32gui.EnumChildWindows(hwnd, enum_child_proc, 0)
            
            # Sort children by position (top-to-bottom, left-to-right)
            node['children'].sort(key=lambda x: (x['rect'][1], x['rect'][0]))
            
            return node
            
        except Exception as e:
            return {'hwnd': hwnd, 'error': str(e), 'children': []}

    def _format_hierarchy_tree(self, tree: Dict) -> str:
        """Format tree as readable hierarchical structure"""
        output = []
        
        def format_node(node, prefix=""):
            try:
                hwnd = node['hwnd']
                title = node.get('title', '')
                class_name = node.get('class', '')
                size = node.get('size', (0, 0))
                rect = node.get('rect', (0, 0, 0, 0))
                
                # Format the line
                title_display = title[:40] + "..." if len(title) > 40 else title
                title_display = title_display or "Untitled"
                
                line = f"{prefix}‚îú‚îÄ {title_display}"
                line += f" [{class_name}]"
                line += f" {size[0]}√ó{size[1]}"
                line += f" @({rect[0]},{rect[1]})"
                line += f" HWND:{hwnd}"
                
                output.append(line)
                
                # Process children
                children = node.get('children', [])
                for i, child in enumerate(children):
                    is_last = (i == len(children) - 1)
                    child_prefix = prefix + ("    " if is_last else "‚îÇ   ")
                    format_node(child, child_prefix)
                    
            except Exception as e:
                output.append(f"{prefix}‚îú‚îÄ ERROR: {e}")
        
        # Header
        root_title = tree.get('title', 'Unknown Window')
        root_class = tree.get('class', 'Unknown')
        root_size = tree.get('size', (0, 0))
        
        output.append(f"üå≥ WINDOW HIERARCHY TREE")
        output.append(f"‚ïê" * 60)
        output.append(f"üè† Root: {root_title} [{root_class}] {root_size[0]}√ó{root_size[1]}")
        output.append("")
        
        # Root children
        children = tree.get('children', [])
        for i, child in enumerate(children):
            is_last = (i == len(children) - 1)
            child_prefix = "    " if is_last else "‚îÇ   "
            format_node(child, child_prefix)
        
        if not children:
            output.append("‚îî‚îÄ (No child windows detected)")
        
        output.append("")
        output.append(f"üìä Total regions found: {self._count_nodes(tree)}")
        
        return "\n".join(output)

    def _count_nodes(self, tree: Dict) -> int:
        """Count total nodes in tree"""
        count = 1  # Count this node
        for child in tree.get('children', []):
            count += self._count_nodes(child)
        return count

    def launch_application(self, app_name: str, screen_id: int, fullscreen: bool = True) -> Tuple[bool, str]:
        """
        Launch an application on a specific screen in fullscreen mode
        
        Args:
            app_name: Name/path of the application to launch
            screen_id: Screen ID (1-based) to launch the app on
            fullscreen: Whether to make the app fullscreen (default: True)
            
        Returns:
            Tuple[bool, str]: (success, message)
        """
        try:
            time.sleep(0.1)
            
            # Validate screen ID
            if screen_id < 1 or screen_id > len(self.monitors):
                return False, f"Invalid screen ID {screen_id}. Available screens: 1-{len(self.monitors)}"
            
            target_monitor = self.monitors[screen_id - 1]
            
            # Check if app is already running
            existing_windows = self.find_window_by_app(app_name)
            if existing_windows:
                # App already running - warn user
                running_instances = len(existing_windows)
                window_details = []
                for window in existing_windows[:3]:  # Show first 3 instances
                    screen = window.get('screen', 'Unknown')
                    title = window.get('title', 'Untitled')[:30]
                    window_details.append(f"'{title}' on Screen {screen}")
                
                details_str = ", ".join(window_details)
                if running_instances > 3:
                    details_str += f" and {running_instances - 3} more"
                
                return False, f"‚ö†Ô∏è  Application '{app_name}' is already running ({running_instances} instance{'s' if running_instances > 1 else ''}): {details_str}. Some applications don't support multiple instances."
            
            # Try to launch the application
            import subprocess
            
            # Get the full path if it's just an app name
            app_path = self._resolve_application_path(app_name)
            if not app_path:
                return False, f"Could not find application: {app_name}"
            
            print(f"Launching: {app_path}")
            
            # Launch the application
            try:
                process = subprocess.Popen(app_path, shell=True)
                launched_pid = process.pid
            except Exception as e:
                return False, f"Failed to launch application: {e}"
            
            # Wait for the window to appear (with timeout)
            new_window_hwnd = None
            max_wait_time = 20  # 10 seconds timeout
            wait_interval = 0.5
            elapsed_time = 0
            
            print(f"Waiting for window to appear (PID: {launched_pid})...")
            
            while elapsed_time < max_wait_time and not new_window_hwnd:
                time.sleep(wait_interval)
                elapsed_time += wait_interval
                
                # Look for new windows using the correct method
                current_windows = self.get_all_windows()
                for window in current_windows:
                    # Try to match by process name or PID
                    window_proc = window.get('proc', '').lower()
                    app_name_lower = app_name.lower()
                    
                    if (app_name_lower in window_proc or 
                        window_proc.replace('.exe', '') in app_name_lower or
                        window.get('pid') == launched_pid):
                        new_window_hwnd = window['hwnd']
                        print(f"Found new window: {window.get('title', 'Untitled')} (HWND: {new_window_hwnd})")
                        break
            
            if not new_window_hwnd:
                return False, f"Application launched but window not detected within {max_wait_time} seconds. It may still be starting up."
            
            # Move window to target screen and make fullscreen
            success_move = self.move_window_to_monitor(new_window_hwnd, screen_id)
            if not success_move[0]:
                return False, f"Application launched but failed to move to screen {screen_id}: {success_move[1]}"
            
            time.sleep(0.5)  # Let the move complete
            
            if fullscreen:
                # Maximize the window to make it fullscreen
                success_max = self.maximize_window(new_window_hwnd)
                if not success_max[0]:
                    return False, f"Application launched and moved to screen {screen_id} but failed to maximize: {success_max[1]}"
                
                return True, f"‚úÖ Successfully launched '{app_name}' on Screen {screen_id} in fullscreen mode"
            else:
                return True, f"‚úÖ Successfully launched '{app_name}' on Screen {screen_id}"
                
        except Exception as e:
            return False, f"Failed to launch application: {e}"

    def _resolve_application_path(self, app_name: str) -> Optional[str]:
        """
        Resolve application name to full path using JSON configuration
        """
        # If it's already a full path, return as-is
        if os.path.isfile(app_name):
            return app_name
        
        # Load application mappings from JSON
        app_mappings = self._load_application_mappings()
        
        app_key = app_name.lower().replace('.exe', '')
        if app_key in app_mappings:
            mapped_paths = app_mappings[app_key]
            if isinstance(mapped_paths, list):
                # Try multiple paths for Office apps
                for path in mapped_paths:
                    resolved_path = self._resolve_path_variables(path)
                    if os.path.isfile(resolved_path):
                        return resolved_path
            else:
                # Single path
                resolved_path = self._resolve_path_variables(mapped_paths)
                if os.path.isfile(resolved_path):
                    return resolved_path
        
        # Try Windows PATH
        try:
            app_name_exe = app_name if app_name.endswith('.exe') else app_name + '.exe'
            path = shutil.which(app_name_exe)
            if path:
                return path
        except:
            pass
        
        # Last resort
        return app_name

    def _load_application_mappings(self) -> Dict:
        """Load application mappings from JSON file"""
        try:
            json_path = os.path.join(os.path.dirname(__file__), 'safe_applications.json')
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('applications', {})
        except (FileNotFoundError, json.JSONDecodeError, KeyError) as e:
            print(f"Warning: Could not load application mappings: {e}")
            # Fallback to basic mappings
            return {
                'notepad': 'notepad.exe',
                'calc': 'calc.exe',
                'paint': 'mspaint.exe'
            }

    def _resolve_path_variables(self, path: str) -> str:
        """Resolve path variables like {USER}"""
        if '{USER}' in path:
            path = path.replace('{USER}', getpass.getuser())
        return path

    def get_all_windows(self) -> List[Dict]:
        """Get all visible windows across all monitors"""
        data = self.get_structured_windows()
        all_windows = []
        
        for monitor_data in data["monitors"].values():
            for app_data in monitor_data["applications"].values():
                for window_data in app_data["windows"].values():
                    # Convert to the expected format
                    window_dict = {
                        "hwnd": window_data['hwnd'],
                        "title": window_data['title'],
                        "pid": window_data['pid'],
                        "proc": app_data['process_name'],
                        "rect": [
                            window_data['position']['x'],
                            window_data['position']['y'],
                            window_data['position']['x'] + window_data['size']['width'],
                            window_data['position']['y'] + window_data['size']['height']
                        ],
                        "screen": window_data['monitor'],
                        "minimized": window_data['minimized']
                    }
                    all_windows.append(window_dict)
        
        return all_windows

    def send_esc_enhanced(self) -> Tuple[bool, str]:
        """Enhanced ESC with multiple methods for better dialog compatibility"""
        methods_tried = []
        
        # Method 1: SendInput (prioritize this for dialogs)
        try:
            success = self._send_esc_via_sendinput_direct()
            if success:
                return True, "ESC sent via SendInput (enhanced)"
            methods_tried.append("SendInput failed")
        except Exception as e:
            methods_tried.append(f"SendInput error: {e}")
        
        # Method 2: PostMessage to foreground window (better for modal dialogs)
        try:
            success = self._send_esc_via_postmessage_direct()
            if success:
                return True, "ESC sent via PostMessage (enhanced)"
            methods_tried.append("PostMessage failed")
        except Exception as e:
            methods_tried.append(f"PostMessage error: {e}")
        
        # Method 3: Fall back to existing logic
        try:
            return self.send_key_combination("ESC")
        except Exception as e:
            methods_tried.append(f"Standard method error: {e}")
        
        return False, f"All ESC methods failed: {'; '.join(methods_tried)}"

    def _send_esc_via_sendinput_direct(self) -> bool:
        """Direct SendInput for ESC key only"""
        import ctypes
        from ctypes import wintypes
        
        class KEYBDINPUT(ctypes.Structure):
            _fields_ = [("wVk", wintypes.WORD), ("wScan", wintypes.WORD), 
                       ("dwFlags", wintypes.DWORD), ("time", wintypes.DWORD),
                       ("dwExtraInfo", ctypes.POINTER(wintypes.ULONG))]
        
        class INPUT(ctypes.Structure):
            class _INPUT(ctypes.Union):
                _fields_ = [("ki", KEYBDINPUT)]
            _anonymous_ = ("_input",)
            _fields_ = [("type", wintypes.DWORD), ("_input", _INPUT)]
        
        VK_ESCAPE = 0x1B
        inputs = []
        
        # Key down
        inp = INPUT()
        inp.type = 1  # INPUT_KEYBOARD
        inp.ki.wVk = VK_ESCAPE
        inp.ki.dwFlags = 0
        inputs.append(inp)
        
        # Key up  
        inp = INPUT()
        inp.type = 1
        inp.ki.wVk = VK_ESCAPE
        inp.ki.dwFlags = 2  # KEYEVENTF_KEYUP
        inputs.append(inp)
        
        user32 = ctypes.windll.user32
        num_sent = user32.SendInput(len(inputs), (INPUT * len(inputs))(*inputs), ctypes.sizeof(INPUT))
        return num_sent == len(inputs)

    def _send_esc_via_postmessage_direct(self) -> bool:
        """Direct PostMessage for ESC key"""
        import win32gui
        
        hwnd = win32gui.GetForegroundWindow()
        if not hwnd:
            return False
        
        WM_KEYDOWN, WM_KEYUP, VK_ESCAPE = 0x0100, 0x0101, 0x1B
        
        result1 = win32gui.PostMessage(hwnd, WM_KEYDOWN, VK_ESCAPE, 0)
        time.sleep(0.05)
        result2 = win32gui.PostMessage(hwnd, WM_KEYUP, VK_ESCAPE, 0)
        
        return result1 != 0 and result2 != 0


# Example usage and testing
if __name__ == "__main__":
    wm = WindowManager()
    
    # Print structured output
    wm.print_structured_output(show_minimized=True)
    
    print("\n" + "="*40 + " JSON OUTPUT " + "="*40)
    # Show JSON format
    data = wm.get_structured_windows()
    print(json.dumps(data, indent=2, default=str))


==================================================

